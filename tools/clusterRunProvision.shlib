#!/usr/bin/env bash
set -u

# Copyright 2019-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# BASH VERSION CHECK - since hash maps are implemented >= bash version 4
bash_major_version=$(echo ${BASH_VERSION} | cut -d. -f1)
if (($bash_major_version < 4)); then
	echo "===================================================================="
	echo "Bash version >= 4 is required. Current bash version: ${BASH_VERSION}. Script may fail"
	echo "How to upgrade bash on MacOS:"
	echo "1. Run \"brew update && brew install bash\" to install the latest version of bash for macOS"
	echo "2. Run \"sudo vim /etc/shells\" and add \"/usr/local/bin/bash\" to the list"
	echo "3. Run \"chsh -s /usr/local/bin/bash\" to set default shell to the new one"
	echo "4. Exit and restart the current session"
	echo "===================================================================="
	return 1
fi

. ./importExporter.shlib

# globals
# -----------------
declare DEFAULT_ADMIN
declare DEFAULT_PW
# Run curl in silent mode to prevent progress bar
CURL="curl -s"
POOLS_DEFAULT_BUCKETS_PATH="pools/default/buckets"
CBWORKLOAD_COLLECTION_NUM_ITEMS=10000
CB_CLI_BIN="../../../../../../../install/bin/couchbase-cli"
RR_REST="settings/resourceManagement/bucket/residentRatio"

# topological globals
# -----------------
# cluster -> Bucket(s)
# Bucket -> Scopes
# Scopes -> Collections
declare -A CLUSTER_NAME_HOST_MAP
declare -A CLUSTER_NAME_PORT_MAP
declare -A CLUSTER_NAME_SSLPORT_MAP
declare -A CLUSTER_SETUP_DONE_MAP
declare -A CLUSTER_NAME_SECURE_PORT_MAP
declare -A CLUSTER_NAME_XDCR_PORT_MAP
declare -A CLUSTER_NAME_KV_PORT_MAP
declare -A CLUSTER_NAME_BUCKET_MAP
declare -A BUCKET_NAME_RAMQUOTA_MAP
declare -A BUCKET_NAME_SCOPE_MAP
declare -A SCOPE_NAME_COLLECTION_MAP
declare -A BUCKET_PROPERTIES_OUTPUT_MAP
declare -A BUCKET_REPL_PROPERTIES_MAP
declare -A BUCKET_REPL_PROPERTIES_OUTPUT_MAP
declare -A BUCKET_REPL_EXPORT_MAP
declare -A CLUSTER_DEPENDENCY_MAP
declare -A CLUSTER_ENCRYPTION_LEVEL_MAP
declare -A NODE_CERT_MAP
declare -A NODE_KEY_MAP
declare -A NODE_CA_MAP
declare -A CLIENT_CERT_MAP
declare -A CLIENT_KEY_MAP
declare -A VAGRANT_KV_EXTERNAL_MAP
declare -A VAGRANT_KVSSL_EXTERNAL_MAP
declare -A VAGRANT_CAPI_EXTERNAL_MAP
declare -A VAGRANT_IP_EXTERNAL_MAP
declare -A VAGRANT_VM_IP_MAP
declare -A VAGRANT_VM_IDX_MAP
declare -A VAGRANT_VERSION_MAP
declare -A CLUSTER_NAME_KV_PORT_MAP

# optional globals
# -----------------
# if not defined, will look for it using locate
declare CBWORKLOADGEN=""
declare DATALOAD_CONT_DELAY="10"
# Key is in the format of "BucketName,ParameterName"
# Value is in the format of actual value to send
declare -A BUCKET_NAME_PROPERTIES_MAP
declare -A CLUSTER_ROOT_CERTIFICATE_MAP
declare -A CLUSTER_ROOT_CERTIFICATE_LOCATION
declare -A CLUSTER_ROOT_KEY_LOCATION
declare VAGRANT_LB_IP

# These are to record which containers have been created already
# to prevent duplicated creates
declare -A CLUSTER_NAME_BUCKET_DONE_MAP
declare -A BUCKET_NAME_SCOPE_DONE_MAP
declare -A SCOPE_NAME_COLLECTION_DONE_MAP

REST_MAX_RETRY=5
GET_BROKEN_MAP_NOT_FOUND=255
CHECK_CHANGES_LEFT_MAX=5

# With python 3.9 to bypass "OpenSSL 3.0's legacy provider failed to load" message when running cbworkloadgen
export CRYPTOGRAPHY_OPENSSL_NO_LEGACY=1

# Input
# 0: ClusterName
# 1: Bucket Name
# 2: Scope Name (optional)
# 3: Collection Name (optional)
# Return code:
# 0: if namespace exists
# 1: If it does not
function checkNamespaceCreated {
	local clusterName=$1
	local bucketName=$2
	local scopeName=${3:-}
	local collectionName=${4:-}
	local key
	local key2

	for chkClusterName in $(echo ${!CLUSTER_NAME_BUCKET_DONE_MAP[@]}); do
		if [[ "$chkClusterName" == "$clusterName" ]]; then
			bucketNames=(${CLUSTER_NAME_BUCKET_DONE_MAP[$clusterName]:-})
			for chkBucketName in $(echo ${bucketNames[@]}); do
				if [[ "$chkBucketName" == "$bucketName" ]]; then
					if [[ -z "${scopeName:-}" ]]; then
						# User asked for clusterName:bucketName and it was done
						return 0
					fi
					key="${chkClusterName},${chkBucketName}"
					for chkScopeName in $(echo ${BUCKET_NAME_SCOPE_DONE_MAP["$key"]:-}); do
						if [[ "$chkScopeName" == "$scopeName" ]]; then
							if [[ -z "${collectionName:-}" ]]; then
								#User asked for cluster:bucket:scope and it's done
								return 0
							fi
							key2="${chkClusterName},${chkBucketName},${chkScopeName}"
							for chkColName in $(echo ${SCOPE_NAME_COLLECTION_DONE_MAP["$key2"]:-}); do
								if [[ "$chkColName" == "$collectionName" ]]; then
									return 0
								fi
							done
						fi
					done
				fi
			done
		fi
	done
	return 1
}

function recordNamespaceCreated {
	local clusterName=$1
	local bucketName=$2
	local scopeName=${3:-}
	local collectionName=${4:-}

	if [[ -z "${scopeName:-}" ]]; then
		# bucket
		local -a bucketArr
		local key="${clusterName}"
		if [[ -z ${CLUSTER_NAME_BUCKET_DONE_MAP[$key]:-} ]]; then
			bucketArr=("$bucketName")
		else
			bucketArr=(${CLUSTER_NAME_BUCKET_DONE_MAP[$key]})
			bucketArr[${#bucketArr[@]}]="$bucketName"
		fi
		CLUSTER_NAME_BUCKET_DONE_MAP[$key]=${bucketArr[@]}
	elif [[ -z "${collectionName:-}" ]]; then
		local -a scopeArr
		local key="${clusterName},${bucketName}"
		if [[ -z ${BUCKET_NAME_SCOPE_DONE_MAP[$key]:-} ]]; then
			scopeArr=("$scopeName")
		else
			scopeArr=(${BUCKET_NAME_SCOPE_DONE_MAP[$key]})
			scopeArr[${#scopeArr[@]}]="$scopeName"
		fi
		BUCKET_NAME_SCOPE_DONE_MAP[$key]=${scopeArr[@]}
	else
		local -a colArr
		local key="${clusterName},${bucketName},${scopeName}"
		if [[ -z ${SCOPE_NAME_COLLECTION_DONE_MAP[$key]:-} ]]; then
			colArr=("$collectionName")
		else
			colArr=(${SCOPE_NAME_COLLECTION_DONE_MAP[$key]})
			colArr[${#colArr[@]}]="$collectionName"
		fi
		SCOPE_NAME_COLLECTION_DONE_MAP[$key]=${colArr[@]}
	fi
}

function deleteBucketRecordNamespace {
	local clusterName=$1
	local bucketName=$2

	# First remove the bucket entity
	local key="${clusterName}"
	local -a bucketArr
	if [[ ! -z ${CLUSTER_NAME_BUCKET_DONE_MAP[$key]:-} ]]; then
		# remove the bucket map from the array of bucketDone by creating a new array
		bucketArr=(${CLUSTER_NAME_BUCKET_DONE_MAP[$key]})
		newArray=()
		local value
		for value in "${bucketArr[@]}"; do
			[[ "$value" != "$bucketName" ]] && newArray+=($value)
		done
		CLUSTER_NAME_BUCKET_DONE_MAP[$key]=${newArray[@]}
	fi

	# Before unsetting scopeArr, unset all the collection under each scope
	key="${clusterName},${bucketName}"
	if [[ -z ${BUCKET_NAME_SCOPE_DONE_MAP[$key]:-} ]]; then
		# no scopes or collections underneath, we're done
		return
	fi

	local -a scopeArr
	scopeArr=(${BUCKET_NAME_SCOPE_DONE_MAP[$key]})
	unset BUCKET_NAME_SCOPE_DONE_MAP[$key]

	local oneScope
	for oneScope in "${scopeArr[@]}"; do
		key="${clusterName},${bucketName},${oneScope}"
		unset SCOPE_NAME_COLLECTION_DONE_MAP[$key]
	done

}

# Input:
# 1. Bucket name
# 2. An associative array of Key - Parameter Value - value to send
# Will store information as:
# BUCKET_NAME_PROPERTIES_MAP=([B1,CompressionMode]="Active" [B1,ramQuotaMB]="100" )
function insertPropertyIntoBucketNamePropertyMap {
	local bucketName=$1
	local -n incomingMap=$2
	for key in ${!incomingMap[@]}; do
		BUCKET_NAME_PROPERTIES_MAP["${bucketName},${key}"]=${incomingMap[$key]}
	done
	export BUCKET_NAME_PROPERTIES_MAP
}

function cleanupBucketNamePropertyMap {
	BUCKET_NAME_PROPERTIES_MAP=()
}

function cleanupClientCertMaps {
	CLIENT_CERT_MAP=()
	CLIENT_KEY_MAP=()
}

# Input:
# 1. Bucket name
# Outputs associative array as a exported global of BUCKET_PROPERTIES_OUTPUT_MAP
function getPropertiesFromBucketNamePropertyMap {
	local bucketName=$1

	# first clear previous data - cannot use unset as it breaks the return val
	BUCKET_PROPERTIES_OUTPUT_MAP=()

	# key is bucketName,Property
	for bp in ${!BUCKET_NAME_PROPERTIES_MAP[@]}; do
		key=$(echo "$bp" | cut -d, -f1)
		property=$(echo "$bp" | cut -d, -f2)
		if [[ $key != $bucketName ]]; then
			continue
		fi
		BUCKET_PROPERTIES_OUTPUT_MAP["$property"]=${BUCKET_NAME_PROPERTIES_MAP[$bp]}
	done
	export BUCKET_PROPERTIES_OUTPUT_MAP
}

# Input:
# 1. Source Cluster name
# 2. Source Bucket name
# 3. Target Cluster name
# 4. Target Cluster name
# 2. An associative array of Key - Parameter Value - value to send
function insertPropertyIntoBucketReplPropertyMap {
	local sourceCluster=$1
	local sourceBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local -n incomingMap=$5

	BUCKET_REPL_PROPERTIES_MAP=()
	for key in ${!incomingMap[@]}; do
		BUCKET_REPL_PROPERTIES_MAP["${sourceCluster},${sourceBucket},${targetCluster},${targetBucket},${key}"]=${incomingMap[$key]}
	done
	export BUCKET_REPL_PROPERTIES_MAP
}

# Input:
# 1. Source Cluster name
# 2. Source Bucket name
# 3. Target Cluster name
# 4. Target Cluster name
# 2. An associative array of Key - Parameter Value - value to send
function insertBucketReplIntoExportMap {
	local sourceCluster=$1
	local sourceBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local replRestID=$5

	BUCKET_REPL_EXPORT_MAP["${sourceCluster},${sourceBucket},${targetCluster},${targetBucket}"]=${replRestID}
	export BUCKET_REPL_EXPORT_MAP
}

function getBucketReplicationRestID {
	local chkSourceCluster=$1
	local chkSourceBucket=$2
	local chkTargetCluster=$3
	local chkTargetBucket=$4

	for replKey in "${!BUCKET_REPL_EXPORT_MAP[@]}"; do
		local sourceCluster=$(echo "$replKey" | cut -d, -f1)
		local restID=$(echo "${BUCKET_REPL_EXPORT_MAP[$replKey]}" | sed 's/"//g')
		local sourceBucket=$(echo "$replKey" | cut -d, -f2)
		local targetCluster=$(echo "$replKey" | cut -d, -f3)
		local targetBucket=$(echo "$replKey" | cut -d, -f4)

		if [[ "$chkSourceCluster" == "$sourceCluster" && "$chkSourceBucket" == "$sourceBucket" && "$chkTargetCluster" == "$targetCluster" && "$chkTargetBucket" == "$targetBucket" ]]; then
			echo "$restID"
			return 0
		fi
	done
	return 1
}

# Input:
# 1. Source Cluster name
# 2. Source Bucket name
# 3. Target Cluster name
# 4. Target Cluster name
function getPropertiesFromBucketReplPropertyMap {
	local sourceCluster=$1
	local sourceBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	BUCKET_REPL_PROPERTIES_OUTPUT_MAP=()

	local checkString="${sourceCluster},${sourceBucket},${targetCluster},${targetBucket}"
	# key is bucketName,Property
	for bp in ${!BUCKET_REPL_PROPERTIES_MAP[@]}; do
		key=$(echo "$bp" | cut -d, -f1-4)
		property=$(echo "$bp" | cut -d, -f5)
		if [[ $key != $checkString ]]; then
			continue
		fi
		BUCKET_REPL_PROPERTIES_OUTPUT_MAP["$property"]=${BUCKET_REPL_PROPERTIES_MAP[$bp]}
	done
}

function printBucketPropertiesResults {
	declare -p BUCKET_PROPERTIES_OUTPUT_MAP | cut -d' ' -f3- | cut -d'=' -f2-
}

function printBucketReplPropertiesResults {
	declare -p BUCKET_REPL_PROPERTIES_OUTPUT_MAP | cut -d' ' -f3- | cut -d= -f2-
}

declare -a getBucketOutArr
function getBucketPropertiesRESTString {
	getBucketOutArr=()
	for property in "${!BUCKET_PROPERTIES_OUTPUT_MAP[@]}"; do
		if [[ "$property" != "conflictResolutionType" ]] || [[ -z "${OVERRIDE_CRMODE:-}" ]]; then
			getBucketOutArr+=("-d")
			getBucketOutArr+=("${property}=${BUCKET_PROPERTIES_OUTPUT_MAP[$property]}")
		fi
	done

	if [[ -n "${OVERRIDE_CRMODE:-}" ]]; then
		echo "INFO: Overriding conflictResolutionType bucket setting to ${OVERRIDE_CRMODE:-} due to OVERRIDE_CRMODE=${OVERRIDE_CRMODE:-}"
		getBucketOutArr+=("-d")
		getBucketOutArr+=("conflictResolutionType=${OVERRIDE_CRMODE:-}")
	fi
}

declare -a getBucketReplOutArr
function getBucketReplPropertiesRESTString {
	getBucketReplOutArr=()
	for property in "${!BUCKET_REPL_PROPERTIES_OUTPUT_MAP[@]}"; do
		if [[ "$property" != "mobile" ]] || ((${OVERRIDE_MOBILE:-} == 0)); then
			getBucketReplOutArr+=("-d")
			getBucketReplOutArr+=("${property}=${BUCKET_REPL_PROPERTIES_OUTPUT_MAP[$property]}")
		fi
	done

	if [[ ! -z "${OVERRIDE_MOBILE:-}" ]] && ((${OVERRIDE_MOBILE:-} != 0)); then
		echo "INFO: Overriding mobile replication setting to Active due to OVERRIDE_MOBILE=${OVERRIDE_MOBILE:-}"
		getBucketReplOutArr+=("-d")
		getBucketReplOutArr+=("mobile=Active")
	fi
}

function getBucketInfoRaw {
	local clusterName=$1
	local bucketName=$2
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X GET http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName
}

function getBucketInfo {
	local clusterName=$1
	local bucketName=$2

	if (($(checkJQ) != 0)); then
		getBucketInfoRaw $clusterName $bucketName
	else
		echo $(getBucketInfoRaw $clusterName $bucketName) | jq
	fi
}

function getBucketItemCount {
	local clusterName=$1
	local bucketName=$2
	local maxRetry=3
	local i

	if (($(checkJQ) != 0)); then
		echo "Cannot run $0 without jq"
		return 1
	fi

	for ((i = 0; $i < $maxRetry; i = $(($i + 1)))); do
		rawOutput=$(getBucketInfoRaw $clusterName $bucketName)
		if (($? != 0)); then
			continue
		fi
		basicStats=$(echo "$rawOutput" | jq '.basicStats')
		if (($? != 0)); then
			continue
		fi
		itemCount=$(echo "$basicStats" | jq '.itemCount')
		if (($? == 0)); then
			echo "$itemCount"
			break
		fi
	done
}

# Tests and see if "cluster_run -n x" has been run
function testForClusterRun {
	for port in ${CLUSTER_NAME_PORT_MAP[@]}; do
		$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X GET http://localhost:$port/nodes/self/controller/settings >/dev/null 2>&1
		if (($? != 0)); then
			echo "Node $port not found. Skipping cluster_run XDCR init"
			return 1
		fi
	done
}

function setupVagrantAltAddress {
	local clusterName="$1"
	local hostname=${VAGRANT_VM_IP_MAP[$clusterName]}
	local altHostName

	if [[ -n "${VAGRANT_LB_IP:-}" ]]; then
		altHostName="$VAGRANT_LB_IP"
	elif [[ -n "${VAGRANT_IP_EXTERNAL_MAP["$clusterName"]:-}" ]]; then
		altHostName=${VAGRANT_IP_EXTERNAL_MAP["$clusterName"]:-}
		setupVagrantAltPortForwarding "$clusterName"
	fi

	if [[ -n "${altHostName:-}" ]]; then
		hostname="$altHostName"
	fi

	$CURL -X PUT -u $DEFAULT_ADMIN:$DEFAULT_PW -d "hostname=$hostname&mgmtSSL=${CLUSTER_NAME_SSLPORT_MAP[$clusterName]}&mgmt=${CLUSTER_NAME_PORT_MAP[$clusterName]}&kv=${VAGRANT_KV_EXTERNAL_MAP[$clusterName]}&kvSSL=${VAGRANT_KVSSL_EXTERNAL_MAP[$clusterName]}&capi=${VAGRANT_CAPI_EXTERNAL_MAP[$clusterName]}" http://127.0.0.1:${CLUSTER_NAME_PORT_MAP[$clusterName]}/node/controller/setupAlternateAddresses/external
}

function getClusterIdx {
	local clusterName="$1"
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local nodeDirIdx=$(echo "$port % 10" | bc)

	echo "$nodeDirIdx"
}

function setupCluster {
	local initPort
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		if [[ ! -z "${CLUSTER_SETUP_DONE_MAP[$clusterName]:-}" ]]; then
			echo "$clusterName has already been set up - skipping setup"
			continue
		else
			CLUSTER_SETUP_DONE_MAP[$clusterName]="1"
		fi

		local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
		# If this nodeInfo is meant to be a dependency (added to a cluster) then don't add it
		if [[ -v CLUSTER_DEPENDENCY_MAP[${clusterName:-}] ]]; then
			continue
		fi

		if [[ -z "${VAGRANT_KV_EXTERNAL_MAP[$clusterName]:-}" ]]; then
			initPort="$port"
		else
			initPort=8091
		fi

		local hostIP="127.0.0.1"
		if [[ ! -z "${VAGRANT_VM_IP_MAP[$clusterName]:-}" ]]; then
			hostIP=${VAGRANT_VM_IP_MAP[$clusterName]}
		fi
		echo "SETTING up cluster name $clusterName on port $port with hostIP $hostIP"

		$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X POST http://localhost:$port/nodes/self/controller/settings >/dev/null 2>&1
		$CURL -X POST http://localhost:$port/node/controller/rename -d hostname="$hostIP" >/dev/null 2>&1
		$CURL -X POST http://localhost:$port/node/controller/setupServices -d services=kv >/dev/null 2>&1
		$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -v -X POST http://localhost:$port/settings/web -d password=$DEFAULT_PW -d username=$DEFAULT_ADMIN -d port=$initPort >/dev/null 2>&1
		if (($? != 0)); then
			echo "non-0 error when setting up cluster"
			return $?
		fi

		# Vagrant, set up alternate address so cbworkloadgen can run from dev machine onto vagrants
		if [[ ! -z "${VAGRANT_KV_EXTERNAL_MAP["$clusterName"]:-}" ]]; then
			setupVagrantAltAddress "$clusterName"
		fi
		echo ""
	done
}

function setupClusterWithN1QL {
	local initPort
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		if [[ ! -z "${CLUSTER_SETUP_DONE_MAP[$clusterName]:-}" ]]; then
			echo "$clusterName has already been set up - skipping setup"
			continue
		else
			CLUSTER_SETUP_DONE_MAP[$clusterName]="1"
		fi

		local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
		# If this nodeInfo is meant to be a dependency (added to a cluster) then don't add it
		if [[ -v CLUSTER_DEPENDENCY_MAP[${clusterName:-}] ]]; then
			continue
		fi

		if [[ -z "${VAGRANT_KV_EXTERNAL_MAP[$clusterName]:-}" ]]; then
			initPort="$port"
		else
			initPort=8091
		fi

		local hostIP="127.0.0.1"
		if [[ ! -z "${VAGRANT_VM_IP_MAP[$clusterName]:-}" ]]; then
			hostIP=${VAGRANT_VM_IP_MAP[$clusterName]}
		fi
		echo "SETTING up cluster name $clusterName on port $port with hostIP $hostIP"

		$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X POST http://localhost:$port/nodes/self/controller/settings >/dev/null 2>&1
		$CURL -X POST http://localhost:$port/node/controller/rename -d hostname="$hostIP" >/dev/null 2>&1
		$CURL -X POST http://localhost:$port/node/controller/setupServices -d services=kv%2Cn1ql >/dev/null 2>&1
		$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -v -X POST http://localhost:$port/settings/web -d password=$DEFAULT_PW -d username=$DEFAULT_ADMIN -d port=$initPort >/dev/null 2>&1
		if (($? != 0)); then
			echo "non-0 error when setting up cluster"
			return $?
		fi

		# Vagrant, set up alternate address so cbworkloadgen can run from dev machine onto vagrants
		if [[ ! -z "${VAGRANT_KV_EXTERNAL_MAP["$clusterName"]:-}" ]]; then
			setupVagrantAltAddress "$clusterName"
		fi
		echo ""
	done
}

function setupVagrantAltAddresses {
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		setupVagrantAltAddress "$clusterName"
	done
}

function getNsServerPoolsDefault {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X GET http://127.0.0.1:$port/pools/default
}

function getRebalancingInternal {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X GET http://127.0.0.1:$port/pools/default/rebalanceProgress
}

function getLowerRebalancingPercentage {
	local clusterName=$1

	percentages=$(getRebalancingInternal $clusterName | jq | grep progress | awk '{print $NF}')
	# 0.650390625
	# 0.5553385416666667
	if (($? != 0)); then
		return $?
	fi

	local lowestPercentage=1
	for percentage in $(echo "$percentages"); do
		if (($(echo "$percentage < $lowestPercentage" | bc) == 1)); then
			lowestPercentage=$percentage
		fi
	done

	echo "$lowestPercentage"
}

function waitForRebalanceToFinish {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local pstr="[=======================================================================]"

	echo "Waiting for rebalancing to finish..."
	local status=$(getRebalancingInternal $clusterName | jq '.status')
	while (($(echo "$status" | grep -c "running") > 0)); do
		sleep 5
		status=$(getRebalancingInternal "$clusterName" | jq '.status')
		if (($? != 0)); then
			continue
		fi

		local curPercentage=$(getLowerRebalancingPercentage $clusterName)
		if (($? != 0)); then
			continue
		fi
		local percentInt=$(echo "$curPercentage * 100" | bc | cut -d'.' -f1)
		if [[ -z "${percentInt:-}" ]]; then
			continue
		fi
		local pd=$(($percentInt * 73 / 100))
		printf "\r%3d.%1d%% %.${pd}s" $(($percentInt)) $((($percentInt * 1000 / 100) % 10)) $pstr
	done
	echo ""
}

function addOneNodeIn {
	local dependentClusterName=$1
	local dependentNodePort=${CLUSTER_NAME_PORT_MAP[$dependentClusterName]:-}
	local nodeName=$2
	local port=${CLUSTER_NAME_PORT_MAP[$nodeName]:-}
	local retryCnt=0
	local dependentNodeHostname
	local dependentNodePortToUse
	local httpStr
	local output

	for ((retryCnt = 0; $retryCnt < 5; retryCnt = $(($retryCnt + 1)))); do
		echo "Adding $dependentClusterName:$dependentNodePort ($nodeName) to $port"
		local preAddNumNodes=$(getNsServerPoolsDefault "$nodeName" | jq '.nodes' | jq length)

		httpStr="https://"
		# Special case for vagrant
		if [[ ! -z "${VAGRANT_VM_IP_MAP[$dependentClusterName]:-}" ]]; then
			dependentNodeHostname="${VAGRANT_VM_IP_MAP[$dependentClusterName]}"
			dependentNodePortToUse="18091"
			# special case for 6.0.x
			if [[ ! -z "${VAGRANT_VERSION_MAP[$nodeName]:-}" ]] && [[ "${VAGRANT_VERSION_MAP[$nodeName]}" =~ 6\.0\. ]]; then
				httpStr="http://"
				dependentNodePortToUse="8091"
			fi
		else
			dependentNodeHostname="127.0.0.1"
			dependentNodePortToUse="1${dependentNodePort}"
		fi

		output=$($CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X POST http://localhost:$port/controller/addNode -d user=$DEFAULT_ADMIN -d password=$DEFAULT_PW -d hostname="${httpStr}${dependentNodeHostname}:${dependentNodePortToUse}" 2>&1)
		if [[ "$output" =~ Node\ is\ already\ part\ of\ cluster ]]; then
			return 0
		fi

		echo "Waiting for membership update"
		sleep 10

		local postAddNumNodes=$(getNsServerPoolsDefault "$nodeName" | jq '.nodes' | jq length)

		if (($postAddNumNodes != $(($preAddNumNodes + 1)))); then
			echo "Error - adding a node resulted going from $preAddNumNodes to $postAddNumNodes"
		else
			return 0
		fi
	done

	exit 1
}

function addNodesIn {
	local dependentClusterName
	for dependentClusterName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		local nodeName=${CLUSTER_DEPENDENCY_MAP[$dependentClusterName]:-}

		addOneNodeIn $dependentClusterName $nodeName
	done
}

function populateKnownNodesString {
	local nodeName=$1
	local poolsDefault=$(getNsServerPoolsDefault $nodeName)
	local membership=$(echo $poolsDefault | jq | grep otpNode | awk '{print $NF}' | sed 's/"//g' | sed 's/,//g')
	# n_0@192.168.1.113
	# n_2@127.0.0.1

	local knownNodesString="knownNodes="
	local comma=""
	# knownNodes=n_2@127.0.0.1,n_0@192.168.1.113
	for member in $(echo "$membership"); do
		knownNodesString="${knownNodesString}${comma}${member}"
		comma=","
	done
	echo "$knownNodesString"
}

function startRebalancingWithKnownNodes {
	local nodeName=$1
	local knownNodesString=$2
	local port=${CLUSTER_NAME_PORT_MAP[$nodeName]:-}

	# This kicks off the rebalancing
	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/controller/rebalance -d "$knownNodesString"
	if (($? != 0)); then
		echo "Error when trying to rebalance with known $knownNodesString"
	fi

	sleep 10
	waitForRebalanceToFinish $nodeName
}

function startRebalancing {
	local nodeName=$1
	local knownNodesString
	local depNodeName

	echo "Starting rebalance process..."
	knownNodesString=$(populateKnownNodesString $nodeName)

	startRebalancingWithKnownNodes "$nodeName" "$knownNodesString"

	# Vagrant nodes need alt addresses added
	if [[ ! -z "${VAGRANT_KV_EXTERNAL_MAP[$nodeName]:-}" ]]; then
		echo "Setting up alternate address for $nodeName"
		setupVagrantAltAddress "$nodeName"
		# Need to find dependent node and setup alternate address for that node too
		for depNodeName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
			if [[ "${CLUSTER_DEPENDENCY_MAP[$depNodeName]:-}" == "$nodeName" ]]; then
				echo "Found $depNodeName as a depdency node. Setting up alternate addressing"
				setupVagrantAltAddress "$depNodeName"
				break
			fi
		done
	fi
}

function startEjectNode {
	# Essentially we will work off of portname
	local nodeName=$1
	local motherNode=$2
	local localhostIp="127.0.0.1"
	local port=${CLUSTER_NAME_PORT_MAP[$nodeName]:-}
	local motherPort=${CLUSTER_NAME_PORT_MAP[$motherNode]:-}
	local otpNodeName
	local hostNameToLookFor

	if [[ ! -z "${VAGRANT_VM_IP_MAP[$nodeName]:-}" ]]; then
		hostNameToLookFor="${VAGRANT_VM_IP_MAP[$nodeName]}:8091"
	else
		hostNameToLookFor="${localhostIp}:${port}"
	fi

	local nodesList=$(getNsServerPoolsDefault $nodeName | jq '.nodes' | jq -cr '.[]')
	#{"clusterMembership":"active","recoveryType":"none","status":"healthy","otpNode":"n_0@192.168.1.113","thisNode":true,"hostname":"192.168.1.113:9000","nodeUUID":"cbef3c8c28031971e9e61234560c8f0d","clusterCompatibility":458752,"version":"0.0.0-0000-enterprise","os":"x86_64-apple-darwin18.7.0","cpuCount":12,"ports":{"direct":12000,"httpsCAPI":19500,"httpsMgmt":19000,"distTCP":21400,"distTLS":21450},"services":["kv"],"nodeEncryption":false,"configuredHostname":"192.168.1.113:9000","addressFamily":"inet","externalListeners":[{"afamily":"inet","nodeEncryption":false},{"afamily":"inet6","nodeEncryption":false}],"couchApiBase":"http://192.168.1.113:9500/","couchApiBaseHTTPS":"https://192.168.1.113:19500/","systemStats":{"cpu_utilization_rate":16.81045313677862,"cpu_stolen_rate":0,"swap_total":2147483648,"swap_used":951320576,"mem_total":34359738368,"mem_free":17357692928,"mem_limit":34359738368,"cpu_cores_available":12,"allocstall":18446744073709552000},"interestingStats":{"couch_docs_actual_disk_size":39218356,"couch_views_actual_disk_size":0,"curr_items":0,"curr_items_tot":0,"ep_bg_fetched":0,"couch_docs_data_size":1997575,"mem_used":69419072,"vb_active_num_non_resident":0,"vb_replica_curr_items":0,"cmd_get":0,"get_hits":0,"ops":0},"uptime":"401","memoryTotal":34359738368,"memoryFree":17357692928,"mcdMemoryReserved":26214,"mcdMemoryAllocated":26214}
	#{"clusterMembership":"active","recoveryType":"none","status":"healthy","otpNode":"n_2@127.0.0.1","hostname":"127.0.0.1:9002","nodeUUID":"7356e3a2ed404e7bec0d2ca43ceb3526","clusterCompatibility":458752,"version":"0.0.0-0000-enterprise","os":"x86_64-apple-darwin18.7.0","cpuCount":12,"ports":{"direct":12004,"httpsCAPI":19502,"httpsMgmt":19002,"distTCP":21400,"distTLS":21450},"services":["kv"],"nodeEncryption":false,"configuredHostname":"127.0.0.1:9002","addressFamily":"inet","externalListeners":[{"afamily":"inet","nodeEncryption":false},{"afamily":"inet6","nodeEncryption":false}],"couchApiBase":"http://127.0.0.1:9502/","couchApiBaseHTTPS":"https://127.0.0.1:19502/","systemStats":{"cpu_utilization_rate":20.66955363091272,"cpu_stolen_rate":0,"swap_total":2147483648,"swap_used":951320576,"mem_total":34359738368,"mem_free":17360678912,"mem_limit":34359738368,"cpu_cores_available":12,"allocstall":18446744073709552000},"interestingStats":{"couch_docs_actual_disk_size":38648300,"couch_views_actual_disk_size":0,"curr_items":0,"curr_items_tot":0,"ep_bg_fetched":0,"couch_docs_data_size":2004302,"mem_used":69085160,"vb_active_num_non_resident":0,"vb_replica_curr_items":0,"cmd_get":0,"get_hits":0,"ops":0},"uptime":"403","memoryTotal":34359738368,"memoryFree":17360678912,"mcdMemoryReserved":26214,"mcdMemoryAllocated":26214}

	if [[ -z "${nodesList:-}" ]]; then
		echo "ERROR - nodesList is empty. Did you enter the wrong argument for startEjectNode?"
		exit 1
	fi

	local checkHostName
	local nodeInfo
	local failoverNodeString
	local knownNodesString
	local optNodeNameStripped
	local OLDIFS="$IFS"

	IFS=$'\n'
	for nodeInfo in $(echo "$nodesList"); do
		IFS="$OLDIFS"
		checkHostName=$(echo "$nodeInfo" | jq '.hostname' | sed 's/"//g')
		if [[ "$checkHostName" == "$hostNameToLookFor" ]]; then
			# Found it
			otpNodeName=$(echo "$nodeInfo" | jq '.otpNode')
			# "n_0@192.168.1.113"
			otpNodeNameStripped=$(echo "$otpNodeName" | sed 's/"//g')
			failoverNodeString="ejectedNodes=$otpNodeNameStripped"
			knownNodesString=$(populateKnownNodesString $motherNode)
			local preEjectCnt=$(getNsServerPoolsDefault $motherNode | jq '.nodes' | jq length)
			$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$motherPort/controller/rebalance -d "$failoverNodeString" -d "$knownNodesString"
			if (($? != 0)); then
				echo "Error when trying to rebalance with eject $failoverNodeString and known $knownNodesString"
			fi
			sleep 10
			waitForRebalanceToFinish $motherNode
			local postEjectCnt=$(getNsServerPoolsDefault $motherNode | jq '.nodes' | jq length)
			if (($postEjectCnt != $(($preEjectCnt - 1)))); then
				echo "Error - ejecting a node resulted going from $preEjectCnt to $postEjectCnt"
				exit 1
			fi
		fi
		IFS=$'\n'
	done
	IFS="$OLDIFS"
}

# Similar to failoverNode but cleans everything up
# TODO neil - find a way to refactor duplicate code
function restoreClusterBack {
	# Essentially we will work off of portname
	local nodeName=$1
	local localhostIp="127.0.0.1"
	local port=${CLUSTER_NAME_PORT_MAP[$nodeName]:-}
	local hostNameToLookFor="${localhostIp}:${port}"
	local otpNodeName

	local totalFoundNode=0

	local preEjectCnt=$(getNsServerPoolsDefault $nodeName | jq '.nodes' | jq length)
	for dependentClusterName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		local dependentNodePort=${CLUSTER_NAME_PORT_MAP[$dependentClusterName]:-}
		local motherNode=${CLUSTER_DEPENDENCY_MAP[$dependentClusterName]:-}
		local port=${CLUSTER_NAME_PORT_MAP[$motherNode]:-}

		echo "Found $dependentClusterName removing $dependentNodePort ($motherNode) to $port"
		hostNameToLookFor="${localhostIp}:${dependentNodePort}"

		local nodesList=$(getNsServerPoolsDefault $nodeName | jq '.nodes' | jq -cr '.[]')
		#{"clusterMembership":"active","recoveryType":"none","status":"healthy","otpNode":"n_0@192.168.1.113","thisNode":true,"hostname":"192.168.1.113:9000","nodeUUID":"cbef3c8c28031971e9e61234560c8f0d","clusterCompatibility":458752,"version":"0.0.0-0000-enterprise","os":"x86_64-apple-darwin18.7.0","cpuCount":12,"ports":{"direct":12000,"httpsCAPI":19500,"httpsMgmt":19000,"distTCP":21400,"distTLS":21450},"services":["kv"],"nodeEncryption":false,"configuredHostname":"192.168.1.113:9000","addressFamily":"inet","externalListeners":[{"afamily":"inet","nodeEncryption":false},{"afamily":"inet6","nodeEncryption":false}],"couchApiBase":"http://192.168.1.113:9500/","couchApiBaseHTTPS":"https://192.168.1.113:19500/","systemStats":{"cpu_utilization_rate":16.81045313677862,"cpu_stolen_rate":0,"swap_total":2147483648,"swap_used":951320576,"mem_total":34359738368,"mem_free":17357692928,"mem_limit":34359738368,"cpu_cores_available":12,"allocstall":18446744073709552000},"interestingStats":{"couch_docs_actual_disk_size":39218356,"couch_views_actual_disk_size":0,"curr_items":0,"curr_items_tot":0,"ep_bg_fetched":0,"couch_docs_data_size":1997575,"mem_used":69419072,"vb_active_num_non_resident":0,"vb_replica_curr_items":0,"cmd_get":0,"get_hits":0,"ops":0},"uptime":"401","memoryTotal":34359738368,"memoryFree":17357692928,"mcdMemoryReserved":26214,"mcdMemoryAllocated":26214}
		#{"clusterMembership":"active","recoveryType":"none","status":"healthy","otpNode":"n_2@127.0.0.1","hostname":"127.0.0.1:9002","nodeUUID":"7356e3a2ed404e7bec0d2ca43ceb3526","clusterCompatibility":458752,"version":"0.0.0-0000-enterprise","os":"x86_64-apple-darwin18.7.0","cpuCount":12,"ports":{"direct":12004,"httpsCAPI":19502,"httpsMgmt":19002,"distTCP":21400,"distTLS":21450},"services":["kv"],"nodeEncryption":false,"configuredHostname":"127.0.0.1:9002","addressFamily":"inet","externalListeners":[{"afamily":"inet","nodeEncryption":false},{"afamily":"inet6","nodeEncryption":false}],"couchApiBase":"http://127.0.0.1:9502/","couchApiBaseHTTPS":"https://127.0.0.1:19502/","systemStats":{"cpu_utilization_rate":20.66955363091272,"cpu_stolen_rate":0,"swap_total":2147483648,"swap_used":951320576,"mem_total":34359738368,"mem_free":17360678912,"mem_limit":34359738368,"cpu_cores_available":12,"allocstall":18446744073709552000},"interestingStats":{"couch_docs_actual_disk_size":38648300,"couch_views_actual_disk_size":0,"curr_items":0,"curr_items_tot":0,"ep_bg_fetched":0,"couch_docs_data_size":2004302,"mem_used":69085160,"vb_active_num_non_resident":0,"vb_replica_curr_items":0,"cmd_get":0,"get_hits":0,"ops":0},"uptime":"403","memoryTotal":34359738368,"memoryFree":17360678912,"mcdMemoryReserved":26214,"mcdMemoryAllocated":26214}

		if [[ -z "${nodesList:-}" ]]; then
			echo "ERROR - nodesList is empty. Did you enter the wrong nodeName for failoverNode?"
			exit 1
		fi

		local checkHostName
		local nodeInfo
		local failoverNodeString
		local knownNodesString
		local optNodeNameStripped
		local foundFailoverNode=0
		local OLDIFS="$IFS"

		IFS=$'\n'
		for nodeInfo in $(echo "$nodesList"); do
			IFS="$OLDIFS"
			checkHostName=$(echo "$nodeInfo" | jq '.hostname' | sed 's/"//g')
			if [[ "$checkHostName" == "$hostNameToLookFor" ]]; then
				foundFailoverNode=1
				# Found it
				otpNodeName=$(echo "$nodeInfo" | jq '.otpNode')
				# "n_0@192.168.1.113"
				otpNodeNameStripped=$(echo "$otpNodeName" | sed 's/"//g')
				failoverNodeString="otpNode=$otpNodeNameStripped"
				$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/controller/failOver -d "$failoverNodeString"
				if (($? != 0)); then
					echo "Error when trying to rebalance with eject $failoverNodeString and known $knownNodesString"
				fi
				echo "Wait 10 sec after issuing failover command ..."
				sleep 10
			fi
			IFS=$'\n'
		done
		IFS="$OLDIFS"
		if (($foundFailoverNode == 0)); then
			echo "Could not find $hostNameToLookFor"
			return 1
		else
			totalFoundNode=$(($totalFoundNode + 1))
		fi
	done

	if (($totalFoundNode > 0)); then
		startRebalancing "$nodeName" "$otpNodeNameStripped"
		echo "Sleeping 20 seconds before checking"
		sleep 20
		local postEjectCnt=$(getNsServerPoolsDefault $nodeName | jq '.nodes' | jq length)
		if (($postEjectCnt != $(($preEjectCnt - $totalFoundNode)))); then
			echo "Error - failover $totalFoundNode nodes resulted going from $preEjectCnt to $postEjectCnt"
			return 1
		fi
	fi
}

function failoverNode {
	# Essentially we will work off of portname
	local nodeName=$1
	local motherNode=$2
	local localhostIp="127.0.0.1"
	local port=${CLUSTER_NAME_PORT_MAP[$nodeName]:-}
	local motherPort=${CLUSTER_NAME_PORT_MAP[$motherNode]:-}
	local hostNameToLookFor="${localhostIp}:${port}"
	local otpNodeName

	local totalRetryCnt=2

	while (($totalRetryCnt > 0)); do
		local nodesList=$(getNsServerPoolsDefault $nodeName | jq '.nodes' | jq -cr '.[]')
		#{"clusterMembership":"active","recoveryType":"none","status":"healthy","otpNode":"n_0@192.168.1.113","thisNode":true,"hostname":"192.168.1.113:9000","nodeUUID":"cbef3c8c28031971e9e61234560c8f0d","clusterCompatibility":458752,"version":"0.0.0-0000-enterprise","os":"x86_64-apple-darwin18.7.0","cpuCount":12,"ports":{"direct":12000,"httpsCAPI":19500,"httpsMgmt":19000,"distTCP":21400,"distTLS":21450},"services":["kv"],"nodeEncryption":false,"configuredHostname":"192.168.1.113:9000","addressFamily":"inet","externalListeners":[{"afamily":"inet","nodeEncryption":false},{"afamily":"inet6","nodeEncryption":false}],"couchApiBase":"http://192.168.1.113:9500/","couchApiBaseHTTPS":"https://192.168.1.113:19500/","systemStats":{"cpu_utilization_rate":16.81045313677862,"cpu_stolen_rate":0,"swap_total":2147483648,"swap_used":951320576,"mem_total":34359738368,"mem_free":17357692928,"mem_limit":34359738368,"cpu_cores_available":12,"allocstall":18446744073709552000},"interestingStats":{"couch_docs_actual_disk_size":39218356,"couch_views_actual_disk_size":0,"curr_items":0,"curr_items_tot":0,"ep_bg_fetched":0,"couch_docs_data_size":1997575,"mem_used":69419072,"vb_active_num_non_resident":0,"vb_replica_curr_items":0,"cmd_get":0,"get_hits":0,"ops":0},"uptime":"401","memoryTotal":34359738368,"memoryFree":17357692928,"mcdMemoryReserved":26214,"mcdMemoryAllocated":26214}
		#{"clusterMembership":"active","recoveryType":"none","status":"healthy","otpNode":"n_2@127.0.0.1","hostname":"127.0.0.1:9002","nodeUUID":"7356e3a2ed404e7bec0d2ca43ceb3526","clusterCompatibility":458752,"version":"0.0.0-0000-enterprise","os":"x86_64-apple-darwin18.7.0","cpuCount":12,"ports":{"direct":12004,"httpsCAPI":19502,"httpsMgmt":19002,"distTCP":21400,"distTLS":21450},"services":["kv"],"nodeEncryption":false,"configuredHostname":"127.0.0.1:9002","addressFamily":"inet","externalListeners":[{"afamily":"inet","nodeEncryption":false},{"afamily":"inet6","nodeEncryption":false}],"couchApiBase":"http://127.0.0.1:9502/","couchApiBaseHTTPS":"https://127.0.0.1:19502/","systemStats":{"cpu_utilization_rate":20.66955363091272,"cpu_stolen_rate":0,"swap_total":2147483648,"swap_used":951320576,"mem_total":34359738368,"mem_free":17360678912,"mem_limit":34359738368,"cpu_cores_available":12,"allocstall":18446744073709552000},"interestingStats":{"couch_docs_actual_disk_size":38648300,"couch_views_actual_disk_size":0,"curr_items":0,"curr_items_tot":0,"ep_bg_fetched":0,"couch_docs_data_size":2004302,"mem_used":69085160,"vb_active_num_non_resident":0,"vb_replica_curr_items":0,"cmd_get":0,"get_hits":0,"ops":0},"uptime":"403","memoryTotal":34359738368,"memoryFree":17360678912,"mcdMemoryReserved":26214,"mcdMemoryAllocated":26214}

		if [[ -z "${nodesList:-}" ]]; then
			echo "ERROR - nodesList is empty. Did you enter the wrong argument for failoverNode?"
			exit 1
		fi

		local checkHostName
		local nodeInfo
		local failoverNodeString
		local knownNodesString
		local optNodeNameStripped
		local OLDIFS="$IFS"

		IFS=$'\n'
		for nodeInfo in $(echo "$nodesList"); do
			IFS="$OLDIFS"
			checkHostName=$(echo "$nodeInfo" | jq '.hostname' | sed 's/"//g')
			if [[ "$checkHostName" == "$hostNameToLookFor" ]]; then
				# Found it
				otpNodeName=$(echo "$nodeInfo" | jq '.otpNode')
				# "n_0@192.168.1.113"
				otpNodeNameStripped=$(echo "$otpNodeName" | sed 's/"//g')
				failoverNodeString="otpNode=$otpNodeNameStripped"
				local preEjectCnt=$(getNsServerPoolsDefault $motherNode | jq '.nodes' | jq length)
				$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$motherPort/controller/failOver -d "$failoverNodeString"
				if (($? != 0)); then
					echo "Error when trying to rebalance with eject $failoverNodeString and known $knownNodesString"
				fi
				echo "Wait 20 sec after issuing failover command before rebalancing command..."
				sleep 20
				startRebalancing "$motherNode" "$otpNodeNameStripped"
				local postEjectCnt=$(getNsServerPoolsDefault $motherNode | jq '.nodes' | jq length)
				if (($postEjectCnt != $(($preEjectCnt - 1)))); then
					echo "Error - failover a node resulted going from $preEjectCnt to $postEjectCnt"
					totalRetryCnt=$(($totalRetryCnt - 1))
				else
					totalRetryCnt=0
				fi
			fi
			IFS=$'\n'
		done
		IFS="$OLDIFS"
	done
}

function enableDeveloperPreview {
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		# enable developer preview
		echo -n "Enabling developer preview on $clusterName"
		local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
		$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://localhost:$port/settings/developerPreview -d enabled="true"
		if (($? != 0)); then
			return $?
		fi
		echo ""
	done
}

function createBucket {
	local clusterName=$1
	local bucketName=$2
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	getPropertiesFromBucketNamePropertyMap "$bucketName"
	echo "For cluster $clusterName CREATING bucket $bucketName with properties $(printBucketPropertiesResults)"
	local ramQuotaCheck=${BUCKET_PROPERTIES_OUTPUT_MAP["ramQuotaMB"]:-}
	if [[ -z "$ramQuotaCheck" ]]; then
		echo "Missing ramQuota for $bucketName"
		return 1
	fi
	getBucketPropertiesRESTString

	# Only run the bucket create command if it hasn't been executed before
	checkNamespaceCreated "$clusterName" "$bucketName"
	if ((!$? == 0)); then
		$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X POST http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH -d name=$bucketName ${getBucketOutArr[@]} >/dev/null 2>&1
		if (($? != 0)); then
			return $?
		fi
		recordNamespaceCreated "$clusterName" "$bucketName"
	fi

	# If bucket has scopes
	if [[ ! -z "${BUCKET_NAME_SCOPE_MAP[$bucketName]:-}" ]]; then
		setupScopes $clusterName $bucketName
	fi

	#if ((${OVERRIDE_MOBILE:-} != 0)); then
	if [[ ! -z "${OVERRIDE_MOBILE:-}" ]] && ((${OVERRIDE_MOBILE:-} != 0)); then
		echo "INFO: Overriding enableCrossClusterVersioning setting to true due to OVERRIDE_MOBILE=${OVERRIDE_MOBILE:-}"
		setCrossClusterVersioningForBucket $clusterName $bucketName
	fi
}

function writeJSONDocument {
	local clusterName=$1
	local bucketName=$2
	local docName=$3
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	# jsonData needs to be enclosed in single quotes
	#local jsonData='{"foo":"bar"}'
	local jsonData=$4

	$CURL --location --request POST http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/docs/$docName \
		--header 'Accept: application/json, text/plain, */*' --header 'Content-Type: application/x-www-form-urlencoded; charset=UTF-8' \
		-u $DEFAULT_ADMIN:$DEFAULT_PW --data-urlencode value=$jsonData >/dev/null
}

function getJSONDocument {
	local clusterName=$1
	local bucketName=$2
	local docName=$3
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	$CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/docs/$docName
}

function writeBinaryDocument {
	local clusterName=$1
	local bucketName=$2
	local docName=$3
	local binaryData=$4
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X POST http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/docs/$docName \
		--data-urlencode value=$binaryData
}

function pipCheckCouchbase {
	if (($(pip3 list 2>&1 | grep -c couchbase) == 0)); then
		pip3 install couchbase
	fi
}

function lockDocument {
	local clusterName=$1
	local bucketName=$2
	local docName=$3
	local secsToLock=$4
	local kvPort=${CLUSTER_NAME_KV_PORT_MAP[$clusterName]:-}

	pipCheckCouchbase

	python3 <<END

from couchbase.auth import PasswordAuthenticator
from couchbase.bucket import Bucket
from couchbase.cluster import Cluster
from couchbase.options import ClusterOptions
from datetime import timedelta
import sys
import time

bootstrap="127.0.0.1:$kvPort"
bucket_name="$bucketName"

# Connect options - authentication
auth = PasswordAuthenticator(
    "$DEFAULT_ADMIN",
    "$DEFAULT_PW",
)

cluster = Cluster('couchbase://{}'.format(bootstrap), ClusterOptions(auth))
bucket = cluster.bucket(bucket_name)

cb_coll = bucket.default_collection()
cb_coll.get_and_lock("$docName", timedelta(seconds=$secsToLock))

END
}

function deleteJSONDocument {
	local clusterName=$1
	local bucketName=$2
	local docName=$3
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	$CURL --location --request DELETE http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/docs/$docName \
		-u $DEFAULT_ADMIN:$DEFAULT_PW
}

function writeCollectionJSONDoc {
	local clusterName=$1
	local bucketName=$2
	local scopeName=$3
	local collectionName=$4
	local docName=$5
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local jsonData=$6

	$CURL --location --request POST http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/scopes/$scopeName/collections/$collectionName/docs/$docName \
		--header 'Accept: application/json, text/plain, */*' --header 'Content-Type: application/x-www-form-urlencoded; charset=UTF-8' \
		-u $DEFAULT_ADMIN:$DEFAULT_PW --data-urlencode value=$jsonData >/dev/null
}

function setupBuckets {
	for clusterName in $(echo ${!CLUSTER_NAME_BUCKET_MAP[@]}); do
		local bucketNames=(${CLUSTER_NAME_BUCKET_MAP[$clusterName]:-})
		for bucketName in $(echo ${bucketNames[@]}); do
			createBucket "$clusterName" "$bucketName"
		done
	done
}

function deleteBucket {
	local clusterName=$1
	local bucketName=$2
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X DELETE http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName >/dev/null 2>&1
	deleteBucketRecordNamespace "$clusterName" "$bucketName"
}

function flushBucket {
	local clusterName=$1
	local bucketName=$2
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	# Don't redirect to dev null in case the bucket has flush disabled - which the error message will help
	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X POST http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/controller/doFlush
}

function cleanupBuckets {
	for clusterName in $(echo ${!CLUSTER_NAME_BUCKET_MAP[@]}); do
		local bucketNames=(${CLUSTER_NAME_BUCKET_MAP[$clusterName]:-})
		for bucketName in $(echo ${bucketNames[@]}); do
			echo "For cluster $clusterName DELETING bucket $bucketName"
			deleteBucket "$clusterName" "$bucketName"
		done
	done
	CLUSTER_NAME_BUCKET_DONE_MAP=()
	BUCKET_NAME_SCOPE_DONE_MAP=()
	SCOPE_NAME_COLLECTION_DONE_MAP=()
}

function forceBucketPurge {
	local clusterName=$1
	local bucketName=$2
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	# https://src.couchbase.org/source/xref/trunk/ns_server/CHANGES?r=87b36e7e#561
	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X POST http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/controller/unsafePurgeBucket
}

function createScope {
	local clusterName=$1
	local bucketName=$2
	local scopeName=$3
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	echo "For cluster $clusterName bucket $bucketName CREATING scope $scopeName"
	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X POST http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/scopes -d name=$scopeName >/dev/null 2>&1
}

function deleteScope {
	local clusterName=$1
	local bucketName=$2
	local scopeName=$3
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	echo "For cluster $clusterName bucket $bucketName DELETING scope $scopeName"
	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X DELETE http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/scopes/$scopeName/ >/dev/null 2>&1
}

# inputs
# 1. cluster name
# 2. bucket name
function setupScopes {
	local clusterName=$1
	local bucketName=$2
	if [[ -z "${clusterName:-}" ]] || [[ -z "${bucketName:-}" ]]; then
		echo "Invalid input"
		return 1
	fi

	local -a scopesArr=(${BUCKET_NAME_SCOPE_MAP[$bucketName]:-})
	if [[ -z "${scopesArr:-}" ]]; then
		echo "No scopes found for bucket $bucketName"
		return 1
	fi

	for scopeName in $(echo ${scopesArr[@]}); do
		checkNamespaceCreated "$clusterName" "$bucketName" "$scopeName"
		if ((!$? == 0)); then
			createScope "$clusterName" "$bucketName" "$scopeName"
			recordNamespaceCreated "$clusterName" "$bucketName" "$scopeName"
		fi
		# If scope has collections
		if [[ ! -z "${SCOPE_NAME_COLLECTION_MAP[$scopeName]:-}" ]]; then
			setupCollections $clusterName $bucketName $scopeName
		fi
	done
}

function createCollection {
	local clusterName=$1
	local bucketName=$2
	local scopeName=$3
	local collectionName=$4
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	echo "For cluster $clusterName bucket $bucketName scope $scopeName CREATING collection $collectionName"
	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X POST http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/scopes/$scopeName/collections -d name=$collectionName >/dev/null 2>&1
}

function deleteCollection {
	local clusterName=$1
	local bucketName=$2
	local scopeName=$3
	local collectionName=$4
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	echo "For cluster $clusterName bucket $bucketName scope $scopeName DELETING collection $collectionName"
	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X DELETE http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/scopes/$scopeName/collections/$collectionName >/dev/null 2>&1
}

# inputs
# 1. cluster name
# 2. bucket name
# 3. scope name
function setupCollections {
	local clusterName=$1
	local bucketName=$2
	local scopeName=$3
	if [[ -z "${clusterName:-}" ]] || [[ -z "${bucketName:-}" ]] || [[ -z "${scopeName:-}" ]]; then
		echo "Invalid input"
		return 1
	fi

	local collectionsArr=(${SCOPE_NAME_COLLECTION_MAP[$scopeName]:-})
	if [[ -z "${collectionsArr:-}" ]]; then
		echo "No collections found for scope $scopeName"
		return 1
	fi

	for collectionName in $(echo ${collectionsArr[@]}); do
		checkNamespaceCreated "$clusterName" "$bucketName" "$scopeName" "$collectionName"
		if ((!$? == 0)); then
			createCollection "$clusterName" "$bucketName" "$scopeName" "$collectionName"
			recordNamespaceCreated "$clusterName" "$bucketName" "$scopeName" "$collectionName"
		fi
	done
}

# Allow specific flags to be passed in:
# -d : <developer mode>
function setupTopologies {
	local OPTIND
	local d
	local developerPreviewSet=0
	local opt

	while getopts "d" opt; do
		case ${opt} in
		d)
			developerPreviewSet=1
			;;
		esac
	done

	setupCluster
	if (($? != 0)); then
		return $?
	fi

	if (($developerPreviewSet == 1)); then
		enableDeveloperPreview
		if (($? != 0)); then
			return $?
		fi
	fi

	setupBuckets
	if (($? != 0)); then
		return $?
	fi
}

# Takes 2 arguments:
# 1- Source cluster name
# 2- Target cluster name
# 3- Target Hostname override
function createRemoteClusterReference {
	local source=$1
	local target=$2
	local targetHost=${3:-"127.0.0.1"}
	if [[ -z "${source:-}" ]] || [[ -z "${target:-}" ]]; then
		echo "Invalid input"
		return 1
	fi
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$source]:-}
	local targetPort=${CLUSTER_NAME_PORT_MAP[$target]:-}
	local sourceHost=${CLUSTER_NAME_HOST_MAP[$source]:-"127.0.0.1"}

	# special case handling for Vagrant
	if [[ ! -z "${VAGRANT_VM_IP_MAP[$target]:-}" ]]; then
		targetHost="${VAGRANT_VM_IP_MAP[$target]}"
		# This may need TLS port in the future?
		targetPort="8091"
	fi

	echo "Creating remote cluster reference from $source to $target"
	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://$sourceHost:$sourcePort/pools/default/remoteClusters -d name=$target -d hostname=$targetHost:$targetPort -d username=$DEFAULT_ADMIN -d password=$DEFAULT_PW
	echo ""
}

function createHalfSecureRemoteClusterReference {
	local source=$1
	local target=$2
	local targetHost=${3:-"127.0.0.1"}
	if [[ -z "${source:-}" ]] || [[ -z "${target:-}" ]]; then
		echo "Invalid input"
		return 1
	fi
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$source]:-}
	local targetPort=${CLUSTER_NAME_PORT_MAP[$target]:-}
	local sourceHost=${CLUSTER_NAME_HOST_MAP[$source]:-"127.0.0.1"}

	echo "Creating remote cluster reference from $source to $target"
	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://$sourceHost:$sourcePort/pools/default/remoteClusters -d name=$target -d hostname=$targetHost:$targetPort -d username=$DEFAULT_ADMIN -d password=$DEFAULT_PW -d encryptionType=half -d demandEncryption=on
	echo ""
}

function createReplicationInternal {
	local sourceID=$1
	local targetID=$2
	local i

	# Under stressed systems, possible that replication creation could fail
	for ((i = 0; $i < 3; i = $(($i + 1)))); do
		replicationID=$($CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${NODEPORTS[$sourceID]}/controller/createReplication -d fromBucket=${BUCKETNAMES[$sourceID]} -d toCluster=${CLUSTERNAMES[$targetID]} -d toBucket=${BUCKETNAMES[$targetID]} -d replicationType=continuous -d checkpointInterval=60 -d statsInterval=500)
		if (($? == 0)); then
			echo "$replicationID"
		elif (($i != 2)); then
			echo "Replication creation returned error code. Will retry in 10 seconds..."
			sleep 10
		fi
	done
}

# Check if jq is present. It is used for parsing JSON in a bash environment
function checkJQ {
	which jq >/dev/null 2>&1
	if (($? != 0)); then
		which brew >/dev/null 2>&1
		if (($? != 0)); then
			return $?
		fi
		echo "jq not found... installing from homebrew"
		brew install jq
		return $?
	fi
	echo $?
}

function getKeyUsingJQ {
	local arg=$1
	local key=$2
	if [[ -z "${arg:-}" ]]; then
		return 1
	fi

	echo $arg | jq ${key} 2>/dev/null
}

#Input:
# 1 - source cluster
# 2 - source bucketname
# 3 - target cluster
# 4 - target bucketname
# TODO - optional args for replication
function createBucketReplication {
	local sourceCluster=$1
	local sourceBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local -a replProperties=$5
	local i

	if [[ -z "${sourceCluster:-}" ]] || [[ -z "${sourceBucket:-}" ]] || [[ -z "${targetCluster:-}" ]] || [[ -z "${targetBucket:-}" ]] || [[ -z "${replProperties}" ]]; then
		echo "Invalid input"
		return 1
	fi

	insertPropertyIntoBucketReplPropertyMap $sourceCluster $sourceBucket $targetCluster $targetBucket $replProperties
	getPropertiesFromBucketReplPropertyMap $sourceCluster $sourceBucket $targetCluster $targetBucket

	local sourcePort=${CLUSTER_NAME_PORT_MAP[$sourceCluster]:-}
	local sourceHost=${CLUSTER_NAME_HOST_MAP[$sourceCluster]:-"127.0.0.1"}
	getBucketReplPropertiesRESTString

	for ((i = 0; $i < 3; i = $(($i + 1)))); do
		repId=$($CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://$sourceHost:$sourcePort/controller/createReplication -d fromBucket=$sourceBucket -d toCluster=$targetCluster -d toBucket=$targetBucket "${getBucketReplOutArr[@]}")
		if (((($? == 0)) && (($(echo "$repId" | grep -c error) == 0)) && (($(echo "$repId" | grep -c "kv vb map is empty") == 0)) && (($(echo "$repId" | grep -c "Unable to send to the following nodes") == 0)))); then
			if (($(checkJQ) == 0)); then
				repIdReal=$(getKeyUsingJQ "$repId" '.id')
				if [[ "$repIdReal" == "" ]]; then
					echo "Captured replicationID: $repId"
				else
					restFriendlyReplID=$(echo $repIdReal | sed 's|/|%2F|g')
					echo "ReplicationID: $repIdReal Rest-FriendlyID: $restFriendlyReplID"
					insertBucketReplIntoExportMap "$sourceCluster" "$sourceBucket" "$targetCluster" "$targetBucket" "$restFriendlyReplID"
				fi
			else
				echo "Captured replicationID: $repId"
			fi
			return 0
		elif (($i != 2)); then
			echo "Replication creation returned error code. Will retry in 10 seconds..."
			sleep 10
		fi
	done
	return 1
}

function cleanupRemoteClusterRefs {
	for replKey in "${!BUCKET_REPL_EXPORT_MAP[@]}"; do
		local sourceCluster=$(echo "$replKey" | cut -d, -f1)
		local sourceHost=${CLUSTER_NAME_HOST_MAP[$sourceCluster]:-"127.0.0.1"}
		local sourcePort=${CLUSTER_NAME_PORT_MAP[$sourceCluster]:-}
		local targetCluster=$(echo "$replKey" | cut -d, -f3)

		echo "Deleting remote cluster reference $targetCluster on cluster $sourceCluster"
		$CURL -X DELETE -u $DEFAULT_ADMIN:$DEFAULT_PW http://$sourceHost:$sourcePort/pools/default/remoteClusters/$targetCluster >/dev/null 2>&1
	done
}

function deleteBucketReplication {
	local sourceClusterReq=$1
	local sourceBucketReq=$2
	local targetClusterReq=$3
	local targetBucketReq=$4

	for replKey in "${!BUCKET_REPL_EXPORT_MAP[@]}"; do
		local sourceCluster=$(echo "$replKey" | cut -d, -f1)
		local restID=$(echo "${BUCKET_REPL_EXPORT_MAP[$replKey]}" | sed 's/"//g')
		local sourceHost=${CLUSTER_NAME_HOST_MAP[$sourceCluster]:-"127.0.0.1"}
		local sourcePort=${CLUSTER_NAME_PORT_MAP[$sourceCluster]:-}
		local sourceBucket=$(echo "$replKey" | cut -d, -f2)
		local targetCluster=$(echo "$replKey" | cut -d, -f3)
		local targetBucket=$(echo "$replKey" | cut -d, -f4)

		if [[ "$sourceCluster" == "$sourceClusterReq" ]] && [[ "$sourceBucket" == "$sourceBucketReq" ]] &&
			[[ "$targetCluster" == "$targetClusterReq" ]] && [[ "$targetBucket" == "$targetBucketReq" ]]; then
			echo "DELETING replication from sourceCluster $sourceCluster sourceBucket $sourceBucket to targetCluster $targetCluster targetBucket $targetBucket..."
			$CURL -X DELETE -u $DEFAULT_ADMIN:$DEFAULT_PW http://$sourceHost:$sourcePort/controller/cancelXDCR/${restID} >/dev/null 2>&1
			return
		fi
	done

	echo "Unable to find replication from exported data to delete $sourceClusterReq $sourceBucketReq to $targetClusterReq $targetBucketReq"
	exit 1
}

function cleanupBucketReplications {
	# Certain functions only exist under test library
	[[ $(type -t killAllBgJobs) == function ]] && killAllBgJobs

	for replKey in "${!BUCKET_REPL_EXPORT_MAP[@]}"; do
		local sourceCluster=$(echo "$replKey" | cut -d, -f1)
		local restID=$(echo "${BUCKET_REPL_EXPORT_MAP[$replKey]}" | sed 's/"//g')
		local sourceHost=${CLUSTER_NAME_HOST_MAP[$sourceCluster]:-"127.0.0.1"}
		local sourcePort=${CLUSTER_NAME_PORT_MAP[$sourceCluster]:-}
		local sourceBucket=$(echo "$replKey" | cut -d, -f2)
		local targetCluster=$(echo "$replKey" | cut -d, -f3)
		local targetBucket=$(echo "$replKey" | cut -d, -f4)

		if [[ $(type -t waitForOneReplicationToBeDeleted) == function ]]; then
			waitForOneReplicationToBeDeleted "$sourceCluster" "$sourceBucket" "$targetBucket" &
			sleep 2
		fi
		echo "DELETING replication from sourceCluster $sourceCluster sourceBucket $sourceBucket to targetCluster $targetCluster targetBucket $targetBucket..."
		$CURL -X DELETE -u $DEFAULT_ADMIN:$DEFAULT_PW http://$sourceHost:$sourcePort/controller/cancelXDCR/${restID} >/dev/null 2>&1
	done
	[[ $(type -t waitForBgJobs) == function ]] && waitForBgJobs
}

function findCbDocLoader {
	if [[ ! -z "${CBDOCLOADER:-}" ]]; then
		echo "$CBDOCLOADER"
		return 0
	fi

	which locate >/dev/null 2>&1
	if (($? != 0)); then
		return $?
	fi
	# Just pick one
	docloader=$(locate cbdocloader | grep install | grep bin | head -n 1)
	if (($? != 0)); then
		echo ""
		return 1
	fi
	if [[ -z "${CBDOCLOADER:-}" ]]; then
		# set it in case needed it in future
		export CBDOCLOADER=$docloader
	fi
	echo "$docloader"
	return 0

}

function findCbimport {
	if [[ ! -z "${CBIMPORT:-}" ]]; then
		echo "$CBIMPORT"
		return 0
	fi

	local cbimport
	local command=locate

	# need to have locate or mdfind
	which locate >/dev/null 2>&1
	if (($? != 0)); then
		# locate is not present, use mdfind
		which mdfind >/dev/null 2>&1
		if (($? != 0)); then
			# mdfind also not present
			echo "locate or mdfind not found"
			return $?
		fi

		# use mdfind instead of locate
		command=mdfind
	fi

	cbimport=$($command cbimport | grep install | grep bin | head -n 1)
	if (($? != 0)); then
		echo ""
		return 1
	fi

	# there may be cases where locate database isn't updated yet, try using mdfind
	if [[ -z "${cbimport:-}" && "$command" == "locate" ]]; then
		cbimport=$(mdfind cbimport | grep install | grep bin | head -n 1)
		if (($? != 0)); then
			echo ""
			return 1
		fi
	fi
	echo "$cbimport"

	if [[ -z "${CBIMPORT:-}" ]]; then
		# set it in case needed it in future
		export CBIMPORT=$cbimport
	fi
	return 0
}

#Input
# 1 - cluster name
# 2 - bucket name
# 3 - file name
# cbdocloader is deprecated. Use runCbimport instead
function runDocLoader {
	local clusterName=$1
	local bucketName=$2
	local fileName=$3
	if [[ -z "${clusterName:-}" ]] || [[ -z "${bucketName:-}" ]] || [[ -z "${fileName:-}" ]]; then
		echo "Invalid input"
		return 1
	fi
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	docLoader=$(findCbDocLoader)
	if (($? != 0)); then
		echo "Could not find docLoader"
		return 1
	fi

	getPropertiesFromBucketNamePropertyMap "$bucketName"
	local ramQuota=${BUCKET_PROPERTIES_OUTPUT_MAP["ramQuotaMB"]:-}
	if [[ -z "$ramQuota" ]]; then
		echo "Missing ramQuota for $bucketName"
		return 1
	fi

	local retCode=1
	while (($retCode > 0)); do
		Echo "Executing cbdocloader on bucket $bucketName for file $fileName..."
		$docLoader -c localhost:${port} -u $DEFAULT_ADMIN -p $DEFAULT_PW -b $bucketName -m $ramQuota -d $fileName
		retCode=$?
	done
}

#Input
# 1 - cluster name
# 2 - bucket name
# 3 - file name
function runCbimport {
	local clusterName=$1
	local bucketName=$2
	local fileName=$3
	if [[ -z "${clusterName:-}" ]] || [[ -z "${bucketName:-}" ]] || [[ -z "${fileName:-}" ]]; then
		echo "Invalid input"
		return 1
	fi
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	cbimport=$(findCbimport)
	if (($? != 0)); then
		echo "Could not find cbimport"
		return 1
	fi

	local retCode=1
	while (($retCode > 0)); do
		Echo "Executing cbimport on bucket $bucketName for file $fileName..."
		$cbimport json -f sample -b $bucketName -c localhost:${port} -u $DEFAULT_ADMIN -p $DEFAULT_PW -d $fileName
		retCode=$?
	done
}

function findCbWorkloadGen {
	if [[ ! -z "${CBWORKLOADGEN:-}" ]]; then
		echo "$CBWORKLOADGEN"
		return 0
	fi

	local -i count
	local path=$(pwd)
	local cbworkloadgenBin="cbworkloadgen"
	local findResult
	local workloadGen

	while [[ "$path" != "/" ]]; do
		findResult=$(find $path -name "${cbworkloadgenBin}")
		count=$(echo "$findResult" | grep -c .)
		if (($count > 0)); then
			workloadGen=$(echo "$findResult" | grep "${cbworkloadgenBin}$" | grep -e "build" -e "install" -e "bin" | head -n 1)
			if [[ -z "$CBWORKLOADGEN" ]]; then
				# set it in case needed it in future
				CBWORKLOADGEN=$workloadGen
			fi
			echo "$workloadGen"
			return 0
		fi
		path=$(dirname "$path")
	done
	echo ""
	return 1
}

# Input
# 1 - cluster name
# 2 - bucket name
function runCbWorkloadGenBucket {
	local clusterName=$1
	local bucketName=$2
	local numItems="${3:-10000}"
	local prefix="${4:-xdcrProv_$clusterName}"
	local i
	if [[ -z "${clusterName:-}" ]] || [[ -z "${bucketName:-}" ]]; then
		echo "Invalid input"
		return 1
	fi

	if [[ ! -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
		vagrantRunCBWorkloadGenBucket "$clusterName" "$bucketName" "$numItems" "$prefix"
		return
	fi

	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	workloadGen=$(findCbWorkloadGen)
	if (($? != 0)) || [[ -z "$workloadGen" ]]; then
		echo "Could not find workload generator binary"
		return 1
	fi

	for ((i = 0; i < 3; i = $(($i + 1)))); do
		echo "Running cbworkloadGen on $clusterName bucket $bucketName"
		# Run json documents with set/get ratio of 100%
		echo $workloadGen -i $numItems -j -r 1 -n 127.0.0.1:$port -b $bucketName -u $DEFAULT_ADMIN -p $DEFAULT_PW --prefix=$prefix
		$workloadGen -i $numItems -j -r 1 -n 127.0.0.1:$port -b $bucketName -u $DEFAULT_ADMIN -p $DEFAULT_PW --prefix=$prefix
		if (($? == 0)); then
			return 0
		elif (($? != 0)) && (($i != 2)); then
			echo "Workloadgen resulted in error. Possibly system is loaded. Retry in 10 seconds"
			sleep 10
		fi
	done
}

# Very basic way of validation - given a target cluster, simply write the same docs naming convention as the target document
# If the doc count hasn't increased, then the keys are replicated correctly
function validateCbWorkloadGenCollection {
	local validateCluster=$1
	local validateBucket=$2
	local validateScope=$3
	local validateCollection=$4

	local clusterName=$5
	local bucketName=$6
	local scopeName=$7
	local collectionName=$8
	local additionalPrefix${9:-}

	if [[ -z "${clusterName:-}" ]] || [[ -z "${bucketName:-}" ]] || [[ -z "${scopeName:-}" ]] || [[ -z "${collectionName:-}" ]] ||
		[[ -z "${validateCluster:-}" ]] || [[ -z "${validateBucket:-}" ]] || [[ -z "${validateScope:-}" ]] || [[ -z "${validateCollection:-}" ]]; then
		echo "Invalid input"
		return 1
	fi

	local port=${CLUSTER_NAME_PORT_MAP[$validateCluster]:-}
	workloadGen=$(findCbWorkloadGen)
	if (($? != 0)) || [[ -z "$workloadGen" ]]; then
		echo "Could not find workload generator binary"
		return 1
	fi

	manifestOutput=$(getManifest $validateCluster $validateBucket)
	if (($? != 0)); then
		echo "Error retrieving manifest for cluster $validateCluster bucket $validateBucket"
		return 1
	fi

	collectionId=$(getCollectionIdFromScopeAndCollectionName "$manifestOutput" "$validateScope" "$validateCollection")
	if (($? != 0)); then
		echo "Error retrieving collection ID for scope $validateScope collection $validateCollection"
		echo "Output: $manifestOutput"
		return 1
	fi

	local prefix
	local colIdHex
	for ((i = 0; i < 3; i = $(($i + 1)))); do
		echo "Validating on $validateCluster $validateBucket $validateScope $validateCollection by running same name as it was on $clusterName"
		prefix=xdcrProv_$clusterName
		if [[ ! -z "${additionalPrefix:-}" ]]; then
			prefix=${prefix}_${additionalPrefix}
		fi
		# Run 10000 items of json documents with set/get ratio of 100%
		echo "Running cbworkloadGen on port $port bucket $validateBucket collectionId $collectionId"
		colIdHex=$(printf '%x' $collectionId)
		if [[ ! -z "${VAGRANT_VM_IP_MAP[$validateCluster]:-}" ]]; then
			vagrantRunCBWorkloadGenCollection "$validateCluster" "$validateBucket" "$prefix" "$colIdHex"
			return $?
		else
			echo "$validateCluster not found and running traditional workloadgen"
			$workloadGen -i $CBWORKLOAD_COLLECTION_NUM_ITEMS -j -r 1 -n 127.0.0.1:$port -b $validateBucket -u $DEFAULT_ADMIN -p $DEFAULT_PW --prefix=$prefix -c $colIdHex
			if (($? == 0)); then
				return 0
			elif (($? != 0)) && (($i != 2)); then
				echo "Workloadgen resulted in error. Possibly system is loaded. Retry in 10 seconds"
				sleep 10
			fi
		fi
	done
}

CONTINUOUS_WORKLOAD_PREFIX="_xdcr_continuous_workload"

function runCbWorkloadGenCollection {
	local clusterName=$1
	local bucketName=$2
	local scopeName=$3
	local collectionName=$4
	local additionalPrefix=${5:-}
	local collectionId
	local i
	local loopFlag=""

	if [[ -z "${clusterName:-}" ]] || [[ -z "${bucketName:-}" ]] || [[ -z "${scopeName:-}" ]] || [[ -z "${collectionName:-}" ]]; then
		echo "Invalid input"
		return 1
	fi
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	workloadGen=$(findCbWorkloadGen)
	if (($? != 0)) || [[ -z "$workloadGen" ]]; then
		echo "Could not find workload generator binary"
		return 1
	fi

	manifestOutput=$(getManifest $clusterName $bucketName)
	if (($? != 0)); then
		echo "Error retrieving manifest for cluster $clusterName bucket $bucketName"
		return 1
	fi

	collectionId=$(getCollectionIdFromScopeAndCollectionName "$manifestOutput" "$scopeName" "$collectionName")
	if (($? != 0)); then
		echo "Error retrieving collection ID for scope $scopeName collection $collectionName"
		echo "Output: $manifestOutput"
		return 1
	fi

	local prefix
	local colIdHex
	for ((i = 0; i < 3; i = $(($i + 1)))); do
		echo "Running cbworkloadGen on $clusterName bucket $bucketName scope: $scopeName collection $collectionName (ID: $collectionId)"
		prefix=xdcrProv_$clusterName
		colIdHex=$(printf '%x' $collectionId)
		if [[ ! -z "$additionalPrefix" ]]; then
			prefix=${prefix}_${additionalPrefix}
			if [[ "$additionalPrefix" == "$CONTINUOUS_WORKLOAD_PREFIX" ]]; then
				echo "LOOPFLAG"
				loopFlag="-l"
			fi
		fi
		# Run 10000 items of json documents with set/get ratio of 100%
		if [[ ! -z "${VAGRANT_VM_IP_MAP[$clusterName]:-}" ]]; then
			vagrantRunCBWorkloadGenCollection "$clusterName" "$bucketName" "$prefix" "$colIdHex"
			return $?
		else
			$workloadGen -i $CBWORKLOAD_COLLECTION_NUM_ITEMS -j -r 1 -n 127.0.0.1:$port -b $bucketName -u $DEFAULT_ADMIN -p $DEFAULT_PW --prefix=$prefix -c $colIdHex "$loopFlag"
			if (($? == 0)); then
				return 0
			elif (($? != 0)) && (($i != 2)); then
				echo "Workloadgen resulted in error. Possibly system is loaded. Retry in 10 seconds"
				sleep 10
			fi
		fi
	done
}

function runCbWorkloadGenCollectionCont {
	local clusterName=$1
	local bucketName=$2
	local scopeName=$3
	local collectionName=$4

	# hacky - specially named prefix
	runCbWorkloadGenCollection "$clusterName" "$bucketName" "$scopeName" "$collectionName" "$CONTINUOUS_WORKLOAD_PREFIX"
}

function waitForBgJobs {
	echo "Waiting for background jobs to finish..."
	local jobsCnt=$(jobs -l | grep -c "Running")
	while (($jobsCnt > 0)); do
		sleep 1
		jobsCnt=$(jobs -l | grep -c "Running")
	done
}

function stopWhenAnyBgJobStops {
	local totalBgJobs=$1
	local jobsCnt=$(jobs -l | grep -c "Running")
	while (($jobsCnt == $totalBgJobs)); do
		jobsCnt=$(jobs -l | grep -c "Running")
		sleep 3
	done
	exit 0
}

# Input: 1. clusterName
#        2. bucketName
function getManifest {
	local clusterName="$1"
	local bucketName="$2"
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	if [[ -z "${port:-}" ]]; then
		echo ""
		return 1
	fi

	$CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X GET http://localhost:$port/$POOLS_DEFAULT_BUCKETS_PATH/$bucketName/scopes
}

# Called hexString because input is in a form of double quoted string
# Also converts them to upper case because bc only takes A-F for hex
function hexStringToDec {
	local hexString=$1
	local hex=$(echo "$hexString" | sed 's/"//g' | tr '[:lower:]' '[:upper:]')

	echo "obase=10; ibase=16; $hex" | bc
}

function prettyPrintManifest {
	local manifest=$1
	local i

	# get manifest version
	local manifestVersion=$(echo "$manifest" | jq '.uid')
	local manifestVersionDec=$(hexStringToDec $manifestVersion)
	echo "Manifest version $manifestVersionDec"

	#get all the scopes
	local scopesList=$(echo "$manifest" | jq '.scopes')
	local scopesListLen=$(echo "$manifest" | jq '.scopes | length')

	for ((i = 0; $i < $scopesListLen; i = $(($i + 1)))); do
		local scopeOutput=$(echo "$scopesList" | jq .[$i])
		local scopeName=$(echo "$scopeOutput" | jq '.name')
		local scopeUID=$(echo "$scopeOutput" | jq '.uid')
		local scopeUIDdec=$(hexStringToDec "$scopeUID")
		echo "ScopeName $scopeName (UID $scopeUIDdec)"

		# Get individual collections within this scope
		local collectionsList=$(echo "$scopeOutput" | jq '.collections')
		local collectionsListLen=$(echo "$scopeOutput" | jq '.collections | length')
		for ((j = 0; $j < $collectionsListLen; j = $(($j + 1)))); do
			local collectionsOutput=$(echo "$collectionsList" | jq .[$j])
			local collectionName=$(echo "$collectionsOutput" | jq '.name')
			local collectionUID=$(echo "$collectionsOutput" | jq '.uid')
			local collectionUIDdec=$(hexStringToDec "$collectionUID")
			echo "ScopeName $scopeName CollectionName $collectionName (UID $collectionUIDdec)"
		done
	done
}

# Returns non-0 if not found
function getCollectionIdFromScopeAndCollectionName {
	local manifest=$1
	local requestedScopeName=$2
	local requestedCollectionName=$3
	local i

	local scopesList=$(echo "$manifest" | jq '.scopes')
	local scopesListLen=$(echo "$manifest" | jq '.scopes | length')

	for ((i = 0; $i < $scopesListLen; i = $(($i + 1)))); do
		local scopeOutput=$(echo "$scopesList" | jq .[$i])
		# Requested doesn't have double quotes, but manifest output does
		local scopeName=$(echo "$scopeOutput" | jq '.name' | sed 's/"//g')
		if [[ "$scopeName" == "$requestedScopeName" ]]; then
			local collectionsList=$(echo "$scopeOutput" | jq '.collections')
			local collectionsListLen=$(echo "$scopeOutput" | jq '.collections | length')
			for ((j = 0; $j < $collectionsListLen; j = $(($j + 1)))); do
				local collectionsOutput=$(echo "$collectionsList" | jq .[$j])
				# Requested doesn't have double quotes, but manifest output does
				local collectionName=$(echo "$collectionsOutput" | jq '.name' | sed 's/"//g')
				local collectionUID=$(echo "$collectionsOutput" | jq '.uid')
				local collectionUIDdec=$(hexStringToDec "$collectionUID")
				if [[ "$collectionName" == "$requestedCollectionName" ]]; then
					echo "$collectionUIDdec"
					return 0
				fi
			done
		fi
	done

	# Not found
	echo ""
	return 1
}

function printSingleClusterBucketScopeAndCollection {
	local clusterName=$1
	local bucketName=$2

	# Get the manifest for this bucket
	local manifestOutput=""
	local manifestVersion=""
	manifestOutput=$(getManifest $clusterName $bucketName)
	if (($? != 0)); then
		echo "Error retrieving manifest - Cluster $clusterName bucket $bucketName scope $scopeName"
		return
	elif [[ -z "$manifestOutput" ]]; then
		echo "Retrieved empty manifest JSON - Cluster $clusterName bucket $bucketName scope $scopeName"
		return
	fi

	manifestVersion=$(echo "$manifestOutput" | jq '.uid')
	echo "Cluster $clusterName Bucket $bucketName collections manifest version: $manifestVersion"

	prettyPrintManifest "$manifestOutput"
}

# Print a summary of all the topology setup -> scope and collection info
# Uses the manifest REST API
function printGlobalScopeAndCollectionInfo {
	if (($(checkJQ) != 0)); then
		echo "jq not found - cannot run $0"
		return 1
	fi

	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
		local -a buckets=(${CLUSTER_NAME_BUCKET_MAP[$clusterName]:-})
		for bucketName in $(echo ${buckets[@]}); do
			printSingleClusterBucketScopeAndCollection "$clusterName" "$bucketName"
		done
	done
}

# Stats library
function parseStatsOutput {
	local statsOutput="${1:-}"
	local hostPort=${2:-0}
	local results
	local result
	local keys
	local key
	local checkPort

	# Stats output can be more than one node. Rolling window where last number is the latest:
	# {"samplesCount":60,"isPersistent":true,"lastTStamp":1595364466482,"interval":1000,
	# "timestamp":[1595364456473,1595364457474,1595364458475,1595364459476,1595364460477,1595364461478,1595364462478,1595364463479,1595364464480,1595364465481,1595364466482],
	# "nodeStats":{"127.0.0.1:9000":[7168,1057,0,0,0,0,0,0,0,0,0]}}
	# or
	# '{"samplesCount":60,"isPersistent":true,"lastTStamp":1595369104271,"interval":1000,
	# "timestamp":[1595369091258,1595369092259,1595369093260,1595369094261,1595369095262,1595369096263,1595369097264,1595369098265,1595369099266,1595369100267,1595369101268,1595369102269,1595369103270,1595369104271],
	# "nodeStats":{"[::1]:9000":[7168,1799,0,0,0,38,0,0,0,0,0,0,0,0]}}'
	# or
	# '{"samplesCount":60,"isPersistent":true,"lastTStamp":1606180623429,"interval":1000,
	# "timestamp":[1606180609415,1606180610416,1606180611417,1606180612418,1606180613419,1606180614420,1606180615421,1606180616422,1606180617423,1606180618424,1606180619425,1606180620426,1606180621427,1606180622428,1606180623429],
	# "nodeStats":{"192.168.1.113:9000":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"[::1]:9001":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}}'

	# results could fail if there is no stats yet, i.e.
	# +++ statsOutput='{"samplesCount":60,"isPersistent":true,"lastTStamp":0,"interval":1000,"timestamp":[],"nodeStats":{"[::1]:9000":[]}}'
	results=$(echo "$statsOutput" | jq ".nodeStats")
	keys=$(echo "$results" | jq keys | jq .[] | sed 's/"//g')
	# 192.168.1.113:9000
	# [::1]:9001

	if [[ ! -z ${VAGRANT_KV_EXTERNAL_MAP[@]:-} ]]; then
		# checkPort will be 8091 and hostPort should also be 8091
		hostPort="8091"
	fi

	for key in $(echo "$keys"); do
		checkPort=$(echo "$key" | rev | cut -d: -f1 | rev)
		if (($checkPort == $hostPort)); then
			# found it
			result=$(echo $results | jq ".[\"$key\"]")
			if [[ -z "${result:-}" || "$result" == "null" ]]; then
				echo ""
				return 1
			fi
			echo "$result" | jq '.[-1]'
			return 0
		fi
	done
}

# Gets the last reading of the stats output
function getStats {
	local srcClusterName=$1
	local srcBucketName=$2
	local targetClusterName=$3
	local targetBucketName=$4
	local statsName=$5
	local result

	restId=$(getRestIDFromExportedData "$srcClusterName" "$srcBucketName" "$targetClusterName" "$targetBucketName")
	if (($? != 0)); then
		return $?
	fi

	local port=${CLUSTER_NAME_PORT_MAP[$srcClusterName]}
	local host=${CLUSTER_NAME_HOST_MAP[$srcClusterName]:-"127.0.0.1"}
	if (($(checkJQ) != 0)); then
		return 1
	fi
	local curlResult=1
	local parseResult=1
	local counter=0
	local result
	statsOutput=$($CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X GET http://$host:$port/$POOLS_DEFAULT_BUCKETS_PATH/$srcBucketName/stats/replications%2F${restId}%2F${statsName})
	curlResult=$?
	if (($curlResult == 0)); then
		result=$(parseStatsOutput "$statsOutput" "$port")
		parseResult=$?
	fi

	while (((((($curlResult != 0)) || (($parseResult != 0)))) && (($counter < $REST_MAX_RETRY)))); do
		counter=$(($counter + 1))
		sleep 5
		statsOutput=$($CURL -u $DEFAULT_ADMIN:$DEFAULT_PW -X GET http://$host:$port/$POOLS_DEFAULT_BUCKETS_PATH/$srcBucketName/stats/replications%2F${restId}%2F${statsName})

		curlResult=$?
		if (($curlResult == 0)); then
			result=$(parseStatsOutput "$statsOutput" "$port")
			parseResult=$?
		fi
	done
	echo "$result"
}

function isReplicationPaused {
	local srcClusterName=$1
	local srcBucketName=$2
	local targetClusterName=$3
	local targetBucketName=$4
	local pauseRequested

	restID=$(getBucketReplicationRestID "$srcClusterName" "$srcBucketName" "$targetClusterName" "$targetBucketName")
	if (($? != 0)); then
		echo "Unable to find REST ID"
		return 1
	fi
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$srcClusterName]:-}
	if [[ -z "$sourcePort" ]]; then
		echo "Unable to find admin port for cluster $srcClusterName"
		return 1
	fi

	pauseRequested=$($CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${sourcePort}/settings/replications/${restID} | jq '.pauseRequested')
	if (($(echo "$pauseRequested" | grep -ic "true") > 0)); then
		return 1
	else
		return 0
	fi
}

function pauseReplication {
	local srcClusterName=$1
	local srcBucketName=$2
	local targetClusterName=$3
	local targetBucketName=$4

	restID=$(getBucketReplicationRestID "$srcClusterName" "$srcBucketName" "$targetClusterName" "$targetBucketName")
	if (($? != 0)); then
		echo "Unable to find REST ID"
		return 1
	fi
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$srcClusterName]:-}
	if [[ -z "$sourcePort" ]]; then
		echo "Unable to find admin port for cluster $srcClusterName"
		return 1
	fi

	echo "Pausing replication $restID"
	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${sourcePort}/settings/replications/${restID} -d pauseRequested=true >/dev/null 2>&1
}

function resumeReplication {
	local srcClusterName=$1
	local srcBucketName=$2
	local targetClusterName=$3
	local targetBucketName=$4

	restID=$(getBucketReplicationRestID "$srcClusterName" "$srcBucketName" "$targetClusterName" "$targetBucketName")
	if (($? != 0)); then
		echo "Unable to find REST ID"
		return 1
	fi
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$srcClusterName]:-}
	if [[ -z "$sourcePort" ]]; then
		echo "Unable to find admin port for cluster $srcClusterName"
		return 1
	fi

	local encryptionLevel=${CLUSTER_ENCRYPTION_LEVEL_MAP[$srcClusterName]:-}
	if [[ "$encryptionLevel" == "strict" ]]; then
		local replicatorId=$(echo "$restID" | sed 's|%2F|/|g')
		echo "Resuming replication $restID using CLI"
		$CB_CLI_BIN xdcr-replicate --resume -c 127.0.0.1:${sourcePort} -u $DEFAULT_ADMIN -p $DEFAULT_PW --xdcr-replicator $replicatorId
	else
		echo "Resuming replication $restID"
		$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${sourcePort}/settings/replications/${restID} -d pauseRequested=false >/dev/null 2>&1
	fi
}

declare INTERNAL_SETTINGS_REST_PATH="xdcr/internalSettings"

function listInternalSettings {
	local clusterName=$1
	local jqStr
	jqLocation=$(which jq)
	if (($? == 0)); then
		jqStr="$jqLocation"
	fi
	importProvisionedConfig

	local port=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid depedentClusterName $clusterName"
		return 1
	fi

	if [[ ! -z "$jqStr" ]]; then
		$CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/$INTERNAL_SETTINGS_REST_PATH | $jqLocation
	else
		$CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/$INTERNAL_SETTINGS_REST_PATH
	fi
}

function setInternalSettingsWithoutImport {
	local clusterName=$1
	local -a keyVal=("${@:2}")

	local jqStr
	jqLocation=$(which jq)
	if (($? == 0)); then
		jqStr="$jqLocation"
	fi

	local port=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	# Because to do multiple -d keyvals, it's better to pass in a single array
	local -a curlMultiArr
	for kv in "${keyVal[@]}"; do
		curlMultiArr+=(" -d ")
		curlMultiArr+=("$kv")
	done

	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/$INTERNAL_SETTINGS_REST_PATH ${curlMultiArr[@]} >/dev/null 2>&1
}

function setInternalSettings {
	local clusterName=$1
	local -a keyVal=("${@:2}")

	local jqStr
	jqLocation=$(which jq)
	if (($? == 0)); then
		jqStr="$jqLocation"
	fi
	importProvisionedConfig

	local port=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	# After 7.1, the XDCR internal settings is now able to be handled by the ns_server
	# so the XDCR port forwarding isn't needed anymore for vagrant
	# For now, assume toy is 7.1 or above
	local vagrantVersion
	local majorVersion
	local minorVersion
	if [[ ! -z ${VAGRANT_VERSION_MAP[$clusterName]:-} ]]; then
		vagrantVersion="${VAGRANT_VERSION_MAP[$clusterName]}"
		if [[ "$vagrantVersion" == "toy" ]]; then
			port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
		elif [[ "$vagrantVersion" =~ ([7-9])\.([1-9]) ]]; then
			port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
		fi
	fi

	if [[ -z "$port" ]]; then
		echo "Invalid depedentClusterName $clusterName"
		return 1
	fi

	# Because to do multiple -d keyvals, it's better to pass in a single array
	local -a curlMultiArr
	for kv in "${keyVal[@]}"; do
		curlMultiArr+=(" -d ")
		curlMultiArr+=("$kv")
	done

	local i=0
	for ((i = 0; $i < 3; i = $(($i + 1)))); do
		$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/$INTERNAL_SETTINGS_REST_PATH ${curlMultiArr[@]} >/dev/null 2>&1
		if (($? == 0)); then
			break
		fi
	done
}

# Gets one setting
function getInternalSetting {
	local clusterName=$1
	local settingKey=$2

	local port=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid depedentClusterName $clusterName"
		return 1
	fi

	local result=1
	local output
	while (($result != 0)); do
		output=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/$INTERNAL_SETTINGS_REST_PATH | jq ".$settingKey")
		if (($? == 0)) && [[ ! -z "${output:-}" ]]; then
			result=0
			echo "$output"
		fi
	done
}

function getClusterLogs {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid depedentClusterName $clusterName"
		return 1
	fi

	$CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/diag 2>&1
}

# 1. Node ID's log to get
# 2. Cluster name to look for
function getClusterUuidUsingNameFromLogs {
	local logNodeName=$1
	local clusterName=$2

	local logs
	logs=$(getInternalNodeXdcrLog "$logNodeName")
	if ! (($? == 0)); then
		# echo "Unable to get log for validation"
		return 1
	fi

	local clusterCbStrings
	clusterCbStrings=$(echo "$logs" | grep "remoteClusterChangedCallback called on id")
	local oneLine
	local OLDIFS="$IFS"
	IFS=$'\n'
	for oneLine in $(echo "$clusterCbStrings"); do
		if [[ "$oneLine" =~ name:${clusterName} ]]; then
			if [[ "$oneLine" =~ uuid:([[:alnum:]]+) ]]; then
				echo ${BASH_REMATCH[1]}
				IFS="$OLDIFS"
				return 0
			fi
		fi
	done
	IFS="$OLDIFS"
	return 2
}

# 1. Node log to be looking for
# 2. ClusterName
# 3. Source Bucket Name
# 4. Target Bucket Name
function getSetVBTimestampMsgsFromLogs {
	local logNodeName=$1
	local clusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4
	local backfillPipeline=${5:-}

	local clusterUuid
	clusterUuid=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$clusterName")
	local retVal=$?
	if ((!$retVal == 0)); then
		echo "Unable to get clusterUUID with return code $retVal"
		return 1
	fi

	if [[ -z "${backfillPipeline:-}" ]]; then
		getInternalNodeXdcrLog "$logNodeName" | grep "${clusterUuid}/${srcBucketName}/${tgtBucketName}" | grep -v "backfill" | grep "Set VBTimestamp"
	else
		getInternalNodeXdcrLog "$logNodeName" | grep "backfill_${clusterUuid}/${srcBucketName}/${tgtBucketName}" | grep "Set VBTimestamp"
	fi
}

# Usage: Grep "Set VBTimestamp" from the logs and then pass to this function via pipe
function parseSetVBTimestamps {
	local -A VbSeqnoMap
	local input
	local OLDIFS="$IFS"
	input=$(cat)
	IFS=$'\n'
	for oneLine in $(echo "$input"); do
		local vb=$(echo "$oneLine" | awk '{print $7}' | sed 's/,//g' | sed 's/vb=//g')
		local startingSeqno=$(echo "$oneLine" | awk '{print $8}' | sed 's/,//g' | sed 's/ts.Seqno=//g')
		if [[ -z "$vb" ]] || [[ -z "$startingSeqno" ]]; then
			echo "Unable to parse"
			IFS="$OLDIFS"
			return 1
		fi

		if [[ -z "${VbSeqnoMap["$vb"]:-}" ]]; then
			# First entry
			VbSeqnoMap["$vb"]="$startingSeqno"
		else
			local val="${VbSeqnoMap["$vb"]}"
			local newVal="${val},${startingSeqno}"
			VbSeqnoMap["$vb"]="$newVal"
		fi
	done
	IFS="$OLDIFS"

	# Print
	local i=0
	for ((i = 0; $i < 1024; i = $(($i + 1)))); do
		if [[ ! -z "${VbSeqnoMap["$i"]:-}" ]]; then
			echo "VB $i: ${VbSeqnoMap["$i"]}"
		fi
	done
}

# Usage: Grep "Set VBTimestamp" from the logs and then pass to this function via pipe
function getFirstNon0VB {
	local -A VbSeqnoMap
	local input
	local OLDIFS="$IFS"
	input=$(cat)
	IFS=$'\n'
	for oneLine in $(echo "$input"); do
		local vb=$(echo "$oneLine" | awk '{print $7}' | sed 's/,//g' | sed 's/vb=//g')
		local startingSeqno=$(echo "$oneLine" | awk '{print $8}' | sed 's/,//g' | sed 's/ts.Seqno=//g')
		if [[ -z "$vb" ]] || [[ -z "$startingSeqno" ]]; then
			echo "Unable to parse"
			IFS="$OLDIFS"
			return 1
		fi

		if [[ "$startingSeqno" == 0 ]]; then
			continue
		fi

		# Found a non-0 starting one
		IFS="$OLDIFS"
		echo "$vb"
		return 0
	done
	IFS="$OLDIFS"
	echo "Did not find one"
	return 1
}

function getXDCRCheckpoints {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	checkpointOutput=$($CURL http://localhost:$port/diag/eval -d 'ns_server_testrunner_api:grab_all_goxdcr_checkpoints()' -u $DEFAULT_ADMIN:$DEFAULT_PW)
	if (($? != 0)); then
		return $?
	fi
	echo "$checkpointOutput"
}

# Usage:
# setReplicationSettings <sourceCluster> <sourceBucket> <targetCluster> <targetBucket> <key=value> ...
function setReplicationSettings {
	local sourceCluster=$1
	local sourceBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local -a keyVal=("${@:5}")
	local port=${CLUSTER_NAME_PORT_MAP[$sourceCluster]:-}

	replId=$(getBucketReplicationRestID "$sourceCluster" "$sourceBucket" "$targetCluster" "$targetBucket")
	if ! (($? == 0)); then
		echo "Unable to get replication ID"
		return 1
	fi

	if [[ -z "${port:-}" ]]; then
		echo "Cannot get port number"
		return 1
	fi

	setReplicationSettingsInternal "$replId" "$port" ${keyVal[@]}
}

function setReplicationSettingsInternal {
	local replId=$1
	local port=$2
	local -a keyVal=("${@:3}")
	local jqStr

	# Because to do multiple -d keyvals, it's better to pass in a single array
	local -a curlMultiArr
	for kv in "${keyVal[@]}"; do
		curlMultiArr+=(" -d ")
		curlMultiArr+=("$kv")
	done

	jqLocation=$(which jq)
	if (($? == 0)); then
		jqStr="$jqLocation"
	fi

	if [[ ! -z "${jqStr:-}" ]]; then
		$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${port}/settings/replications/${replId} ${curlMultiArr[@]} | $jqStr
	else
		$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${port}/settings/replications/${replId} ${curlMultiArr[@]}
	fi

}

# Usage:
# getReplicationSettings <sourceCluster> <sourceBucket> <targetCluster> <targetBucket>
function getReplicationSettings {
	local sourceCluster=$1
	local sourceBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local port=${CLUSTER_NAME_PORT_MAP[$sourceCluster]:-}

	replId=$(getBucketReplicationRestID "$sourceCluster" "$sourceBucket" "$targetCluster" "$targetBucket")
	if ! (($? == 0)); then
		echo "Unable to get replication ID"
		return 1
	fi

	if [[ -z "${port:-}" ]]; then
		echo "Cannot get port number"
		return 1
	fi

	getReplicationSettingsInternal "$replId" "$port"
}

function getReplicationSettingsInternal {
	local replId=$1
	local port=$2
	local jqStr

	jqLocation=$(which jq)
	if (($? == 0)); then
		jqStr="$jqLocation"
	fi

	if [[ ! -z "${jqStr:-}" ]]; then
		$CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${port}/settings/replications/${replId} | $jqStr
	else
		$CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${port}/settings/replications/${replId}
	fi

}

function getReplicationInfos {
	local port=$1

	$CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${port}/pools/default/replicationInfos
}

# Users can specify:
# 0. (requestedLevel 0) Cluster only - this will return the eventID for the whole broken map
# 1. (requestedLevel 1) Cluster and sourceScopeName - this will return the eventID for the whole source scope in the broken map
# 2. (requestedLevel 2) 1 + sourceCollectionName - return eventID for the sourceScope.sourceCol
# 3.           2 + targetScope - invalid
# 4. (requestedLevel 3) 2 + targetScope + targetCollectionName - return eventID for a single mapping
#
# Warning: Error condition - if specified entity is not found, calls exit on the script
function getBrokenMapEntryId {
	local cluster=$1
	local sourceScopeName=${2:-}
	local sourceCollectionName=${3:-}
	local targetScopeName=${4:-}
	local targetCollectionName=${5:-}
	local requestedSrcNamespace
	local requestedTgtNamespace
	local returnEventId
	local requestedLevel=0

	# check as target pairs need to be present
	if [[ ! -z "$targetScopeName" ]] || [[ ! -z "$targetCollectionName" ]]; then
		if [[ -z "$targetScopeName" ]] || [[ -z "$targetCollectionName" ]]; then
			echo "Both targets need to be specified if one is specified"
			exit 1
		fi
	fi

	# figure out which level we are diving to
	if [[ ! -z "$sourceScopeName" ]]; then
		requestedLevel=1
		if [[ ! -z "$sourceCollectionName" ]]; then
			requestedLevel=2
			if [[ ! -z "$targetScopeName" ]]; then
				requestedLevel=3
			fi
		fi
	fi

	if (($requestedLevel >= 2)); then
		requestedSrcNamespace=$(echo -n "\"${sourceScopeName}.${sourceCollectionName}\"")
		if (($requestedLevel == 3)); then
			requestedTgtNamespace=$(echo -n "\"${targetScopeName}.${targetCollectionName}\"")
		fi
	fi

	errList=$(getErrorListForMainPipeline $cluster)
	if ((!$? == 0)); then
		echo "Issue getting error list"
		exit 1
	fi

	# ErrorsList contain multiple error events. There should only be one error type event
	local totalErrorsLen=$(echo "$errList" | jq 'length')
	local i
	for ((i = 0; i < $totalErrorsLen; i = $(($i + 1)))); do
		local oneEvent
		local eventType
		local returnEventId
		oneEvent=$(echo "$errList" | jq ".[$i]")
		eventType=$(echo "$oneEvent" | jq '.EventType')
		if ((!eventType == $BROKENEVENT_TYPE)); then
			continue
		fi
		# Found the overall broken map event
		if (($requestedLevel == 0)); then
			returnEventId=$(echo "$oneEvent" | jq '.EventId')
			return $returnEventId
		fi
		local scopesEvents
		scopesEvents=$(echo "$oneEvent" | jq '.EventExtras')
		# First see if the sourceScopeName is found
		local scopesEventsKeys
		scopesEventsKeys=$(echo "$scopesEvents" | jq 'keys[]')
		local scopeEventKey
		for scopeEventKey in $(echo "$scopesEventsKeys"); do
			local scopeEvent
			scopeEvent=$(echo "$scopesEvents" | jq ".[$scopeEventKey]")
			local scopeEventScopeNameWithoutQuotes
			scopeEventScopeNameWithoutQuotes=$(echo "$scopeEvent" | jq '.EventDesc' | sed 's/"//g')
			if [[ ! "$scopeEventScopeNameWithoutQuotes" == "$sourceScopeName" ]]; then
				continue
			fi
			# Found the source scope
			if (($requestedLevel == 1)); then
				returnEventId=$(echo "$scopeEvent" | jq '.EventId')
				return $returnEventId
			fi
			# Now, cycle through each source namespace to find the matching source namespace
			local sourceNamespaces
			local sourceNamespacesKeys
			sourceNamespaces=$(echo "$scopeEvent" | jq '.EventExtras')
			sourceNamespacesKeys=$(echo "$sourceNamespaces" | jq 'keys[]')
			local oneKey
			for oneKey in $(echo "$sourceNamespacesKeys"); do
				local oneSourceNamespace
				oneSourceNamespace=$(echo "$sourceNamespaces" | jq ".[$oneKey]")
				local brokenMapSourceNamespace
				brokenMapSourceNamespace=$(echo "$oneSourceNamespace" | jq '.EventDesc')
				if [[ "$requestedSrcNamespace" == "$brokenMapSourceNamespace" ]]; then
					# Found the source namespace.
					if (($requestedLevel == 2)); then
						returnEventId=$(echo "$oneSourceNamespace" | jq '.EventId')
						return $returnEventId
					fi
					# Now check the target namespace
					local targetNamespaces
					targetNamespaces=$(echo "$oneSourceNamespace" | jq '.EventExtras')
					local targetNamespacesKeys
					targetNamespacesKeys=$(echo "$targetNamespaces" | jq 'keys[]')
					local oneTKey
					for oneTKey in $(echo "$targetNamespacesKeys"); do
						local targetNamespace
						targetNamespace=$(echo "$targetNamespaces" | jq ".[$oneTKey]")
						local brokenMapTargetNamespace
						brokenMapTargetNamespace=$(echo "$targetNamespace" | jq '.EventDesc')
						if [[ "$brokenMapTargetNamespace" == "$requestedTgtNamespace" ]]; then
							# shellcheck disable=SC2001
							returnEventId=$(echo "$oneTKey" | sed 's/"//g')
							echo "Found requested brokenmap of $requestedSrcNamespace -> $requestedTgtNamespace with ID $returnEventId"
							return $returnEventId
						fi
					done
				fi
			done
		done
	done

	echo "Unable to find the matching error event"
	return $GET_BROKEN_MAP_NOT_FOUND
}

function dismissEvent {
	local sourceCluster=$1
	local sourceBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	local sourceScopeName=${5:-}
	local sourceCollectionName=${6:-}
	local targetScopeName=${7:-}
	local targetCollectionName=${8:-}
	local eventID

	getBrokenMapEntryId "$sourceCluster" "$sourceScopeName" "$sourceCollectionName" "$targetScopeName" "$targetCollectionName"
	eventID=$?
	echo "Dismissing event ID: $eventID"

	setReplicationSettings "$sourceCluster" "$sourceBucket" "$targetCluster" "$targetBucket" "dismissEvent=$eventID"
}

# TODO - right now assumes only one outgoing pipeline per cluster
function getErrorListForMainPipeline {
	local clusterName=$1
	local port=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}
	local output
	local mainPipelineErrList

	output=$(getReplicationInfos $port)
	if ((!$? == 0)); then
		echo ""
		return 1
	fi

	if (($(echo "$output" | jq 'length') > 2)); then
		echo "Not valid replicationInfos - seeing more than 2 output"
		return 1
	fi

	mainPipelineErrList=$(echo "$output" | jq '.[0]' | jq '.ErrorList')
	echo "$mainPipelineErrList"
}

function createSecureRemoteClusterReference {
	local source=$1
	local target=$2
	local remoteClusterCert=${3:-}
	if [[ -z "${source:-}" ]] || [[ -z "${target:-}" ]]; then
		echo "Invalid input"
		return 1
	fi
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$source]:-}
	local targetPort=${CLUSTER_NAME_PORT_MAP[$target]:-}
	local targetSecurePort=${CLUSTER_NAME_SECURE_PORT_MAP[$target]:-$targetPort}
	local targetHost="127.0.0.1"

	# special case handling for Vagrant
	if [[ ! -z "${VAGRANT_VM_IP_MAP[$target]:-}" ]]; then
		if [[ -n "${VAGRANT_LB_IP:-}" ]]; then
			# Load balance rin play, use the load balancer IP and custom port
			targetHost=$VAGRANT_LB_IP
			targetSecurePort=${CLUSTER_NAME_SSLPORT_MAP[$target]}
		else
			targetHost="${VAGRANT_VM_IP_MAP[$target]}"
			targetSecurePort="18091"
			# If external is specified, use it
			if [[ -n "${VAGRANT_IP_EXTERNAL_MAP["$target"]:-}" ]]; then
				targetHost="${VAGRANT_IP_EXTERNAL_MAP["$target"]}"
				targetSecurePort="${CLUSTER_NAME_SSLPORT_MAP["$target"]}"
			fi
		fi
	fi

	# See if client cert and keys exist
	local clientCertFile=${CLIENT_CERT_MAP[$target]:-}
	local clientKeyFile=${CLIENT_KEY_MAP[$target]:-}

	# Get the target cluster's root certificate if not provided
	if [[ -z "${remoteClusterCert:-}" ]]; then
		remoteClusterCert=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$targetPort/pools/default/certificate)
	fi

	if [[ -z "${clientCertFile:-}" ]]; then
		echo "Creating SECURE remote cluster reference from $source to $target"
		$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/pools/default/remoteClusters -d name=$target -d hostname=${targetHost}:${targetSecurePort} -d username=$DEFAULT_ADMIN -d password=$DEFAULT_PW \
			-d encryptionType=full -d demandEncryption=1 --data-urlencode "certificate=${remoteClusterCert}"
	else
		echo "Creating SECURE remote cluster reference from $source to $target ($targetHost) using client key $clientKeyFile and cert $clientCertFile"
		local clientKeyData="$(cat $clientKeyFile)"
		local clientCertData="$(cat $clientCertFile)"
		$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/pools/default/remoteClusters -d name=$target -d hostname=${targetHost}:${targetSecurePort} \
			-d encryptionType=full -d demandEncryption=1 --data-urlencode "certificate=${remoteClusterCert}" \
			--data-urlencode "clientKey=${clientKeyData}" --data-urlencode "clientCertificate=${clientCertData}"
	fi

}

function setNodeToNodeEncryption {
	local cluster=$1
	local value=$2
	local port=${CLUSTER_NAME_PORT_MAP[$cluster]:-}

	# turn on encryption:
	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${port}/settings/autoFailover -d enabled=false
	if (($? != 0)); then
		echo "Failed to turn off autoFailover"
		exit $?
	fi
	$CB_CLI_BIN node-to-node-encryption -c http://127.0.0.1:$port -u $DEFAULT_ADMIN -p $DEFAULT_PW --$value
	if (($? != 0)); then
		echo "Failed to set node to node encryption to $value"
		exit $?
	fi
	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:${port}/settings/autoFailover -d enabled=true
	if (($? != 0)); then
		echo "Failed to turn on autoFailover"
		return 1
	fi
	echo "Node to node encryption for $cluster is set to $value" >&1
}

function setEncryptionLevel {
	local cluster=$1
	local value=$2
	local port=${CLUSTER_NAME_PORT_MAP[$cluster]:-}
	# set encryption leval
	$CURL -POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/settings/security -d "clusterEncryptionLevel=$value"
	if (($? != 0)); then
		echo "Failed to set cluster encryption level to $value"
		return 1
	fi
	echo "Encryption level for $cluster is set to $value" >&1
	CLUSTER_ENCRYPTION_LEVEL_MAP[$cluster]="$value"
}

function writeEnabledClientCertJSON {
	local tempFile=$(mktemp)
	echo '{"state": "enable","prefixes": [{"path": "subject.cn","prefix": "","delimiter": ""}]}' >$tempFile
	echo "$tempFile"
}

function writeMandatoryClientCertJSON {
	local tempFile=$(mktemp)
	echo '{
    "state": "mandatory",
    "prefixes": [
      {
        "path": "san.uri",
        "prefix": "www.",
        "delimiter": "."
      },
      {
        "path": "san.email",
        "prefix": "",
        "delimiter": "@"
      }
    ]
  }' >$tempFile
	echo "$tempFile"
}

function writeDisableClientCertJSON {
	local tempFile
	tempFile=$(mktemp)
	echo '{
    "state": "disable",
    "prefixes": [
      {
        "path": "san.uri",
        "prefix": "www.",
        "delimiter": "."
      },
      {
        "path": "san.email",
        "prefix": "",
        "delimiter": "@"
      }
    ]
  }' >$tempFile
	echo "$tempFile"
}

function setMandatoryClientCert {
	local cluster=$1
	local tempFile

	tempFile=$(writeMandatoryClientCertJSON)
	executeClientCertAuth "$cluster" "$tempFile"
}

function setEnableClientCert {
	local cluster=$1
	local tempFile

	tempFile=$(writeEnabledClientCertJSON)
	executeClientCertAuth "$cluster" "$tempFile"
}

function setDisableClientCert {
	local cluster=$1
	local tempFile=$(writeDisableClientCertJSON)

	executeClientCertAuth "$cluster" "$tempFile"
}

function executeClientCertAuth {
	local clusterName=$1
	local tempFile=$2
	local vagrantTempFile="/tmp/clientCertAuthTmp"
	local port=${CLUSTER_NAME_PORT_MAP[$cluster]:-}
	local idx

	if [[ -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
		$CURL -X POST http://127.0.0.1:${port}/settings/clientCertAuth --data-binary @${tempFile} -u $DEFAULT_ADMIN:$DEFAULT_PW
	else
		# First load tempfile to the cluster
		idx="$(getClusterIdx "$clusterName")"
		vscp "$idx" "$tempFile" "$vagrantTempFile"
		${VSSH[$idx]} "curl -X POST http://127.0.0.1:8091/settings/clientCertAuth --data-binary @${vagrantTempFile} -u $DEFAULT_ADMIN:$DEFAULT_PW"
	fi
}

function getPrometheusStats {
	local clusterName=$1
	local port=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}
	local output

	output=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/_prometheusMetrics | grep -v \#)
	echo "$output"
}

function enableDcpOsoBackfill {
	local clusterName=$1
	local bucketName=$2
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	$CURL -i -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://localhost:$port/diag/eval \
		--data "ns_bucket:update_bucket_props(\"$bucketName\", [{extra_config_string, \"dcp_oso_backfill=enabled\"}])"
}

function getSpecificStatFromPrometheus {
	local clusterName=$1
	local sourceBucketName=$2
	local statName=$3
	local port=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	# get the next word after regex match
	statVal=$($CURL -X GET http://localhost:$port/_prometheusMetrics -u $DEFAULT_ADMIN:$DEFAULT_PW |
		grep "sourceBucketName=\"${sourceBucketName}\"" |
		awk -v regex=$statName+".*Main.*} " 'BEGIN{FS=regex}{if ($2!="") print $2}')
	echo $statVal
}

function checkResidentRatioGuardrail {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local output

	output=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/$RR_REST)
	echo "output is $output"
	if [[ "$output" =~ Operation\ not\ allowed ]]; then
		echo "This test needs to be run with 'cluster_run --provisioned'"
		exit 1
	fi
}

# Input Minimum is an integer in percentage, min of 1
function setResidentRatioGuardRailCouchStoreMin {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local minimum=$2

	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/$RR_REST -d couchstoreMinimum="$minimum"
}

function enableInternalResidentRatioGuardrail {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local bucket=$2

	$CURL -v -s -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/diag/eval -d "ns_memcached:set_data_ingress(\"${bucket}\", resident_ratio)."
}

function disableInternalResidentRatioGuardrail {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local bucket=$2

	$CURL -v -s -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/diag/eval -d "ns_memcached:set_data_ingress(\"${bucket}\", ok)."
}
