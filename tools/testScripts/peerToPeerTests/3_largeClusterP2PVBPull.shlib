# Copyright 2019-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# =============================
# topological map information
# =============================
# cluster -> Bucket(s)
# -----------------
CLUSTER_NAME_PORT_MAP=(["C1"]=9000 ["C1P0"]=9001 ["C1P1"]=9002 ["C1P2"]=9003 ["C2"]=9004)
# For uni directional, just have one node rebalancing in
CLUSTER_DEPENDENCY_MAP=(["C1P0"]="C1" ["C1P1"]="C1" ["C1P2"]="C1")
CLUSTER_NAME_XDCR_PORT_MAP=(["C1"]=13000 ["C1P0"]=13001 ["C1P1"]=13002 ["C1P2"]=13003 ["C2"]=13004)
# Set c1 to have 2 buckets and c2 to have 1 bucket
CLUSTER_NAME_BUCKET_MAP=(["C1"]="B0" ["C2"]="B1")
CLUSTER_SETUP_DONE_MAP=()
declare -gA CLUSTER_SETUP_DONE_MAP

# Bucket properties
declare -A BucketProperty=(["ramQuotaMB"]=1024 ["numVBuckets"]=1024)
declare -A Bucket1Properties=(["ramQuotaMB"]=1024 ["CompressionMode"]="Active" ["numVBuckets"]=1024)
insertPropertyIntoBucketNamePropertyMap "B0" BucketProperty
insertPropertyIntoBucketNamePropertyMap "B1" Bucket1Properties

declare -A DefaultBucketReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=60 ["statsInterval"]=500 ["preReplicateVBMasterCheck"]="true")

# Bucket -> Scopes
# -----------------
declare -a scope1Arr=("S1" "S2")
BUCKET_NAME_SCOPE_MAP=(["B0"]=${scope1Arr[@]} ["B1"]="S2")

# Scopes -> Collections
# ----------------------
declare -a collection1Arr=("col1" "col2")
declare -a collection2Arr=("col1" "col2" "col3")
SCOPE_NAME_COLLECTION_MAP=(["S1"]=${collection1Arr[@]} ["S2"]=${collection2Arr[@]} ["S3"]=${collection2Arr[@]})

function runDataLoad {
	echo "RUNNING dataload..."
	runCbWorkloadGenCollection "C1" "B0" "S1" "col1" &
	runCbWorkloadGenCollection "C1" "B0" "S2" "col1" &
	waitForBgJobs
	echo "RUNNING dataload DONE"
}

TOPOLOGY_RESTART_MSG="Restarting pipeline due to source topology change"

declare LOGMSG=$BROKEN_MSG

function runOneReplicationCycleAndPause {
	local timeIntervalSecs=5
	local checkInterval=10
	local maxChangeCnt=3
	local maxStableCnt=3
	local coolDownPeriod=1
	local checkInt
	setupCluster
	setupTopologies
	echo "Waiting 10 seconds to allow cluster setup to complete..."
	sleep 10
	# Shorten the amount of time pipeline restarts
	setInternalSettings "C1" "TopologyChangeCheckInterval=$checkInterval" "MaxTopologyChangeCountBeforeRestart=$maxChangeCnt" "MaxTopologyStableCountBeforeRestart=$maxStableCnt" "TopologySvcCooldownPeriodSec=$coolDownPeriod"
	sleep 5
	checkInternalSetting "C1" "TopologyChangeCheckInterval" "$checkInterval"
	checkInternalSetting "C1" "MaxTopologyChangeCountBeforeRestart" "$maxChangeCnt"
	checkInternalSetting "C1" "MaxTopologyStableCountBeforeRestart" "$maxStableCnt"
	checkInternalSetting "C1" "TopologySvcCooldownPeriodSec" "$coolDownPeriod"
	if (($? != 0)); then
		exit $?
	fi

	local -i currentInstanceCnt
	currentInstanceCnt=$(getClusterLogs "C1" | grep -c "$LOGMSG")

	setCustomManifestRefreshInterval "C1"

	# Wait for vbuckets and all the other things to propagate before XDCR provisioning
	sleep 5
	createRemoteClusterReference "C1" "C2"
	sleep 1
	createBucketReplication "C1" "B0" "C2" "B1" DefaultBucketReplProperties
	printGlobalScopeAndCollectionInfo

	runDataLoad

	echo "Sleeping 20 seconds before changes left check"
	sleep 20

	validateLogWithInstance "C1" "$LOGMSG" $(($currentInstanceCnt + 1))

	checkChangesLeftInternal "C1" "B0" "C2" "B1"
	validateXDCRCheckpoints "C1"
	grepForPanics

	pauseReplication "C1" "B0" "C2" "B1"
	echo "Waiting 10 seconds for pipeline to really pause"
	sleep 10
	grepForPanics

	createScope "C2" "B1" "S1"
	createCollection "C2" "B1" "S1" "col1"

	echo "Sleeping 15 secs before resuming replication"
	sleep 15
	resumeReplication "C1" "B0" "C2" "B1"

	checkChangesLeftInternal "C1" "B0" "C2" "B1"
	grepForPanics

	# Once all is done, pause to re-create checkpoint
	pauseReplication "C1" "B0" "C2" "B1"
	echo "Waiting 10 seconds for pipeline to really pause"
	sleep 10
}

C1LOOKINGC1PMSG="Discovered peers: map\\[127.0.0.1:9001"
CKPT_FOUND_DOCS="retrieving CheckpointsDocs request found"
CKPT_RETRIEVED="Received peerToPeer checkpoint data from node"
CKPT_RESUME_FOUND="checkpoint documents for"
LOADED_BROKEN_MAP="Loaded brokenMap: map"
LOADED_BROKEN_MAP_NAME="S1.col1"

function runOneRebalanceCycle {
	local cycleCnt=$1
	local totalCycleCnt=$2
	local timeIntervalSecs=30

	echo "Sleeping 15 secs before rebalancing node in"
	sleep 15

	echo "============================================================================"
	echo "Rebalance Cycle $(($cycleCnt + 1))/$(($totalCycleCnt)) STARTING"
	echo "============================================================================"

	# Previous test may have messed with the CAs
	setupCertsForTesting
	cleanupClientCertMaps

	addNodesIn
	sleep 5
	startRebalancing "C1"
	echo "Rebalancing node in is completed"

	echo "Sleeping before checking logs"
	sleep 15

	echo "============================================================================"
	echo "Rebalance Cycle $(($cycleCnt + 1))/$(($totalCycleCnt)) DONE"
	echo "============================================================================"
	grepForPanics
}

function runReplicationResume {
	local logs
	local resumeFrom0Cnt
	local -A curDepsCkptsFoundDocsCntMap
	local -A curDepsCkptRetrievedCntMap

	logs=$(getInternalNodeXdcrLog "C1")
	local curCkptsFoundDocsCnt=$(echo "$logs" | grep "$CKPT_FOUND_DOCS" | grep -v "backfill" | grep -c .)
	local curCkptRetrievedCnt=$(echo "$logs" | grep -c "$CKPT_RETRIEVED")

	local tempLogs
	for dependentClusterName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		tempLogs=$(getInternalNodeXdcrLog "$dependentClusterName")
		curDepsCkptsFoundDocsCntMap["$dependentClusterName"]=$(echo "$tempLogs" | grep -c "$CKPT_FOUND_DOCS")
		curDepsCkptRetrievedCntMap["$dependentClusterName"]=$(echo "$tempLogs" | grep -c "$CKPT_RETRIEVED")
	done

	resumeReplication "C1" "B0" "C2" "B1"

	# The more nodes, the more time it takes to resume
	local waitTime=$((20 * ${#CLUSTER_DEPENDENCY_MAP[@]}))
	echo "Waiting $waitTime seconds for resume to finish"
	sleep $waitTime

	# Make sure we check to see that the message is displayed, but make sure that the count is not 0
	logs=$(getInternalNodeXdcrLog "C1")

	# The msg below is displayed whenever a peer node pulls from this node
	local checkCnt=$(echo "$logs" | grep "$CKPT_FOUND_DOCS" | grep -v "backfill" | grep -c .)
	if (($checkCnt < $(($curCkptsFoundDocsCnt + 1)))) || (($checkCnt > $(($curCkptsFoundDocsCnt + ${#CLUSTER_DEPENDENCY_MAP[@]})))); then
		echo "Found $checkCnt instances of $CKPT_FOUND_DOCS (minus backfill)"
		exit 1
	fi

	foundDocCount=$(echo "$logs" | grep "$CKPT_FOUND_DOCS" | grep -cv " 0 ")
	if (($foundDocCount == 0)); then
		echo "C1 unable to retrieve checkpoint docs... were they deleted?"
		exit 1
	fi

	local ckptFoundWith0Count
	local ckptFoundTotalCount
	for dependentClusterName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		tempLogs=$(getInternalNodeXdcrLog "$dependentClusterName")
		ckptFoundWith0Count=$(echo "$tempLogs" | grep "$CKPT_RESUME_FOUND" | grep -c " 0 ")
		ckptFoundTotalCount=$(echo "$tempLogs" | grep -c "$CKPT_RESUME_FOUND")
		if (($ckptFoundWith0Count == $ckptFoundTotalCount)); then
			echo "$dependentClusterName unable to find upserted checkpoints"
			exit 1
		fi
	done

	for dependentClusterName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		local oneNodeCurRetrievedCkptCnt="${curDepsCkptRetrievedCntMap[$dependentClusterName]}"
		validateInternalLogWithInstance "$dependentClusterName" "$CKPT_RETRIEVED" $(($oneNodeCurRetrievedCkptCnt + 1)) $(($oneNodeCurRetrievedCkptCnt + 2))
	done

	# Backfill pipeline from C1 could already be finished but the backfill tasks still exist
	# and there is no ckpt for the backfill tasks... so the backfill tasks would have been
	# pulled by C1P, but no ckpt pulled
	# That's ok... so skip checking those
	for dependentClusterName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		tempLogs=$(getInternalNodeXdcrLog "$dependentClusterName")

		resumeFrom0Cnt=$(echo "$tempLogs" | grep "$TS_PREFIX" | grep -v "backfill" | grep -c "${TS_PREFIX}=0")
		if (($resumeFrom0Cnt > 10)); then
			echo "$dependentClusterName has at least ten VBs that resumed from seqno 0"
			exit 1
		fi
		resumeLoadBrokenMapCnt=$(echo "$tempLogs" | grep "$LOADED_BROKEN_MAP" | grep -c "$LOADED_BROKEN_MAP_NAME")
		if (($resumeLoadBrokenMapCnt == 0)); then
			echo "$dependentClusterName did not load broken map from checkpoint migration"
			exit 1
		fi
	done

	grepForPanics
}

function runTestCase {
	echo "============================================================================"
	echo "Running large scaled cluster with P2P checkpoint pull after rebalancing"
	echo "============================================================================"

	# At this point, settings need to be restored IF the script was forced exited
	trap killAllBgJobs EXIT

	# These tests require a clean log
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		clearInternalNodeXdcrLog "$clusterName"
	done

	runOneReplicationCycleAndPause
	runOneRebalanceCycle 1 1
	runReplicationResume

	# ensure that p2p did not fail
	for dependentClusterName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		validateInternalLogWithInstance "$dependentClusterName" "$P2P_PULL_ERR_MSG" 0
		validateInternalLogWithInstance "$clusterName" "$CKPT_MAPPING_NOT_FOUND_MSG" 0
	done

	echo "Sleeping 60 seconds for heartbeat to be passed and parsed"
	sleep 60
	validatePrometheusSourceNodesCnt "C2" 4
	validatePrometheusSourceRunningReplCnt "C2" 1

	echo "============================================================================"
	echo "PASSED"
	echo "============================================================================"
	cleanupBucketReplications
	cleanupBuckets
	cleanupRemoteClusterRefs

	echo "Cleaning up topology..."
	restoreClusterBack "C1"
}
