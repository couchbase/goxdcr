# Copyright 2019-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# =============================
# topological map information
# =============================
# cluster -> Bucket(s)
# -----------------
CLUSTER_NAME_PORT_MAP=(["C1"]=9000 ["C1P0"]=9001 ["C1P1"]=9002 ["C1P2"]=9003 ["C1P3"]=9004 ["C1P4"]=9005 ["C2"]=9006)
CLUSTER_DEPENDENCY_MAP=(["C1P0"]="C1" ["C1P1"]="C1" ["C1P2"]="C1" ["C1P3"]="C1" ["C1P4"]="C1")
CLUSTER_NAME_XDCR_PORT_MAP=(["C1"]=13000 ["C1P0"]=13001 ["C1P1"]=13002 ["C1P2"]=13003 ["C1P3"]=13004 ["C1P4"]=13005 ["C2"]=13006)

# Set c1 to have 2 buckets and c2 to have 1 bucket
CLUSTER_NAME_BUCKET_MAP=(["C1"]="B0" ["C2"]="B1")
CLUSTER_SETUP_DONE_MAP=()
declare -gA CLUSTER_SETUP_DONE_MAP

# Bucket properties
declare -A BucketProperty=(["ramQuotaMB"]=1024 ["numVBuckets"]=1024)
declare -A Bucket1Properties=(["ramQuotaMB"]=1024 ["CompressionMode"]="Active" ["numVBuckets"]=1024)
insertPropertyIntoBucketNamePropertyMap "B0" BucketProperty
insertPropertyIntoBucketNamePropertyMap "B1" Bucket1Properties

declare -A DefaultBucketReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=60 ["statsInterval"]=500 ["preReplicateVBMasterCheck"]="true")

# Bucket -> Scopes
# -----------------
declare -a scope1Arr=("S1" "S2")
BUCKET_NAME_SCOPE_MAP=(["B0"]=${scope1Arr[@]} ["B1"]="S2")

# Scopes -> Collections
# ----------------------
declare -a collection1Arr=("col1" "col2")
declare -a collection2Arr=("col1" "col2" "col3")
SCOPE_NAME_COLLECTION_MAP=(["S1"]=${collection1Arr[@]} ["S2"]=${collection2Arr[@]} ["S3"]=${collection2Arr[@]})

function runDataLoad {
	echo "RUNNING dataload..."
	runCbWorkloadGenCollection "C1" "B0" "S1" "col1" &
	runCbWorkloadGenCollection "C1" "B0" "S2" "col1" &
	waitForBgJobs
	echo "RUNNING dataload DONE"
}

TOPOLOGY_RESTART_MSG="Restarting pipeline due to source topology change"

TC_CHECK_INTERVAL=10
TC_MAX_CHANGE_CNT=3

function runOneReplicationCycleAndPause {
	local timeIntervalSecs=5
	local checkInterval=$TC_CHECK_INTERVAL
	local maxChangeCnt=$TC_MAX_CHANGE_CNT
	local maxStableCnt=3
	local coolDownPeriod=1
	local checkInt
	local waitTime
	setupTopologies
	# Shorten the amount of time pipeline restarts
	setInternalSettings "C1" "TopologyChangeCheckInterval=$checkInterval" "MaxTopologyChangeCountBeforeRestart=$maxChangeCnt" "MaxTopologyStableCountBeforeRestart=$maxStableCnt" "TopologySvcCooldownPeriodSec=$coolDownPeriod"
	sleep 5
	checkInternalSetting "C1" "TopologyChangeCheckInterval" "$checkInterval"
	checkInternalSetting "C1" "MaxTopologyChangeCountBeforeRestart" "$maxChangeCnt"
	checkInternalSetting "C1" "MaxTopologyStableCountBeforeRestart" "$maxStableCnt"
	checkInternalSetting "C1" "TopologySvcCooldownPeriodSec" "$coolDownPeriod"
	if (($? != 0)); then
		exit $?
	fi

	setCustomManifestRefreshInterval "C1"

	# Wait for vbuckets and all the other things to propagate before XDCR provisioning
	sleep 5
	createRemoteClusterReference "C1" "C2"
	sleep 1
	createBucketReplication "C1" "B0" "C2" "B1" DefaultBucketReplProperties
	printGlobalScopeAndCollectionInfo

	runDataLoad

	waitTime=$((20 * ${#CLUSTER_DEPENDENCY_MAP[@]}))
	echo "$(date): Waiting $waitTime seconds for pipeline to start and replication to finish"
	sleep $waitTime

	checkChangesLeftInternal "C1" "B0" "C2" "B1"
	validateXDCRCheckpoints "C1"
	grepForPanics

	pauseReplication "C1" "B0" "C2" "B1"

	waitTime=$((10 * ${#CLUSTER_DEPENDENCY_MAP[@]}))
	echo "Waiting $waitTime seconds for pipeline to really pause"
	sleep $waitTime
	grepForPanics

	createScope "C2" "B1" "S1"
	createCollection "C2" "B1" "S1" "col1"

	echo "Sleeping 15 secs before resuming replication"
	sleep 15
	resumeReplication "C1" "B0" "C2" "B1"

	waitTime=$((15 * ${#CLUSTER_DEPENDENCY_MAP[@]}))
	echo "$(date): Waiting $waitTime seconds for pipeline to resume and replication to finish"
	sleep $waitTime

	checkChangesLeftInternal "C1" "B0" "C2" "B1"
	grepForPanics

	# Once all is done, pause to re-create checkpoint
	pauseReplication "C1" "B0" "C2" "B1"

	waitTime=$((10 * ${#CLUSTER_DEPENDENCY_MAP[@]}))
	echo "Waiting $waitTime seconds for pipeline to really pause"
	sleep $waitTime
}

C1LOOKINGC1PMSG="Discovered peers: map\\[127.0.0.1:9001"
CKPT_FOUND_DOCS="retrieving CheckpointsDocs request found"
CKPT_RETRIEVED="Received peerToPeer checkpoint data from node"
CKPT_RESUME_FOUND="checkpoint documents for"
LOADED_BROKEN_MAP="Loaded brokenMap: map"
LOADED_BROKEN_MAP_NAME="S1.col1"

function runOneRebalanceCycleIn {
	local timeIntervalSecs=30

	setupCluster

	echo "Sleeping 15 secs before rebalancing node in"
	sleep 15

	# Previous test may have messed with the CAs
	setupCertsForTesting
	cleanupClientCertMaps

	addNodesIn
	sleep 5
	startRebalancing "C1"
	echo "Rebalancing node in is completed"

	grepForPanics
}

function rebalanceNodesOut {
	local numOfNodeToEject=$1
	local i

	for ((i = 1; $i < $numOfNodeToEject; i = $(($i + 1)))); do
		local nodeNameToEject="C1P${i}"
		startEjectNode "$nodeNameToEject" "C1"
	done
}

function validateCkptResume {
	local dependentNodeName=$1
	tempLogs=$(getInternalNodeXdcrLog "$dependentNodeName")
	# CKPT_RESUME_FOUND="checkpoint documents for"
	ckptFoundWith0Count=$(echo "$tempLogs" | grep -v "Backfill" | grep "$CKPT_RESUME_FOUND" | grep -c " 0 ")
	ckptFoundTotalCount=$(echo "$tempLogs" | grep -v "Backfill" | grep -c "$CKPT_RESUME_FOUND")
	if (($ckptFoundWith0Count == $ckptFoundTotalCount)); then
		if (($ckptFoundTotalCount == 0)); then
			echo "$dependentNodeName shows no resume message"
			return 1
		else
			echo "$dependentNodeName unable to find upserted checkpoints"
			exit 1
		fi
	fi
}

function runReplicationResume {
	local logs
	local resumeFrom0Cnt
	local -A curDepsCkptsFoundDocsCntMap
	local -A curDepsCkptRetrievedCntMap
	local dependentNodeName

	logs=$(getInternalNodeXdcrLog "C1")
	local curCkptsFoundDocsCnt=$(echo "$logs" | grep "$CKPT_FOUND_DOCS" | grep -v "backfill" | grep -c .)
	local curCkptRetrievedCnt=$(echo "$logs" | grep -c "$CKPT_RETRIEVED")

	local tempLogs
	for dependentClusterName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		tempLogs=$(getInternalNodeXdcrLog "$dependentClusterName")
		curDepsCkptsFoundDocsCntMap["$dependentClusterName"]=$(echo "$tempLogs" | grep -c "$CKPT_FOUND_DOCS")
		curDepsCkptRetrievedCntMap["$dependentClusterName"]=$(echo "$tempLogs" | grep -c "$CKPT_RETRIEVED")
	done

	resumeReplication "C1" "B0" "C2" "B1"

	# The more nodes, the more time it takes to resume
	local waitTime=$((20 * ${#CLUSTER_DEPENDENCY_MAP[@]}))
	echo "$(date): Waiting $waitTime seconds for resume to finish"
	sleep $waitTime

	checkForP2PError

	# Make sure we check to see that the message is displayed, but make sure that the count is not 0
	logs=$(getInternalNodeXdcrLog "C1")

	# The msg below is displayed whenever a peer node pulls from this node
	local checkCnt=$(echo "$logs" | grep "$CKPT_FOUND_DOCS" | grep -v "backfill" | grep -c .)
	# The acceptable count should be at least one more than current and less than twice the number of nodes
	# Twice because it is possible for a node to do two pulls: one for main and one for a backfill pipeline, but
	# backfill pipeline is not guaranteed
	local expectedMax=$(((($curCkptsFoundDocsCnt + ${#CLUSTER_DEPENDENCY_MAP[@]})) * 2))
	if (($checkCnt < $(($curCkptsFoundDocsCnt + 1)))) || (($checkCnt > $expectedMax)); then
		echo "Found $checkCnt instances of $CKPT_FOUND_DOCS (minus backfill)... expecting > $curCkptsFoundDocsCnt and <= $expectedMax"
		exit 1
	fi

	foundDocCount=$(echo "$logs" | grep "$CKPT_FOUND_DOCS" | grep -cv " 0 ")
	if (($foundDocCount == 0)); then
		echo "C1 unable to retrieve checkpoint docs... were they deleted?"
		exit 1
	fi

	local ckptFoundWith0Count
	local ckptFoundTotalCount
	local retry
	for dependentNodeName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		validateCkptResume "$dependentNodeName"
		retry=0
		while ((!$? == 0 && $retry < 5)); do
			echo "Trying again $retry out of 5..."
			sleep 10
			validateCkptResume "$dependentNodeName"
			retry=$(($retry + 1))
		done
	done

	# Skip validating ckpt pulled because the replications are already distributed

	# Skip validating ckpt resume from non-0 because that's out of scope of this test and the test has changed
	# from original parent test

	grepForPanics
}

function checkForP2PError {
	# ensure that p2p did not fail
	for dependentNodeName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		echo "Validating p2p pull error on $dependentNodeName"
		validateInternalLogWithInstance "$dependentNodeName" "$P2P_PULL_ERR_MSG" 0
	done
}

function runTestCase {
	echo "============================================================================"
	echo "Running large scaled cluster with P2P checkpoint pull after rebalancing 6 nodes restarting pipeline"
	echo "============================================================================"

	# At this point, settings need to be restored IF the script was forced exited
	trap killAllBgJobs EXIT

	runOneRebalanceCycleIn
	runOneReplicationCycleAndPause
	runReplicationResume

	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		validateInternalLogWithInstance "$clusterName" "$P2P_DESERIALIZATION_ERR_MSG" 0
		validateInternalLogWithInstance "$clusterName" "$P2P_UNABLE_TO_RESPOND_MSG" 0
		validateInternalLogWithInstance "$clusterName" "$CKPT_MAPPING_NOT_FOUND_MSG" 0
		validateInternalLogWithInstance "$clusterName" "$P2P_PULL_MANIFEST_ERR" 0
	done

	checkForP2PError
	# Pick a random node to eject
	echo "Picking a random node to eject:"
	local randomID
	randomID=$(echo $(($RANDOM % ${#CLUSTER_DEPENDENCY_MAP[@]})))
	local randomNodeName="C1P${randomID}"
	echo "Ejecting $randomNodeName"
	startEjectNode "$randomNodeName" "C1"

	killAllBgJobs
	# Do one last round
	checkForP2PError

	echo "============================================================================"
	echo "PASSED"
	echo "============================================================================"
	cleanupBucketReplications
	cleanupBuckets
	cleanupRemoteClusterRefs

	echo "To simplify clean up, add random node back in..."

	# Before adding nodes, need to redo certs
	setupCertsForTesting
	cleanupClientCertMaps

	addOneNodeIn "$randomNodeName" "C1"
	sleep 20
	startRebalancing "C1"

	echo "Cleaning up topology..."
	restoreClusterBack "C1"
}
