# Copyright 2025-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# =============================
# topological map information
# =============================
# cluster -> Bucket(s)
# -----------------

CLUSTER_NAME_PORT_MAP=(["C1"]=9000 ["C1P"]=9001 ["C2"]=9002 ["C2P"]=9003)
CLUSTER_DEPENDENCY_MAP=(["C1P"]="C1" ["C2P"]="C2")
CLUSTER_NAME_XDCR_PORT_MAP=(["C1"]=13000 ["C1P"]=13001 ["C2"]=13002 ["C2P"]=13003)
# Set c1 and c2 to have 1 bucket
CLUSTER_NAME_BUCKET_MAP=(["C1"]="B1" ["C2"]="B2")

# Bucket properties
declare -A BucketProperty=(["ramQuotaMB"]=100)
insertPropertyIntoBucketNamePropertyMap "B1" BucketProperty
insertPropertyIntoBucketNamePropertyMap "B2" BucketProperty

declare -A DefaultBucketReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=300 ["statsInterval"]=500)

# Bucket -> Scopes
# -----------------
declare -a scopeArr=("S1" "S2")
BUCKET_NAME_SCOPE_MAP=(["B1"]=${scopeArr[@]} ["B2"]=${scopeArr[@]})

# Scopes -> Collections
# ----------------------
declare -a collectionArr=("col1" "col2")
SCOPE_NAME_COLLECTION_MAP=(["S1"]=${collectionArr[@]} ["S2"]=${collectionArr[@]})

# declare xdcr roles username and password
DEFAULT_XDCR_ADMIN="XDCR_Admin"
DEFAULT_XDCR_INBOUND="XDCR_Inbound"
DEFAULT_PASSWORD="wewewe"

function runDataLoad {
	echo "RUNNING dataload..."
	runCbWorkloadGenCollection "C1" "B1" "S1" "col1"
	runCbWorkloadGenCollection "C1" "B1" "S1" "col2"
	runCbWorkloadGenCollection "C1" "B1" "S2" "col1"
	runCbWorkloadGenCollection "C1" "B1" "S2" "col2"
}

function setupXdcrRoles {
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		setupXdcrAdminUser "$clusterName" "$DEFAULT_XDCR_ADMIN" "$DEFAULT_PASSWORD"
		setupXdcrInboundUser "$clusterName" "$DEFAULT_XDCR_INBOUND" "$DEFAULT_PASSWORD"
	done
}

CREDENTIALS_CHANGE_ERR_MSG="has changed its credentials and the entered credentials on this cluster is no longer valid for pipeline"

function runTestCase {
	echo "============================================================================"
	echo "Running basic replication with password rotation"
	echo "============================================================================"
	setupTopologies
	if (($? != 0)); then
		exit 1
	fi

	# Clear the logs at the beginning.
	# This is necessary because we later use 'grep' to search for specific log lines and count their occurrences.
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		clearInternalNodeXdcrLog "$clusterName"
	done

	echo "Sleeping 10 seconds for XDCR CPUs to have a chance to idle before measurement"
	sleep 10
	testIdleXdcrCPU
	if (($? != 0)); then
		exit 1
	fi

	addNodesIn
	startRebalancing "C1"
	startRebalancing "C2"
	sleep 10

	# setup the xdcr roles
	setupXdcrRoles

	sleep 5
	local C2Port=${CLUSTER_NAME_PORT_MAP["C2"]}
	runConnectionPreCheckUsernamePassword "C1" "C2" "$DEFAULT_XDCR_ADMIN" "$DEFAULT_PASSWORD"
	if (($? != 0)); then
		echo "Connection pre-check with correct username and password failed"
		exit 1
	fi

	#create a remote cluster reference for C2 on C1
	createRemoteClusterReference "C1" "C2" "127.0.0.1" "$DEFAULT_XDCR_INBOUND" "$DEFAULT_PASSWORD"
	if (($? != 0)); then
		exit 1
	fi

	runDataLoad
	sleep 2

	#create a replication from B1 to B2
	createBucketReplication "C1" "B1" "C2" "B2" DefaultBucketReplProperties
	grepForPanics

	# Negative test: invalid parameter for staging
	echo "Testing negative case for staging credentials with invalid parameter..."
	local sourcePort=${CLUSTER_NAME_PORT_MAP["C1"]}
	NEG_RESP=$(curl -s -o /tmp/neg_resp.txt -w "%{http_code}" -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/pools/default/remoteClusters/C2 -d stage=true -d username=$DEFAULT_ADMIN -d password=$DEFAULT_PW -d hello=world)
	NEG_BODY=$(cat /tmp/neg_resp.txt)
	# Clean up temporary file
	rm -f /tmp/neg_resp.txt
	if [[ "$NEG_RESP" != "400" ]]; then
		echo "Negative test failed: Expected HTTP 400, got $NEG_RESP"
		echo "Response body: $NEG_BODY"
		exit 1
	fi
	echo "$NEG_BODY" | grep -q 'invalid parameters provided: \[hello\]' || {
		echo "Negative test failed: Expected error message not found"
		echo "Response body: $NEG_BODY"
		exit 1
	}
	echo "Negative test for invalid staging parameter passed."

	# Now submit the correct request
	echo "Staging secondary credentials with the right set of parameters"
	postStageCredToRemoteReference "C1" "C2" "$DEFAULT_XDCR_INBOUND" "wewewe1"

	echo " Changing Password $(date +"%Y-%m-%d %H:%M:%S.%6N")"
	changeUserPassword "C2" "$DEFAULT_XDCR_INBOUND" "$DEFAULT_PASSWORD" "wewewe1"
	grepForPanics

	# original default password should fail now
	runConnectionPreCheckUsernamePassword "C1" "C2" "$DEFAULT_XDCR_INBOUND" "$DEFAULT_PASSWORD"
	if (($? == 0)); then
		echo "Connection pre-check with old password succeeded but should have failed"
		exit 1
	fi

	echo "Wait for 10sec before grepping for errors"
	sleep 10

	validateLogWithInstance "C1" "$CREDENTIALS_CHANGE_ERR_MSG" "0"

	checkRemoteClusterConnectivity "C1"

	# run precheck with new password
	runConnectionPreCheckUsernamePassword "C1" "C2" "$DEFAULT_XDCR_INBOUND" "wewewe1"
	if (($? != 0)); then
		echo "Connection pre-check with new password failed"
		exit 1
	fi

	# run data load again
	runDataLoad
	sleep 2
	checkUnidirectionalChangesLeft

	validateLogWithInstance "C1" "$CREDENTIALS_CHANGE_ERR_MSG" "0"

	pipelineErrCnt=$(getPrometheusStat "C1" "B1" "B2" "xdcr_pipeline_errors")
	if (($pipelineErrCnt != 0)); then
		echo "Expected zero pipeline errors. PipelineerrCnt=$pipelineErrCnt"
		echo "============================================================================"
		echo "FAILED"
		echo "============================================================================"
	fi

	grepForPanics

	echo "============================================================================"
	echo "PASSED"
	echo "============================================================================"
	cleanupBucketReplications
	cleanupBuckets
	cleanupRemoteClusterRefs
}
