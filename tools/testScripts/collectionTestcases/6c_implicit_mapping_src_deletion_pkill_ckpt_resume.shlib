# Copyright 2025-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# =============================
# topological map information
# =============================
# cluster -> Bucket(s)
# -----------------
CLUSTER_NAME_PORT_MAP=(["C1"]=9000 ["C2"]=9001)
CLUSTER_NAME_XDCR_PORT_MAP=(["C1"]=13000 ["C2"]=13001)
CLUSTER_NAME_BUCKET_MAP=(["C1"]="B1" ["C2"]="B2")

# Bucket properties
declare -A BucketProperty=(["ramQuotaMB"]=100)
declare -A Bucket1Properties=(["ramQuotaMB"]=100 ["CompressionMode"]="Active")
insertPropertyIntoBucketNamePropertyMap "B0" BucketProperty
insertPropertyIntoBucketNamePropertyMap "B1" Bucket1Properties
insertPropertyIntoBucketNamePropertyMap "B2" BucketProperty

declare -A DefaultBucketReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=6000 ["statsInterval"]=500)
declare -A ImplicitReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=6000 ["statsInterval"]=500 ["collectionsOSOMode"]="false" ["xdcrDevBackfillSendDelayMs"]=10000)

# Bucket -> Scopes
# -----------------
BUCKET_NAME_SCOPE_MAP=(["B1"]="S1")

# Scopes -> Collections
# ----------------------
declare -a collection1Arr=("col1" "col2" "col3")
SCOPE_NAME_COLLECTION_MAP=(["S1"]=${collection1Arr[@]})

function runDataLoad {
	# Run CBWorkloadgen in parallel
	runCbWorkloadGenCollection "C1" "B1" "S1" "col1" &
	runCbWorkloadGenCollection "C1" "B1" "S1" "col2" &
	runCbWorkloadGenCollection "C1" "B1" "S1" "col3" &
	waitForBgJobs
}

declare -i ORIG_TARGET_MAN_PULL_INTERVAL

HALTBACKFILLWITHCB_MSG="Restarting the current backfill pipeline"
BACKFILL_HANDLER_NIL="Backfill handler was nil, considering that there was no active backfill pipeline for"

function runTestCase {
	echo "==============================================================================="
	echo "Running implicit mapping - remove some collections from source and resume from old ckpt"
	echo "==============================================================================="
	testForClusterRun
	if (($? != 0)); then
		exit $?
	fi

	# First setup mis-matching mapping meaning all the data reside in C1
	setupTopologies
	if (($? != 0)); then
		exit $?
	fi

	cleanupGoxdcrLogs

	runDataLoad

	# Wait for vbuckets and all the other things to propagate before XDCR provisioning
	sleep 5
	createRemoteClusterReference "C1" "C2"
	sleep 1
	createBucketReplication "C1" "B1" "C2" "B2" ImplicitReplProperties
	printGlobalScopeAndCollectionInfo

	echo "Waiting 15 seconds before checking item count first pass"
	sleep 15
	checkItemCnt "C2" "B2" 0

	# force a checkpointing operation
	pauseReplication "C1" "B1" "C2" "B2"
	sleep 10
	resumeReplication "C1" "B1" "C2" "B2"
	sleep 10

	# Add a col1, col2 and col3 on target
	# The backfill should kick in and fill in all the data to the new collections.
	# A backfill delay of 10s is set also.
	createScope "C2" "B2" "S1"
	createCollection "C2" "B2" "S1" "col1"
	createCollection "C2" "B2" "S1" "col2"
	createCollection "C2" "B2" "S1" "col3"
	printGlobalScopeAndCollectionInfo
	echo "Sleeping 100 seconds for discovery and automatic backfill"
	sleep 100

	# now remove S1.col3 from source bucket
	# and not backfill for S1.col3 anymore (via HaltBackfillWithCb)
	echo "Deleting source collection col3 - target collections should not have backfill anymore"
	deleteCollection "C1" "B1" "S1" "col3"
	printGlobalScopeAndCollectionInfo
	echo "Sleeping 100 seconds for discovery and automatic repair"
	sleep 100

	validateInternalLogWithInstance "C1" "$HALTBACKFILLWITHCB_MSG" 1
	validateInternalLogWithInstance "C1" "$BACKFILL_HANDLER_NIL" 0
	grepForPanics
	validateXDCRCheckpoints "C1"
	validateXDCRCheckpoints "C2"

	runCbWorkloadGenCollection "C1" "B1" "S1" "col1" &
	runCbWorkloadGenCollection "C1" "B1" "S1" "col2" &
	killGoXdcr "C1"
	waitForBgJobs

	echo "Sleeping 30s for backfill to start"
	sleep 30

	# speeden-up backfill before checking for changes_left and doc count
	echo "speedening up backfill for it to finish"
	setReplicationSettings "C1" "B1" "C2" "B2" "xdcrDevBackfillSendDelayMs=0"
	sleep 30

	checkUnidirectionalChangesLeft
	grepForPanics
	checkItemCnt "C1" "B1" $(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 2))
	tgtItemCnt=$(getBucketItemCount "C2" "B2")
	maxCnt=$(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 3))
	if (($tgtItemCnt == $maxCnt)); then
		echo "Item count should be lesser than $(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 3)), but is $tgtItemCnt"
		return 1
	fi

	# make sure if col3 is added back, and the new data is flowing now.
	createCollection "C1" "B1" "S1" "col3"
	sleep 2
	runCbWorkloadGenCollection "C1" "B1" "S1" "col3" "" "new" &
	echo "Sleeping 100 seconds for discovery and automatic backfill"
	sleep 100
	waitForBgJobs

	checkUnidirectionalChangesLeft
	grepForPanics
	checkItemCnt "C1" "B1" $(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 3))
	# target should have some documents (not all) from col3 before deletion,
	# and all documents from col3 after re-creation
	tgtItemCnt=$(getBucketItemCount "C2" "B2")
	minCnt=$(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 3))
	maxCnt=$(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 4))
	if ! [[ $tgtItemCnt -ge $minCnt && $tgtItemCnt -le $maxCnt ]]; then
		echo "Item count should be within range $(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 3)) and $(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 4)), but is $tgtItemCnt"
		return 1
	fi

	echo "============================================================================"
	echo "PASSED"
	echo "============================================================================"
	cleanupBucketReplications
	cleanupBuckets
	cleanupRemoteClusterRefs
}
