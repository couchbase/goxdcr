# Copyright 2019-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# =============================
# topological map information
# =============================
# cluster -> Bucket(s)
# -----------------
CLUSTER_NAME_PORT_MAP=(["C1"]=9000 ["C2"]=9001)
CLUSTER_NAME_XDCR_PORT_MAP=(["C1"]=13000 ["C2"]=13001)
# Set c1 to have 2 buckets and c2 to have 1 bucket
declare -a cluster1BucketsArr
cluster1BucketsArr=("B0" "B1")
CLUSTER_NAME_BUCKET_MAP=(["C1"]=${cluster1BucketsArr[@]} ["C2"]="B2")

# Bucket properties
declare -A BucketProperty=(["ramQuotaMB"]=100)
declare -A Bucket1Properties=(["ramQuotaMB"]=100 ["CompressionMode"]="Active")
insertPropertyIntoBucketNamePropertyMap "B0" BucketProperty
insertPropertyIntoBucketNamePropertyMap "B1" Bucket1Properties
insertPropertyIntoBucketNamePropertyMap "B2" BucketProperty

declare -A DefaultBucketReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=60 ["statsInterval"]=500)
declare -A ExplicitReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=60 ["statsInterval"]=500 ["collectionsExplicitMapping"]="true" ["colMappingRules"]='{"S1.col1":"S3.col3"}')

# Bucket -> Scopes
# -----------------
declare -a scope1Arr=("S1" "S2")
declare -a B2ScopeArr=("S1" "S2" "S3")
BUCKET_NAME_SCOPE_MAP=(["B1"]=${scope1Arr[@]} ["B2"]=${B2ScopeArr[@]})

# Scopes -> Collections
# ----------------------
declare -a collection1Arr=("col1" "col2")
declare -a collection2Arr=("col1" "col2" "col3")
SCOPE_NAME_COLLECTION_MAP=(["S1"]=${collection1Arr[@]} ["S2"]=${collection2Arr[@]} ["S3"]=${collection2Arr[@]})

function runDataLoad {
	# Run CBWorkloadgen in parallel
	runCbWorkloadGenCollection "C1" "B1" "S1" "col1"
	waitForBgJobs
}

declare -i ORIG_TARGET_MAN_PULL_INTERVAL

function runTestCase {
	echo "============================================================================"
	echo "Running implicit switchover to explicit test case 2-step"
	echo "============================================================================"
	testForClusterRun
	if (($? != 0)); then
		exit $?
	fi

	# First setup mis-matching mapping meaning all the data reside in C1
	setupTopologies
	if (($? != 0)); then
		exit $?
	fi

	# Get current instance
	local -i currentBackfillInstanceCnt
	local -i currentVBTasksDoneInstanceCnt
	local -i currentBackfillAppendInstanceCnt
	local currentXdcrLog

	currentXdcrLog=$(getInternalNodeXdcrLog "C1")
	currentBackfillInstanceCnt=$(echo "$currentXdcrLog" | grep -c "$BACKFILL_MSG")
	currentBackfillAppendInstanceCnt=$(echo "$currentXdcrLog" | grep -c "$BACKFILL_APPEND_MSG")
	currentVBTasksDoneInstanceCnt=$(echo "$currentXdcrLog" | grep -c "$VBTASKS_DONE_MSG")

	# Wait for vbuckets and all the other things to propagate before XDCR provisioning
	sleep 5
	createRemoteClusterReference "C1" "C2"
	createRemoteClusterReference "C2" "C1"
	sleep 1
	createBucketReplication "C1" "B1" "C2" "B2" DefaultBucketReplProperties
	createBucketReplication "C2" "B2" "C1" "B1" DefaultBucketReplProperties
	printGlobalScopeAndCollectionInfo

	runDataLoad

	# Account for no-op backfill
	currentBackfillInstanceCnt=$(($currentBackfillInstanceCnt + 1))
	currentVBTasksDoneInstanceCnt=$(($currentVBTasksDoneInstanceCnt + 1))

	echo "VALIDATING Data..."
	validateCbWorkloadGenCollection "C2" "B2" "S1" "col1" "C1" "B1" "S1" "col1"

	echo "Waiting 5 seconds before checking item count first pass"
	sleep 5
	checkItemCnt "C1" "B1" $CBWORKLOAD_COLLECTION_NUM_ITEMS
	checkItemCnt "C2" "B2" $CBWORKLOAD_COLLECTION_NUM_ITEMS

	# No backfill should be raised for first pass
	validateInternalLogWithInstance "C1" "$BACKFILL_MSG" $currentBackfillInstanceCnt

	# After replicating 10k items from a source collection to target collection
	# change the replication mapping to point to a new target collection
	# The backfill should kick in and fill in all the data to the new collection
	# resulting in twice the number of items on the target bucket
	echo "Changing explicit mapping using 2 steps"
	setReplicationSettings "C1" "B1" "C2" "B2" 'collectionsExplicitMapping=true'
	sleep 10
	setReplicationSettings "C1" "B1" "C2" "B2" 'colMappingRules={"S1.col1":"S3.col2"}'

	echo "Waiting 5 seconds before checking item count for backfill"
	sleep 5
	newCount=$(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 2))
	checkItemCnt "C2" "B2" $newCount

	validateCbWorkloadGenCollection "C2" "B2" "S3" "col2" "C1" "B1" "S1" "col1"
	echo "VALIDATING data"
	sleep 5
	checkItemCnt "C2" "B2" $newCount

	# Because of MB-66344, it is now possible to have backfills raised because the backfill raise "error" condition will persist
	# Before the MB, we would see:
	# 2025-04-21T11:37:01.621-07:00 ERRO GOXDCR.ReplicaReplicator: Immediate Fetching replication 7b479f1a5e0df8d67d8292163678410f/B1/B2 for ckpt push had err Nothing to send yet
	# until the max retry
	# ... backfill raise and push due to explicit mapping change had error ExplicitMapChangePushRetry Operation failed after max retries.  Last error: Nothing to send yet
	# Because of the asyn nature, the backfill will now be raised, but should not be an issue
	validateInternalLogWithInstance "C1" "$BACKFILL_MSG" $(($currentBackfillInstanceCnt + 1))
	validateInternalLogWithInstance "C1" "$VBTASKS_DONE_MSG" $(($currentVBTasksDoneInstanceCnt + 1))
	grepForPanics
	validateXDCRCheckpoints "C1"
	validateXDCRCheckpoints "C2"

	echo "============================================================================"
	echo "PASSED"
	echo "============================================================================"
	exportProvisionedConfig
	cleanupBucketReplications
	cleanupBuckets
	cleanupRemoteClusterRefs
}
