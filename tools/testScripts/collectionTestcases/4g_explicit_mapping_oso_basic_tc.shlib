# Copyright 2019-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# =============================
# topological map information
# =============================
# cluster -> Bucket(s)
# -----------------
CLUSTER_NAME_PORT_MAP=(["C1"]=9000 ["C2"]=9001)
CLUSTER_NAME_XDCR_PORT_MAP=(["C1"]=13000 ["C2"]=13001)
# Set c1 to have 2 buckets and c2 to have 1 bucket
declare -a cluster1BucketsArr
cluster1BucketsArr=("B0" "B1")
CLUSTER_NAME_BUCKET_MAP=(["C1"]=${cluster1BucketsArr[@]} ["C2"]="B2")

# Bucket properties
declare -A BucketProperty=(["ramQuotaMB"]=100)
declare -A Bucket1Properties=(["ramQuotaMB"]=100 ["CompressionMode"]="Active")
insertPropertyIntoBucketNamePropertyMap "B0" BucketProperty
insertPropertyIntoBucketNamePropertyMap "B1" Bucket1Properties
insertPropertyIntoBucketNamePropertyMap "B2" BucketProperty

declare -A DefaultBucketReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=60 ["statsInterval"]=500)
# OSO mode is default for 7.0
declare -A ExplicitReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=60 ["statsInterval"]=500 ["collectionsExplicitMapping"]="true" ["colMappingRules"]='{"S1.col1":"S3.col3", "S2.col1":"S3.col1"}')

# Bucket -> Scopes
# -----------------
declare -a scope1Arr=("S1" "S2")
BUCKET_NAME_SCOPE_MAP=(["B1"]=${scope1Arr[@]} ["B2"]="S3")

# Scopes -> Collections
# ----------------------
declare -a collection1Arr=("col1" "col2")
declare -a collection2Arr=("col1" "col2" "col3")
SCOPE_NAME_COLLECTION_MAP=(["S1"]=${collection1Arr[@]} ["S2"]=${collection2Arr[@]} ["S3"]=${collection2Arr[@]})

function runDataLoad {
	# Run CBWorkloadgen in parallel
	runCbWorkloadGenCollection "C1" "B1" "S1" "col1" &
	runCbWorkloadGenCollection "C1" "B1" "S2" "col1" &
	runCbWorkloadGenCollection "C1" "B1" "S2" "col2" &
	waitForBgJobs
}

declare -i ORIG_TARGET_MAN_PULL_INTERVAL

function runTestCase {
	echo "============================================================================"
	echo "Running basic explicit mapping test case - new explicit map replication with OSO mode on"
	echo "============================================================================"
	testForClusterRun
	if (($? != 0)); then
		exit $?
	fi

	# First setup mis-matching mapping meaning all the data reside in C1
	setupTopologies
	if (($? != 0)); then
		exit $?
	fi

	local -i checkCount
	local -i targetCheckCount
	checkCount=$(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 3))
	targetCheckCount=$(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 2))

	# Get current instance
	local -i currentBackfillInstanceCnt
	local -i currentVBTasksDoneInstanceCnt
	local -i currentBackfillAppendInstanceCnt
	local -i currentOsoModeCnt
	local -i currentBackfillOsoDocCnt
	local currentXdcrLog

	currentXdcrLog=$(getInternalNodeXdcrLog "C1")
	currentBackfillInstanceCnt=$(echo "$currentXdcrLog" | grep -c "$BACKFILL_MSG")
	currentBackfillAppendInstanceCnt=$(echo "$currentXdcrLog" | grep -c "$BACKFILL_APPEND_MSG")
	currentVBTasksDoneInstanceCnt=$(echo "$currentXdcrLog" | grep -c "$VBTASKS_DONE_MSG")
	currentOsoModeCnt=$(echo "$currentXdcrLog" | grep -c "$OSO_MODE_MSG")
	currentBackfillOsoDocCnt=$(echo "$currentXdcrLog" | grep -c "$OSO_BACKFILL_COUNT")

	# Wait for vbuckets and all the other things to propagate before XDCR provisioning
	sleep 5
	createRemoteClusterReference "C1" "C2"
	createRemoteClusterReference "C2" "C1"
	sleep 1
	createBucketReplication "C1" "B1" "C2" "B2" ExplicitReplProperties
	createBucketReplication "C2" "B2" "C1" "B1" DefaultBucketReplProperties
	printGlobalScopeAndCollectionInfo

	runDataLoad

	# Account for no-op backfill
	currentBackfillInstanceCnt=$(($currentBackfillInstanceCnt + 1))
	currentVBTasksDoneInstanceCnt=$(($currentVBTasksDoneInstanceCnt + 1))

	echo "VALIDATING Data..."
	validateCbWorkloadGenCollection "C2" "B2" "S3" "col3" "C1" "B1" "S1" "col1"

	echo "Waiting 5 seconds before checking item count first pass"
	sleep 5
	checkItemCnt "C1" "B1" $checkCount
	checkItemCnt "C2" "B2" $targetCheckCount

	# No backfill should be raised for first pass
	validateInternalLogWithInstance "C1" "$BACKFILL_MSG" $currentBackfillInstanceCnt

	# After replicating 10k items from a source collection to target collection
	# change the replication mapping to point to a new target collection
	# The backfill should kick in and fill in all the data to the new collection
	# resulting in twice the number of items on the target bucket
	echo "Changing explicit mapping - new target collection should now receive backfill"
	setReplicationSettings "C1" "B1" "C2" "B2" 'colMappingRules={"S2.col2":"S3.col2"}'

	echo "Waiting 5 seconds before checking item count for backfill"
	sleep 5
	checkItemCnt "C2" "B2" $checkCount

	# Backfill should have been raised
	validateInternalLogWithInstance "C1" "$BACKFILL_MSG" $(($currentBackfillInstanceCnt + 1))
	validateInternalLogWithInstance "C1" "$VBTASKS_DONE_MSG" $(($currentVBTasksDoneInstanceCnt + 1))
	# 2 oso mode because one for each DCP nozzle
	validateInternalLogWithInstance "C1" "$OSO_MODE_MSG" $(($currentOsoModeCnt + 1)) $(($currentOsoModeCnt + 4))
	validateInternalLogWithInstance "C1" "$OSO_BACKFILL_COUNT" $(($currentBackfillOsoDocCnt + 1)) $(($currentBackfillOsoDocCnt + 4))
	grepForPanics
	validateXDCRCheckpoints "C1"
	validateXDCRCheckpoints "C2"

	echo "============================================================================"
	echo "PASSED"
	echo "============================================================================"
	exportProvisionedConfig
	cleanupBucketReplications
	cleanupBuckets
	cleanupRemoteClusterRefs
}
