# Copyright 2019-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# =============================
# topological map information
# =============================
# cluster -> Bucket(s)
# -----------------
CLUSTER_NAME_PORT_MAP=(["C1"]=9000 ["C2"]=9001)
CLUSTER_NAME_XDCR_PORT_MAP=(["C1"]=13000 ["C2"]=13001)
# Set c1 to have 2 buckets and c2 to have 1 bucket
declare -a cluster1BucketsArr
cluster1BucketsArr=("B0" "B1")
CLUSTER_NAME_BUCKET_MAP=(["C1"]=${cluster1BucketsArr[@]} ["C2"]="B2")
CLUSTER_NAME_KV_PORT_MAP=(["C1"]=12000 ["C2"]=12002)

# Bucket properties
declare -A BucketProperty=(["ramQuotaMB"]=100)
declare -A Bucket1Properties=(["ramQuotaMB"]=100 ["CompressionMode"]="Active")
insertPropertyIntoBucketNamePropertyMap "B0" BucketProperty
insertPropertyIntoBucketNamePropertyMap "B1" Bucket1Properties
insertPropertyIntoBucketNamePropertyMap "B2" BucketProperty

declare -A DefaultBucketReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=60 ["statsInterval"]=500)

# Bucket -> Scopes
# -----------------
declare -a scope1Arr=("S1" "S2")
BUCKET_NAME_SCOPE_MAP=(["B1"]=${scope1Arr[@]} ["B2"]="S3")

# Scopes -> Collections
# ----------------------
declare -a collection1Arr=("col1" "col2")
declare -a collection2Arr=("col1" "col2" "col3")
SCOPE_NAME_COLLECTION_MAP=(["S1"]=${collection1Arr[@]} ["S2"]=${collection2Arr[@]} ["S3"]=${collection2Arr[@]})

function runDataLoad {
	runCbWorkloadGenCollection "C1" "B1" "S1" "col1" &
	waitForBgJobs
}

function cleanupTestCaseInternalSettings {
	resetCustomManifestRefreshInterval "C1"
}

function runTestCase {
	echo "============================================================================"
	echo "Running live rediscover test case for huge amount of backfill with 1 vb limit"
	echo "============================================================================"
	testForClusterRun
	if (($? != 0)); then
		exit $?
	fi

	# First setup mis-matching mapping meaning all the data reside in C1
	setupTopologies
	if (($? != 0)); then
		exit $?
	fi
	# Before doing provisioning, get old internal settings
	setCustomManifestRefreshInterval "C1"

	# At this point, settings need to be restored IF the script was forced exited
	trap cleanupTestCaseInternalSettings EXIT

	local currentClusterLog=$(getClusterLogs "C1")
	local currentBrokenInstanceCnt=$(echo "$currentClusterLog" | grep -c "$BROKEN_MSG")
	local currentRepairedInstanceCnt=$(echo "$currentClusterLog" | grep -c "$REPAIR_MSG")

	# Wait for vbuckets and all the other things to propagate before XDCR provisioning
	sleep 5
	createRemoteClusterReference "C1" "C2"
	createRemoteClusterReference "C2" "C1"
	sleep 1
	createBucketReplication "C1" "B1" "C2" "B2" DefaultBucketReplProperties
	createBucketReplication "C2" "B2" "C1" "B1" DefaultBucketReplProperties
	printGlobalScopeAndCollectionInfo

	# To make sure ThroughSeqnoTracker's killTimer comes into picture
	echo "Setting XmemMaxRetryInterval=2 and XmemMaxRetry=8"
	setInternalSettings "C1" "XmemMaxRetryInterval=2" "XmemMaxRetry=8"

	# To make sure dcp backfill progresses one vb at a time
	echo "Setting dcp_backfill_in_progress_per_connection_limit=1"
	runCbepctl "C1" "B1" "dcp_param" "dcp_backfill_in_progress_per_connection_limit" 1
	if (($? != 0)); then
		exit $?
	fi

	# Populate large amount of data to get a dcp disk backfill
	numDocs=100000
	echo "Writing $numDocs docs in B1.S1.col1 of C1. 25GB+ of data, will take a while..."
	runCbcPillowFight "C1" "B1" $numDocs "S1" "col1"
	if (($? != 0)); then
		exit $?
	fi

	echo "Waiting 30 seconds before checking item count first pass"
	sleep 30

	# One broken msg for B1.S1.c1 -> B2.S1.c1
	validateLogWithInstance "C1" "$BROKEN_MSG" $(($currentBrokenInstanceCnt + 1))

	# Validate brokenmap exists
	validateBrokenMapExists "C1"
	validateBrokenMapEntry "C1" "S1" "col1" "S1" "col1"

	# Then re-setup the implicit matching that matches
	BUCKET_NAME_SCOPE_MAP=(["B1"]=${scope1Arr[@]} ["B2"]="S1")
	setupTopologies
	printGlobalScopeAndCollectionInfo

	echo "Sleeping 120 seconds for discovery and automatic backfill"
	runDataLoad
	sleep 120

	# After sleeping, the backfill manager should have triggered the backfill
	checkItemCnt "C1" "B1" $(($numDocs + $CBWORKLOAD_COLLECTION_NUM_ITEMS))
	checkItemCnt "C2" "B2" $(($numDocs + $CBWORKLOAD_COLLECTION_NUM_ITEMS))

	validateLogWithInstance "C1" "$REPAIR_MSG" $(($currentRepairedInstanceCnt + 1))
	validateInternalLogWithInstance "C1" "$BACKFILL_KILLED" 0

	grepForPanics
	validateXDCRCheckpoints "C1"
	validateXDCRCheckpoints "C2"

	echo "============================================================================"
	echo "PASSED"
	echo "============================================================================"

	cleanupBucketReplications
	cleanupBuckets
	cleanupRemoteClusterRefs

	cleanupTestCaseInternalSettings
	# remove trap as no longer needed
	trap - EXIT
}
