# Copyright (c) 2019-2020 Couchbase, Inc.
# Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file
# except in compliance with the License. You may obtain a copy of the License at
#   http://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software distributed under the
# License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
# either express or implied. See the License for the specific language governing permissions
# and limitations under the License.

# =============================
# topological map information
# =============================
# cluster -> Bucket(s)
# -----------------
CLUSTER_NAME_PORT_MAP=(["C1"]=9000 ["C2"]=9001)
CLUSTER_NAME_XDCR_PORT_MAP=(["C1"]=13000 ["C2"]=13001)
# Set c1 to have 2 buckets and c2 to have 1 bucket
declare -a cluster1BucketsArr
cluster1BucketsArr=("B0" "B1")
CLUSTER_NAME_BUCKET_MAP=(["C1"]=${cluster1BucketsArr[@]}  ["C2"]="B2")

# Bucket properties
declare -A BucketProperty=(["ramQuotaMB"]=100)
declare -A Bucket1Properties=(["ramQuotaMB"]=100 ["CompressionMode"]="Active")
insertPropertyIntoBucketNamePropertyMap "B0" BucketProperty
insertPropertyIntoBucketNamePropertyMap "B1" Bucket1Properties
insertPropertyIntoBucketNamePropertyMap "B2" BucketProperty

declare -A DefaultBucketReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=60 ["statsInterval"]=500)
declare -A ExplicitReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=60 ["statsInterval"]=500 ["collectionsExplicitMapping"]="true" ["colMappingRules"]='{"S1.col1":"S3.col3", "S2.col1":"S3.col1"}')

# Bucket -> Scopes
# -----------------
declare -a scope1Arr=("S1" "S2")
BUCKET_NAME_SCOPE_MAP=(["B1"]=${scope1Arr[@]} ["B2"]="S3")

# Scopes -> Collections
# ----------------------
declare -a collection1Arr=("col1" "col2")
declare -a collection2Arr=("col1" "col2" "col3")
SCOPE_NAME_COLLECTION_MAP=(["S1"]=${collection1Arr[@]} ["S2"]=${collection2Arr[@]} ["S3"]=${collection2Arr[@]})


function runDataLoad {
	# Run CBWorkloadgen in parallel
	runCbWorkloadGenCollection "C1" "B1" "S1" "col1" &
	runCbWorkloadGenCollection "C1" "B1" "S2" "col1" &
	runCbWorkloadGenCollection "C1" "B1" "S2" "col2" &
	waitForBgJobs
}


declare -i ORIG_TARGET_MAN_PULL_INTERVAL

function runTestCase {
	echo "============================================================================"
	echo "Running basic explicit mapping test case - new explicit map replication"
	echo "============================================================================"
	testForClusterRun
	if (( $? != 0 ));then
		exit $?
	fi

	# First setup mis-matching mapping meaning all the data reside in C1
	setupTopologies
	if (( $? != 0 ));then
		exit $?
	fi

    local -i checkCount
    local -i targetCheckCount
    checkCount=$(( $CBWORKLOAD_COLLECTION_NUM_ITEMS * 3 ))
    targetCheckCount=$(( $CBWORKLOAD_COLLECTION_NUM_ITEMS * 2 ))

	# Get current instance
    local -i currentBackfillInstanceCnt
    local -i currentVBTasksDoneInstanceCnt
	local -i currentBackfillAppendInstanceCnt
	local -i currentOsoModeCnt
	local currentXdcrLog

    currentXdcrLog=`getInternalNodeXdcrLog "C1"`
    currentBackfillInstanceCnt=`echo "$currentXdcrLog" | grep -c "$BACKFILL_MSG"`
    currentBackfillAppendInstanceCnt=`echo "$currentXdcrLog" | grep -c "$BACKFILL_APPEND_MSG"`
    currentVBTasksDoneInstanceCnt=`echo "$currentXdcrLog" | grep -c "$VBTASKS_DONE_MSG"`
    currentOsoModeCnt=`echo "$currentXdcrLog" | grep -c "$OSO_MODE_MSG"`

	# Wait for vbuckets and all the other things to propagate before XDCR provisioning
	sleep 5
	createRemoteClusterReference "C1" "C2"
	createRemoteClusterReference "C2" "C1"
	sleep 1
	createBucketReplication "C1" "B1" "C2" "B2" ExplicitReplProperties
	createBucketReplication "C2" "B2" "C1" "B1" DefaultBucketReplProperties
	printGlobalScopeAndCollectionInfo
	
	runDataLoad

	echo "VALIDATING Data..."
	validateCbWorkloadGenCollection "C2" "B2" "S3" "col3" "C1" "B1" "S1" "col1"

	echo "Waiting 5 seconds before checking item count first pass"
	sleep 5
	checkItemCnt "C1" "B1" $checkCount
	checkItemCnt "C2" "B2" $targetCheckCount

	# No backfill should be raised for first pass
	validateInternalLogWithInstance "C1" "$BACKFILL_MSG" $currentBackfillInstanceCnt

	# After replicating 10k items from a source collection to target collection
	# change the replication mapping to point to a new target collection
	# The backfill should kick in and fill in all the data to the new collection
	# resulting in twice the number of items on the target bucket
	echo "Changing explicit mapping - new target collection should now receive backfill"
	setReplicationSettings "C1" "B1" "C2" "B2" 'colMappingRules={"S2.col2":"S3.col2"}'

	echo "Waiting 5 seconds before checking item count for backfill"
	sleep 5
	checkItemCnt "C2" "B2" $checkCount

	# Backfill should have been raised
	validateInternalLogWithInstance "C1" "$BACKFILL_MSG"  $(( $currentBackfillInstanceCnt + 1 ))
	validateInternalLogWithInstance "C1" "$VBTASKS_DONE_MSG" $(( $currentVBTasksDoneInstanceCnt + 1 ))
	# 2 oso mode because one for each DCP nozzle
	#validateInternalLogWithInstance "C1" "$OSO_MODE_MSG" $(( $currentOsoModeCnt + 2 ))
	grepForPanics
	validateXDCRCheckpoints "C1"
	validateXDCRCheckpoints "C2"

	echo "============================================================================"
	echo "PASSED"
	echo "============================================================================"
	exportProvisionedConfig
	cleanupBucketReplications
 	cleanupBuckets
 	cleanupRemoteClusterRefs
}
