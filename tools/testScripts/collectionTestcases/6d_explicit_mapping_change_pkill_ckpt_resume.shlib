# Copyright 2025-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# =============================
# topological map information
# =============================
# cluster -> Bucket(s)
# -----------------
CLUSTER_NAME_PORT_MAP=(["C1"]=9000 ["C2"]=9001)
CLUSTER_NAME_XDCR_PORT_MAP=(["C1"]=13000 ["C2"]=13001)
CLUSTER_NAME_BUCKET_MAP=(["C1"]="B1" ["C2"]="B2")

# Bucket properties
declare -A BucketProperty=(["ramQuotaMB"]=100)
declare -A Bucket1Properties=(["ramQuotaMB"]=100 ["CompressionMode"]="Active")
insertPropertyIntoBucketNamePropertyMap "B0" BucketProperty
insertPropertyIntoBucketNamePropertyMap "B1" Bucket1Properties
insertPropertyIntoBucketNamePropertyMap "B2" BucketProperty

declare -A DefaultBucketReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=6000 ["statsInterval"]=500)
declare -A ImplicitReplProperties=(["replicationType"]="continuous" ["checkpointInterval"]=6000 ["statsInterval"]=500 ["collectionsOSOMode"]="false" ["xdcrDevBackfillSendDelayMs"]=10000 ["collectionsExplicitMapping"]="true" ["colMappingRules"]='{"S1.col1":"S1.col1"}')

# Bucket -> Scopes
# -----------------
BUCKET_NAME_SCOPE_MAP=(["B1"]="S1")

# Scopes -> Collections
# ----------------------
declare -a collection1Arr=("col1" "col2" "col3")
SCOPE_NAME_COLLECTION_MAP=(["S1"]=${collection1Arr[@]})

function runDataLoad {
	# Run CBWorkloadgen in parallel
	runCbWorkloadGenCollection "C1" "B1" "S1" "col1" &
	runCbWorkloadGenCollection "C1" "B1" "S1" "col2" &
	waitForBgJobs
}

declare -i ORIG_TARGET_MAN_PULL_INTERVAL

HALTBACKFILLWITHCB_MSG="Restarting the current backfill pipeline"
BACKFILL_HANDLER_NIL="Backfill handler was nil, considering that there was no active backfill pipeline for"

function runTestCase {
	echo "==============================================================================="
	echo "Running explicit mapping - remove some collections from source and resume from old ckpt"
	echo "==============================================================================="
	testForClusterRun
	if (($? != 0)); then
		exit $?
	fi

	# First setup mis-matching mapping meaning all the data reside in C1
	setupTopologies
	if (($? != 0)); then
		exit $?
	fi

	cleanupGoxdcrLogs

	runDataLoad

	# Wait for vbuckets and all the other things to propagate before XDCR provisioning
	sleep 5
	createRemoteClusterReference "C1" "C2"
	sleep 1
	createBucketReplication "C1" "B1" "C2" "B2" ImplicitReplProperties
	seedInjectMainPipelineDelay "C1" "B1" "C2" "B2" $SEED_INJ_MAX_MAIN_DELAY_MS
	printGlobalScopeAndCollectionInfo

	echo "Waiting 15 seconds before checking item count first pass"
	sleep 15
	checkItemCnt "C2" "B2" 0

	# force a checkpointing operation
	pauseReplication "C1" "B1" "C2" "B2"
	sleep 10
	resumeReplication "C1" "B1" "C2" "B2"
	sleep 10

	# Add a col1, col2 and col3 on target
	# The backfill should kick in and fill in all the data to the new collections.
	# A backfill delay of 10s is set also.
	createScope "C2" "B2" "S1"
	createCollection "C2" "B2" "S1" "col1"
	createCollection "C2" "B2" "S1" "col2"
	printGlobalScopeAndCollectionInfo
	echo "Sleeping 100 seconds for discovery and automatic backfill"
	sleep 100

	# remove S1.col1 from explicit mapping and add S2.col2
	# and not backfill for S1.col1 anymore (via HaltBackfillWithCb)
	echo "Deleting source collection col3 from mapping - target collections should not have backfill anymore"
	setReplicationSettings "C1" "B1" "C2" "B2" 'colMappingRules={"S1.col2":"S1.col2"}'
	echo "Sleeping 100 seconds for discovery and automatic repair"
	sleep 100

	validateInternalLogWithInstance "C1" "$HALTBACKFILLWITHCB_MSG" 1
	validateInternalLogWithInstance "C1" "$BACKFILL_HANDLER_NIL" 0
	grepForPanics
	validateXDCRCheckpoints "C1"
	validateXDCRCheckpoints "C2"

	runCbWorkloadGenCollection "C1" "B1" "S1" "col1" &
	runCbWorkloadGenCollection "C1" "B1" "S1" "col2" &
	killGoXdcr "C1"
	waitForBgJobs

	echo "Sleeping 30s for backfill to start"
	sleep 30

	# speeden-up backfill before checking for changes_left and doc count
	echo "speedening up backfill for it to finish"
	setReplicationSettings "C1" "B1" "C2" "B2" "xdcrDevBackfillSendDelayMs=0"
	sleep 30

	checkUnidirectionalChangesLeft
	grepForPanics
	checkItemCnt "C1" "B1" $(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 2))
	tgtItemCnt=$(getBucketItemCount "C2" "B2")
	maxCnt=$(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 2))
	if (($tgtItemCnt == $maxCnt)); then
		echo "Item count should be lesser than $(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 2)), but is $tgtItemCnt"
		return 1
	fi

	# make sure if col1 is added back, and the new data is flowing now.
	setReplicationSettings "C1" "B1" "C2" "B2" 'colMappingRules={"S1.col1":"S1.col1","S1.col2":"S1.col2"}'
	sleep 2
	runCbWorkloadGenCollection "C1" "B1" "S1" "col1" "" "new" &
	echo "Sleeping 100 seconds for discovery and automatic backfill"
	sleep 100
	waitForBgJobs

	checkUnidirectionalChangesLeft
	grepForPanics
	# both source and target should have CBWORKLOAD_COLLECTION_NUM_ITEMS from col2 +
	# CBWORKLOAD_COLLECTION_NUM_ITEMS old col1 data +  CBWORKLOAD_COLLECTION_NUM_ITEMS new col1 data
	checkItemCnt "C1" "B1" $(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 3))
	checkItemCnt "C2" "B2" $(($CBWORKLOAD_COLLECTION_NUM_ITEMS * 3))

	echo "============================================================================"
	echo "PASSED"
	echo "============================================================================"
	cleanupBucketReplications
	cleanupBuckets
	cleanupRemoteClusterRefs
}
