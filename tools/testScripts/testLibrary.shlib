# Copyright 2019-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# CONSTANTS
BROKEN_MSG="Found following destination collection(s) missing (and will not get replicated to)"
REPAIR_MSG="Following collection mappings are now repaired and replicating"
BACKFILL_MSG="These collections need to backfill"
BACKFILL_APPEND_MSG="These collections need to append backfill"
VBTASKS_DONE_MSG="has finished processing one task for all requested VBs"
TIMEDOUT_TYPE1_MSG="Executing Action timed out"
TIMEDOUT_TYPE2_MSG="Executing Action2 timed out"
OSO_MODE_MSG="with OSO mode requested"
OSO_BACKFILL_COUNT="oso_received=10000"
DCP_CONVERT_ERR_MSG="Error converting VBTask to DCP Nozzle Task"
BROKENEVENT_TYPE=3
BACKFILL_PIPELINE_TORNDOWN_MSG="Background check task finished"
GOXDCR_IDLE_CPU_THRESHOLD=10
RECEIVE_P2P_REQ_MSG="Received peer-to-peer push requests"
RECEIVE_P2P_REQ_DONE_MSG="Done handling peer-to-peer push requests from"
TS_PREFIX="ts.Seqno"
PIPELINE_SHUTDOWN_DONE_MSG="status is finished shutting down"
P2P_DESERIALIZATION_ERR_MSG="has payloadCompressed but no payload after deserialization"
P2P_UNABLE_TO_RESPOND_MSG="Unable to respond to caller"
CKPT_MAPPING_NOT_FOUND_MSG="Error when getting brokenMapping for"
P2P_BACKFILL_PUSH_RECEIVED_MSG="received peer node push backfill replication"
UNABLE_TO_GET_HIGH_SEQNO_MSG="Unable to find any collection ID for getHighSeqno"
P2P_PULL_ERR_MSG="Unable to respond to caller given type"
BACKFILL_START_MSG="Starting BackfillPipeline"
TOPOLOGY_RESTART_MSG="Topology change detected. Estimated time of pipeline restart"
DCP_ROLLBACK_MSG="Received rollback from DCP stream"
P2P_PULL_MANIFEST_ERR="Unable to retrieve peer manifests for new spec"
XMEM_REPAIR_CONNECTION="Repairing connection"
BACKFILL_PIPELINE_START="Starting BackfillPipeline"
BACKFILL_KILLED="background waiting backfill streams to all be replicated timed out"
BAD_MAGIC_MSG="bad magic"
CKPTSEQNO_BACKARD="Checkpoint seqno went backward"
CKPT_GET_ERR="Error getting ckpt docs for"
BACKFILL_DEL_OP="metakv operation on backfill spec op=2"
BACKFILL_CLEANED="BackfillPipelineClean"
CHANGES_LEFT_0_WAIT_SECS=10
VAGRANT_LOG_DIR="/opt/couchbase/var/lib/couchbase/logs"
GETHIGHSEQNO_COLID_DNE="getHighSeqno could not find collection ID"
REPL_MISSING_WHEN_STARTING="Replication Status is missing when starting pipeline"

# These should be imported after clusterRunProvision script

function checkItemCnt {
	local cluster=$1
	local bucket=$2
	local expectedCnt=$3
	local i

	local previousItemCnt=0
	local maxCnt=8
	for ((i = 0; $i < $maxCnt; i = $(($i + 1)))); do
		echo "Checking item count $(($i + 1)) / $maxCnt"
		itemCount=$(getBucketItemCount "$cluster" "$bucket")
		if (($itemCount == $expectedCnt)); then
			echo "Item count for cluster $cluster bucket $bucket: $itemCount"
			return 0
		else
			if (($itemCount != $previousItemCnt)); then
				previousItemCnt=$itemCount
				i=$(($i - 1))
				echo "WARN: Cluster $cluster bucket $bucket only has $itemCount items. Expect $expectedCnt. Items are increasing..."
			else
				echo "WARN: Cluster $cluster bucket $bucket only has $itemCount items"
			fi
		fi
		echo "Sleeping 10 seconds and retrying..."
		sleep 10
	done
	echo "ERROR: Cluster $cluster bucket $bucket has $itemCount items - failed to match expected items count of $expectedCnt"
	read -p "Press any key once done investigating"
	dumpDebugInfoBeforeExit
	exit 1
}

# Assumes running test script from this directory
function getNsServerDir {
	# Currently this test library exists under goproj/src/github.com/couchbase/goxdcr/tools/testScripts/
	local couchbaseDir="../../../../../../../"
	echo "${couchbaseDir}ns_server"
	return 0
}

function grepForPanics {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"
	for dir in $(ls $logsDir); do
		count=$(grep -c panic ${logsDir}/${dir}/goxdcr.log)
		if (($count > 0)); then
			echo "WARNING Found panics in ${logsDir}/${dir}"
			exit 1
		fi
	done
	return 0
}

function grepForErrs {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"
	for dir in $(ls $logsDir); do
		count=$(grep -c "decoding source mutation" ${logsDir}/${dir}/goxdcr.log)
		if (($count > 0)); then
			echo "WARNING Found err:decoding source mutation in ${logsDir}/${dir}"
			exit 1
		fi
	done
	return 0
}

function grepForPipelineFailures {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"
	for dir in $(ls $logsDir); do
		count=$(grep -c "Failed to start the pipeline" ${logsDir}/${dir}/goxdcr.log)
		if (($count > 0)); then
			echo "WARNING Found err:Failed to start the pipeline in ${logsDir}/${dir}/goxdcr.log"
			return 1
		fi
	done
	return 0
}

function grepForEINVAL {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"
	for dir in $(ls $logsDir); do
		count=$(grep -c "EINVAL" ${logsDir}/${dir}/goxdcr.log)
		if (($count > 0)); then
			echo "WARNING Found EINVAL in ${logsDir}/${dir}"
			exit 1
		fi
	done
	return 0
}

function grepForInvalidCommand {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "Invalid format specified" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found invalid format in ${logsDir}/${dir}"
				exit 1
			fi
		done
	done
	return 0
}

function grepForMultiError {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "SUBDOC_BAD_MULTI" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found SUBDOC_BAD_MULTI in ${logsDir}/${dir}"
				exit 1
			fi
		done
	done
	return 0
}

function grepForDecodingError {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "error decoding" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found 'error decoding' in ${logsDir}/${dir}"
				exit 1
			fi
		done
	done
	return 0
}

function grepForUnknownResponse {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "received error response from setMeta client. Repairing connection" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found 'received error response from setMeta client. Repairing connection' in ${logsDir}/${dir}"
				exit 1
			fi
		done
	done
	return 0
}

function grepForCollectionIdAbsentError {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"
	local found=0

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "received a request with colId" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found 'received a request with colId' in ${logsDir}/${dir}"
				found=1
			fi
		done
	done

	# If occurrences are found, exit
	if (($found != 0)); then
		exit 1
	fi

	return 0
}

function grepForTgtColNamespaceNilError {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"
	local found=0

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "manifest cache validation failed: unexpected nil target collection namespace" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found 'manifest cache validation failed: unexpected nil target collection namespace' in ${logsDir}/${dir}"
				found=1
			fi
		done
	done

	# If occurrences are found, exit
	if (($found != 0)); then
		exit 1
	fi

	return 0
}

function grepForNonMonotonicThroughSeqno {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "nonMonoTS=[1-9]" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found 'nonMonoTS' in ${logsDir}/${dir}"
				exit 1
			fi
		done
	done
	return 0
}

function grepForUnusualOSOSessionEnds {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "unusualEnd=[1-9]" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found 'unusualEnd' in ${logsDir}/${dir}"
				exit 1
			fi
		done
	done
	return 0
}

function grepForFaultyCLogTrackers {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "faultyCLog=[1-9]" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found 'faultyCLog' in ${logsDir}/${dir}"
				exit 1
			fi
		done
	done
	return 0
}

function getDataReplicated {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	echo $(getStats "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket" "data_replicated")
}

function getChangesLeft {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	echo $(getStats "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket" "changes_left")
	if (($? != 0)); then
		echo "Failed to get stats"
		return 1
	fi
}

function getDocsProcessed {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	echo $(getStats "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket" "docs_processed")
}

function waitForChangesLeft0 {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local changesLeft
	local lastChangesLeft=-1
	local i

	for ((i = 0; $i < $CHECK_CHANGES_LEFT_MAX; i = $(($i + 1)))); do
		changesLeft=$(getChangesLeft "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket")
		if (($? != 0)); then
			echo "Failed to get changes_left"
			dumpDebugInfoBeforeExit
			exit 1
		fi
		if [[ -z "${changesLeft:-}" ]]; then
			echo "Changes left is empty. Trying again..."
			sleep $CHANGES_LEFT_0_WAIT_SECS
			continue
		elif [[ "$changesLeft" == "null" ]]; then
			echo "Changes left is null. Trying again..."
			sleep $CHANGES_LEFT_0_WAIT_SECS
			continue
		elif (($changesLeft > 0)); then
			echo "Changes left $changesLeft is not 0 yet..."
		elif (($changesLeft == 0)); then
			return 0
		else
			echo "Changes left unknown value: $changesLeft"
		fi
		if (($changesLeft == $lastChangesLeft)); then
			echo "Changes left is not going down. It is still $changesLeft"
		else
			lastChangesLeft=$changesLeft
			i=$(($i - 1))
			echo "Changes left is not 0. It is $changesLeft... it is decreasing"
		fi
		sleep $CHANGES_LEFT_0_WAIT_SECS
	done

	echo "changes_left never went to zero for $1.$2 -> $3.$4"
	dumpDebugInfoBeforeExit
	exit 1
}

function checkNonNegativeChangesLeft {
	local srcCluster=$1
	validateLogWithInstance "$srcCluster" "changes_left=-" 0
}

function checkChangesLeftInternal {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	checkChangesLeftInternalWithSpecifiedCount "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket" 0
}

# SGW Active Active will have heartbeat document so changes left == 1
function checkChangesLeftInternalSGW {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	checkChangesLeftInternalWithSpecifiedCount "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket" 1
}

function checkChangesLeftInternalWithSpecifiedCount {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local specifiedCount=$5
	local i

	local lastChangesLeft=0

	for ((i = 0; $i < $CHECK_CHANGES_LEFT_MAX; i = $(($i + 1)))); do
		changesLeft=$(getChangesLeft "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket")
		if [[ -z "${changesLeft:-}" ]] || [[ "$changesLeft" == "null" ]]; then
			changesLeft=999999
		fi
		if (($changesLeft <= $specifiedCount)); then
			echo "Node $srcCluster changes_left is $changesLeft"
			checkNonNegativeChangesLeft "$srcCluster"
			return 0
		else
			if (($changesLeft == $lastChangesLeft)); then
				echo "Node $srcCluster Changes left is not $specifiedCount. It is $changesLeft"
			else
				lastChangesLeft=$changesLeft
				i=$(($i - 1))
				echo "Node $srcCluster Changes left is not $specifiedCount. It is $changesLeft... it is decreasing"
			fi
			sleep 10
		fi
	done
	dumpDebugInfoBeforeExit
	exit 1
}

function checkUnidirectionalChangesLeft {
	checkChangesLeftInternal "C1" "B1" "C2" "B2"
}

function checkUnidirectionalChangesLeftSGW {
	checkChangesLeftInternalSGW "C1" "B1" "C2" "B2"
}

function checkBidirectionalChangesLeft {
	checkChangesLeftInternal "C1" "B1" "C2" "B2"
	checkChangesLeftInternal "C2" "B2" "C1" "B1"
}

function checkBidirectionalChangesLeftSGW {
	checkChangesLeftInternalSGW "C1" "B1" "C2" "B2"
	checkChangesLeftInternalSGW "C2" "B2" "C1" "B1"
}

function checkDataReplicatedIsZero {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local oldDataReplicated=$5
	local i

	for ((i = 0; $i < 3; i = $(($i + 1)))); do
		dataReplicated=$(getDataReplicated "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket")
		if (($dataReplicated > 0)); then
			echo "Data replicated $dataReplicated is not 0 yet..."
			if (($dataReplicated != $oldDataReplicated)); then
				echo "Error: Data replicated is different from previous replicated $oldDataReplicated"
				break
			fi
		else
			return 0
		fi
		echo "Sleeping 10 seconds and retrying..."
		sleep 10
	done
	exit 1
}

function checkDocsProcessed {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local docsProcessedCheck=$5
	local prevDocsProcessed=0
	local i

	for ((i = 0; $i < 5; i = $(($i + 1)))); do
		docsProcessed=$(getDocsProcessed "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket")
		if (($docsProcessed != $docsProcessedCheck)); then
			if (($docsProcessed != $prevDocsProcessed)); then
				prevDocsProcessed=$docsProcessed
				i=$(($i - 1))
				echo "DocsProcessed: $docsProcessed. Waiting for it to be $docsProcessedCheck... Items are increasing"
			else
				echo "DocsProcessed: $docsProcessed. Waiting for it to be $docsProcessedCheck..."
			fi
		else
			return 0
		fi
		echo "Sleeping 10 seconds and retrying..."
		sleep 10
	done
	dumpDebugInfoBeforeExit
	exit 1
}

function getSpecificInternalSettings {
	local clusterName=$1
	local key=$2

	echo $(listInternalSettings "$clusterName" | jq ".$key")
}

function killGoXdcr {
	local clusterName=$1
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local sourceXdcrPort=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	if [[ -z "$sourcePort" ]]; then
		echo "Unable to kill goxdcr as source port is not found"
	fi

	echo "Killing GoXDCR for $clusterName with port $sourcePort..."
	ps -ef | grep goxdcr | grep $sourcePort | awk '{print $2}' | xargs kill

	local checkCode=1
	local currentTime=$(date +%s)
	while (($checkCode != 0)); do
		sleep 5
		$CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourceXdcrPort/pools/default/replications >/dev/null 2>&1
		checkCode=$?
	done
}

function killMemcached {
	local nodePrefix=$1

	ps -ef | grep memcached | grep -v grep | grep -v beam | grep "$nodePrefix" | awk '{print $2}' | xargs kill -9
}

function killMobileImportSim {
	local clusterName=$1
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local bucketName=$2

	if [[ -z "$sourcePort" ]]; then
		echo "Unable to kill MobileImportSim as source port is not found"
	fi

	if [[ -z "$bucketName" ]]; then
		echo "Unable to kill MobileImportSim as bucketName is not found"
	fi

	echo "Killing mobile import simulator for $clusterName with port $sourcePort and $bucketName..."
	ps -ef | grep mobileImportSim | grep "hostAddr 127.0.0.1:$sourcePort" | grep "bucketname $bucketName" | awk '{print $2}' | xargs kill
}

# Input:
# 1 - cluster name
# 2 - String to look for
# 3 - Number of occurrences
# 4 - Max number of occurrences
function validateLogWithInstance {
	local clusterName=$1
	local grepStr="$2"
	local instanceCnt=$3
	local maxInstanceCnt=${4:-}

	local logs=$(getClusterLogs "$clusterName")
	if ! (($? == 0)); then
		echo "Unable to get log for validation"
		return 1
	fi

	count=$(echo "$logs" | grep -c "$grepStr")
	if (($count != $instanceCnt)); then
		if [[ ! -z "$maxInstanceCnt" ]] && (($count > $maxInstanceCnt)); then
			echo "Error - requested count for $grepStr is $instanceCnt or < $maxInstanceCnt, but found $count"
			dumpDebugInfoBeforeExit
			echo "Logs: $logs" >/tmp/testOutput.log
			echo "Console logs saved as /tmp/testOutput.log"
			exit 1
		elif [[ ! -z "$maxInstanceCnt" ]]; then
			echo "Warning - requested count for $grepStr is $instanceCnt or < $maxInstanceCnt, found $count"
		else
			echo "Error - requested count for $grepStr is $instanceCnt, but found $count"
			dumpDebugInfoBeforeExit
			echo "Logs: $logs" >/tmp/testOutput.log
			echo "Console logs saved as /tmp/testOutput.log"
			exit 1
		fi
	else
		echo "Found exactly $instanceCnt of \"$grepStr\""
	fi
}

declare -i ORIG_TARGET_MAN_PULL_INTERVAL

function setCustomManifestRefreshInterval {
	local cluster="$1"

	for ((i = 0; i < 2; i = $(($i + 1)))); do
		ORIG_TARGET_MAN_PULL_INTERVAL=$(getSpecificInternalSettings "$cluster" "ManifestRefreshTgtInterval")
		tempTargetManifestPullInterval="5"

		echo "Temporarily updating targetManifestPull from $ORIG_TARGET_MAN_PULL_INTERVAL to $tempTargetManifestPullInterval"
		setInternalSettings "$cluster" "ManifestRefreshTgtInterval=$tempTargetManifestPullInterval"

		echo "Sleeping 10 seconds for XDCR to reboot before checking..."
		sleep 10
		chkTargetManifestPullInterval=$(getSpecificInternalSettings "$cluster" "ManifestRefreshTgtInterval")
		if (($chkTargetManifestPullInterval == $tempTargetManifestPullInterval)); then
			return 0
		else
			echo "Error - unable to update pull interval - stuck at $chkTargetManifestPullInterval. Trying again..."
		fi
	done
	exit 1
}

function resetCustomManifestRefreshInterval {
	local cluster="$1"
	echo "Cleaning up internal settings"
	setInternalSettings "C1" "ManifestRefreshTgtInterval=$ORIG_TARGET_MAN_PULL_INTERVAL"
}

function getInternalNsServerLogDir {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	local lastDigit=$(echo "${port: -1}")
	local logNodeDir="n_${lastDigit}"

	# Currently this test library exists under goproj/src/github.com/couchbase/goxdcr/tools/testScripts/
	local nsServerLogDir="../../../../../../../ns_server/logs/"

	echo "${nsServerLogDir}/${logNodeDir}/"
}

function getInternalNodeMemcachedLog {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	# TODO - memcached log rotates and the filename changes
	# Vagrant may be harder
	local logfileDir=$(getInternalNsServerLogDir "$clusterName")

	local memcachedLog
	for memcachedLog in $(ls $logfileDir | grep memcached); do
		cat ${logfileDir}/${memcachedLog}
	done
}

function getInternalNodeXdcrLog {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName" >&2
		return 1
	fi

	if [[ ! -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
		vagrantGetInternalNodeLog "$clusterName" "goxdcr.log"
		return $?
	fi

	local logfileDir=$(getInternalNsServerLogDir "$clusterName")

	local goxdcrLogFile=${logfileDir}/goxdcr.log
	if ! [[ -f "$goxdcrLogFile" ]]; then
		echo "Unable to find file $goxdcrLogFile" >&2
		return 1
	fi

	cat $goxdcrLogFile
}

function getInternalNodeMetaKvLog {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	if [[ ! -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
		vagrantGetInternalNodeLog "$clusterName" "metakv.log"
		return $?
	fi

	local logfileDir=$(getInternalNsServerLogDir "$clusterName")

	local metaKvLog=${logfileDir}/metakv.log
	if ! [[ -f "$metaKvLog" ]]; then
		echo "Unable to find file $metaKvLog"
		return 1
	fi

	cat $metaKvLog
}

function getInternalNodeNsServerInfoLog {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	if [[ ! -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
		vagrantGetInternalNodeLog "$clusterName" "info.log"
		return $?
	fi

	local logfileDir=$(getInternalNsServerLogDir "$clusterName")

	local info=${logfileDir}/info.log
	if ! [[ -f "$info" ]]; then
		echo "Unable to find file $info"
		return 1
	fi

	cat $info
}

function getInternalNodeNsServerDebugLog {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	if [[ ! -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
		vagrantGetInternalNodeLog "$clusterName" "debug.log"
		return $?
	fi

	local logfileDir=$(getInternalNsServerLogDir "$clusterName")

	local debug=${logfileDir}/debug.log
	if ! [[ -f "$debug" ]]; then
		echo "Unable to find file $debug"
		return 1
	fi

	cat $debug
}

# Used only if the log needs to be clean for parsing purposes
function clearInternalNodeXdcrLog {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	local logfileDir=$(getInternalNsServerLogDir "$clusterName")

	local goxdcrLogFile=${logfileDir}/goxdcr.log
	if ! [[ -f "$goxdcrLogFile" ]]; then
		echo "Unable to find file $goxdcrLogFile"
		return 1
	fi

	local gcFileName=${goxdcrLogFile}.$(date +%s)
	mv $goxdcrLogFile $gcFileName
	rm $gcFileName

	sleep 2
	local logValidated=0
	local checkOpCode=1
	local logs

	while (($logValidated == 0)); do
		logs=$(getInternalNodeXdcrLog "$clusterName")
		checkOpCode=$?
		while (($checkOpCode != 0)); do
			sleep 2
			logs=$(getInternalNodeXdcrLog "$clusterName")
			checkOpCode=$?
		done

		# Check lines in the logs
		local lineCnt=0
		lineCnt=$(echo "$logs" | wc -l)
		if (($lineCnt > 0)); then
			logValidated=1
		fi
	done
}

function waitForOneReplicationToBeDeleted {
	local clusterName=$1
	local srcBucketName=$2
	local tgtBucketName=$3
	local currentInstanceCnt=0

	logs=$(getInternalNodeXdcrLog "$clusterName")
	if ((!$? == 0)); then
		echo "Unable to get log for validation" >&2
		exit 1
	fi

	#	2021-11-03T17:44:45.353-07:00 INFO GOXDCR.PipelineMgr: Replication ebf93073d83a1951c6454753536a6eb5/B1/B2's status is finished shutting down
	currentInstanceCnt=$(echo "$logs" | grep "$PIPELINE_SHUTDOWN_DONE_MSG" | grep -c "$srcBucketName\/$tgtBucketName")
	waitForInternalLogInstance "$clusterName" "$PIPELINE_SHUTDOWN_DONE_MSG" "$(($currentInstanceCnt + 1))" 2 "$srcBucketName\/$tgtBucketName"

	if ((!$? == 0)); then
		echo "Timed out waiting for message $PIPELINE_SHUTDOWN_DONE_MSG with buckets "$srcBucketName/$tgtBucketName" to increase from $currentInstanceCnt by 1" >&2
		dumpDebugInfoBeforeExit
		exit 1
	fi
}

# 1 - cluster name
# 2 - String to look for
# 3 - Minimum Number of occurrences to wait for
# 4 - Number of minutes to wait for
function waitForInternalLogInstance {
	local clusterName=$1
	local grepStr="$2"
	local instanceCnt=$3
	local minToWait=$4
	local optionalGrepStr=${5:-}
	local minElapsed=0
	local i=0

	while (($minElapsed < $minToWait)); do
		logs=$(getInternalNodeXdcrLog "$clusterName")
		if ((!$? == 0)); then
			echo "Unable to get log for validation" >&2
			return 1
		fi

		if [[ -z "$optionalGrepStr" ]]; then
			count=$(echo "$logs" | grep -c "$grepStr")
			if (($count >= $instanceCnt)); then
				echo "Found $instanceCnt instances of the string: $grepStr" >&2
				return
			fi
		else
			count=$(echo "$logs" | grep "$grepStr" | grep -c "$optionalGrepStr")
			if (($count >= $instanceCnt)); then
				echo "Found $instanceCnt instances of the string: $grepStr with $optionalGrepStr" >&2
				return
			fi
		fi

		sleep 10
		i=$(($i + 1))
		if (($i == 6)); then
			minElapsed=$(($minElapsed + 1))
			i=0
		fi
	done

	return 1
}

# 1 - cluster name
# 2 - String to look for
# 3 - Number of occurrences
# 4 - Max number of occurrences
function validateInternalLogWithInstance {
	local clusterName=$1
	local grepStr="$2"
	local instanceCnt=$3
	local maxInstanceCnt=${4:-}

	logs=$(getInternalNodeXdcrLog "$clusterName")
	if ! (($? == 0)); then
		echo "Unable to get log for validation"
		exit 1
	fi

	count=$(echo "$logs" | grep -c "$grepStr")
	if (($count != $instanceCnt)); then
		if [[ ! -z "$maxInstanceCnt" ]] && (($count > $maxInstanceCnt)); then
			echo "Error - requested count for \"$grepStr\" is $instanceCnt or <= $maxInstanceCnt, but found $count" >&2
			dumpDebugInfoBeforeExit
			exit 1
		elif [[ ! -z "$maxInstanceCnt" ]] && (($count < $instanceCnt)); then
			echo "Error - requested count for \"$grepStr\" is $instanceCnt or <= $maxInstanceCnt, but found $count" >&2
			dumpDebugInfoBeforeExit
			exit 1
		elif [[ ! -z "$maxInstanceCnt" ]]; then
			echo "Warning - requested count for \"$grepStr\" is $instanceCnt or <= $maxInstanceCnt, found $count" >&2
		else
			echo "Error - requested count for \"$grepStr\" is $instanceCnt, but found $count" >&2
			dumpDebugInfoBeforeExit
			exit 1
		fi
	else
		echo "Found exactly $instanceCnt of \"$grepStr\""
	fi
}

function validateInternalLogWithInstanceWithGrepV {
	local clusterName=$1
	local grepStr="$2"
	local inverseStr="$3"
	local instanceCnt=$4
	local maxInstanceCnt=${5:-}

	logs=$(getInternalNodeXdcrLog "$clusterName")
	if ! (($? == 0)); then
		echo "Unable to get log for validation"
		exit 1
	fi

	count=$(echo "$logs" | grep "$grepStr" | grep -v "$inverseStr" | wc -l)
	if (($count != $instanceCnt)); then
		if [[ ! -z "$maxInstanceCnt" ]] && (($count > $maxInstanceCnt)); then
			echo "Error - requested count for \"$grepStr\" without \"$inverseStr\" is $instanceCnt or <= $maxInstanceCnt, but found $count" >&2
			dumpDebugInfoBeforeExit
			exit 1
		elif [[ ! -z "$maxInstanceCnt" ]] && (($count < $instanceCnt)); then
			echo "Error - requested count for \"$grepStr\" without \"$inverseStr\" is $instanceCnt or <= $maxInstanceCnt, but found $count" >&2
			dumpDebugInfoBeforeExit
			exit 1
		elif [[ ! -z "$maxInstanceCnt" ]]; then
			echo "Warning - requested count for \"$grepStr\" without \"$inverseStr\" is $instanceCnt or <= $maxInstanceCnt, found $count" >&2
		else
			echo "Error - requested count for \"$grepStr\" without \"$inverseStr\" is $instanceCnt, but found $count" >&2
			dumpDebugInfoBeforeExit
			exit 1
		fi
	else
		echo "Found exactly $instanceCnt of \"$grepStr\" without \"$inverseStr\""
	fi
}

function validateXDCRCheckpoints {
	local cluster=$1

	checkpointOutput=$(getXDCRCheckpoints $cluster)
	if ! (($? == 0)); then
		echo "Unable to get checkpoint"
		dumpDebugInfoBeforeExit
		exit 1
	fi

	# validate
	echo "$checkpointOutput" | jq type >/dev/null
	if ! (($? == 0)); then
		echo "$checkpointOutput" >/tmp/checkpoint.error
		echo "Erroneous checkpoint output to /tmp/checkpoint.error"
		exit 1
	fi
}

function killAllBgJobs {
	jobs -l | awk '{print $2}' | xargs kill
}

function xdcrDifferParseOpts {
	local optsIn=$1

	if [[ "$optsIn" == "compareBody" ]]; then
		echo "-m body"
	elif [[ "$optsIn" == "retry" ]]; then
		echo "-e 2"
	elif [[ "$optsIn" =~ ^-o ]]; then
		# Out directory, just let it fly
		echo "$optsIn"
	fi
}

function runXdcrDiffer {
	local srcCluster=$1
	local srcPort=${CLUSTER_NAME_PORT_MAP[$srcCluster]:-}
	local srcBucket=$2
	local tgtCluster=$3
	local tgtBucket=$4
	local extraOpts1=${5:-}
	local extraOpts2=${6:-}
	local opts1Flag=""
	local opts2Flag=""
	local compareBody

	if [[ -n "${extraOpts1:-}" ]]; then
		opts1Flag="$(xdcrDifferParseOpts "$extraOpts1")"
	fi
	if [[ -n "${extraOpts2:-}" ]]; then
		opts2Flag="$(xdcrDifferParseOpts "$extraOpts2")"
	fi

	pushd $(pwd)

	cd $xdcrDifferDir
	$differSh -u $DEFAULT_ADMIN -p $DEFAULT_PW -h "127.0.0.1:$srcPort" -r $tgtCluster -s $srcBucket -t $tgtBucket -c "$opts1Flag" "$opts2Flag"
	retVal=$?

	popd
	return $retVal
}

function runXdcrDifferValidateNoDiff {
	local srcCluster=$1
	local srcBucket=$2
	local tgtCluster=$3
	local tgtBucket=$4

	local retVal
	runXdcrDiffer "$srcCluster" "$srcBucket" "$tgtCluster" "$tgtBucket"
	retVal=$?
	if (($retVal != 0)); then
		echo "Differ returned non-0 exit code"
		exit 1
	fi

	validateDifferResults 0 0 0 0 0
	retVal=$?
	if (($retVal != 0)); then
		echo "Failed"
		exit 1
	fi
}

function differGetTotalNumber {
	local input="$1"
	local collectionIDs
	local collectionID
	local sum=0

	collectionIDs=$(echo "$input" | jq 'keys' | jq .[])
	for collectionID in $(echo "$collectionIDs"); do
		local keys
		local numDocsForThisCollection
		keys=$(echo "$input" | jq ".$collectionID")
		numDocsForThisCollection=$(echo "$keys" | jq length)
		sum=$(($sum + $numDocsForThisCollection))
	done

	echo "$sum"
}

function validateDifferResults {
	local expectedMismatchCnt=$1
	local expectedMissingSrcCnt=$2
	local expectedMissingTgtCnt=$3
	local expectedDeletedSrcCnt=${4:-}
	local expectedDeletedTgtCnt=${5:-}

	if [[ ! -f "$mutationDiffResults" ]]; then
		echo "Error: Unable to find mutation results file: $mutationDiffResults"
		return 1
	fi

	resultOutput=$(cat $mutationDiffResults)
	validateDifferResultsInternal "$resultOutput" "$expectedMismatchCnt" "$expectedMissingSrcCnt" "$expectedMissingTgtCnt" "$expectedDeletedSrcCnt" "$expectedDeletedTgtCnt"
}

function validateDifferResultsInternal {
	local resultOutput="$1"
	local expectedMismatchCnt="$2"
	local expectedMissingSrcCnt="$3"
	local expectedMissingTgtCnt="$4"
	local expectedDeletedSrcCnt=${5:-}
	local expectedDeletedTgtCnt=${6:-}
	local numOfMismatch
	local numOfMissingSrc
	local numOfMissingTgt
	local numOfDeletedSrc
	local numOfDeletedTgt
	local resultOutput
	local retVal=0
	local mismatchOutput
	local missingFromSourceOutput
	local missingFromTargetOutput
	local deletedFromSourceOutput
	local deletedFromTargetOutput

	mismatchOutput=$(echo "$resultOutput" | jq '.Mismatch')
	missingFromSourceOutput=$(echo "$resultOutput" | jq '.MissingFromSource')
	missingFromTargetOutput=$(echo "$resultOutput" | jq '.MissingFromTarget')

	numOfMismatch=$(differGetTotalNumber "$mismatchOutput")
	numOfMissingSrc=$(differGetTotalNumber "$missingFromSourceOutput")
	numOfMissingTgt=$(differGetTotalNumber "$missingFromTargetOutput")

	if (($numOfMismatch != $expectedMismatchCnt)); then
		echo "Expected $expectedMismatchCnt mismatch(es), but found $numOfMismatch"
		retVal=1
	fi

	if (($numOfMissingSrc != $expectedMissingSrcCnt)); then
		echo "Expected $expectedMissingSrcCnt missing from source, but found $numOfMissingSrc"
		retVal=1
	fi

	if (($numOfMissingTgt != $expectedMissingTgtCnt)); then
		echo "Expected $expectedMissingTgtCnt missing from target, but found $numOfMissingTgt"
		retVal=1
	fi

	if [ ! -z "$expectedDeletedSrcCnt" ]; then
		deletedFromSourceOutput=$(echo "$resultOutput" | jq '.DeletedFromSource')
		numOfDeletedSrc=$(differGetTotalNumber "$deletedFromSourceOutput")
		if (($numOfDeletedSrc != $expectedDeletedSrcCnt)); then
			echo "Expected $expectedDeletedSrcCnt deleted from source, but found $numOfDeletedSrc"
			retVal=1
		fi
	fi

	if [ ! -z "$expectedDeletedTgtCnt" ]; then
		deletedFromTargetOutput=$(echo "$resultOutput" | jq '.DeletedFromTarget')
		numOfDeletedTgt=$(differGetTotalNumber "$deletedFromTargetOutput")
		if (($numOfDeletedTgt != $expectedDeletedTgtCnt)); then
			echo "Expected $expectedDeletedTgtCnt deleted from target, but found $numOfDeletedTgt"
			retVal=1
		fi
	fi

	if (($retVal == 1)); then
		echo "$resultOutput" | jq
		echo ""
	fi

	return $retVal
}

function checkDifferLogItemCount {
	local srcOrTgt=$1
	local itemCnt=$2
	local filteredCnt=$3
	local logFile="${xdcrDifferDir}/outputs/xdcrDiffer.log"
	local expected="$srcOrTgt bucket item count including tombstones is $itemCnt (excluding $filteredCnt filtered mutations)"

	found=$(grep -c "$expected" $logFile)
	if (($found == 0)); then
		echo "Did not find the line: \"$expected\" from the file $logFile"
		exit 1
	fi
	echo "Found the line: $expected"
}

function checkInternalSetting {
	local clusterName=$1
	local settingKey=$2
	local expectedVal=$3
	local checkInt

	checkInt=$(getInternalSetting "$clusterName" "$settingKey")
	if (($checkInt != $expectedVal)); then
		echo "$settingKey is not set to $expectedVal. It is $checkInt"
		exit 1
	fi
}

# TODO - right now assumes only one outgoing pipeline per cluster
function validateBrokenMapExists {
	local errList
	local cluster=$1

	errList=$(getErrorListForMainPipeline $cluster)
	if ((!$? == 0)); then
		echo "Issue getting error list"
		exit 1
	fi

	if (($(echo "$errList" | jq 'length') == 0)); then
		echo "See no error list"
		exit 1
	fi
}

function checkNoErrorInErrorList {
	local cluster="$1"
	validateNumberOfEvents "$cluster" 0
}

function validateNumberOfEvents {
	local errList
	local cluster=$1
	local count=$2

	waitForNumberOfEvents "$cluster" "$count" 0
	if (($? > 0)); then
		exit 1
	fi
}

function waitForNumberOfEvents {
	local errList
	local cluster=$1
	local count=$2
	local minToWaitFor=$3

	errList=$(getErrorListForMainPipeline $cluster)
	if ((!$? == 0)); then
		echo "Issue getting error list"
		exit 1
	fi

	local curMin=0
	local actualCount=$(echo "$errList" | jq 'length')
	if (($actualCount != $count)); then
		echo "Expecting $count in errorsList but found $actualCount"
		if (($minToWaitFor == 0)) || (($curMin > $minToWaitFor)); then
			return 1
		else
			curMin=$(($curMin + 1))
			echo "Waiting one minute and trying again"
			sleep 60
		fi
	fi
}

function validateBrokenMapDoesNotExist {
	local cluster=$1
	checkNoErrorInErrorList $cluster
}

# Ensures that a specified linkage is broken
function validateBrokenMapEntry {
	local cluster=$1
	local sourceScopeName=$2
	local sourceCollectionName=$3
	local targetScopeName=$4
	local targetCollectionName=$5

	getBrokenMapEntryId "$cluster" "$sourceScopeName" "$sourceCollectionName" "$targetScopeName" "$targetCollectionName"
	local entryId=$?
	if (($entryId == $GET_BROKEN_MAP_NOT_FOUND)); then
		exit 1
	fi
	echo "Got entry ID: $entryId"
}

function validateBrokenMapEntryDNE {
	local cluster=$1
	local sourceScopeName=$2
	local sourceCollectionName=$3
	local targetScopeName=$4
	local targetCollectionName=$5

	getBrokenMapEntryId "$cluster" "$sourceScopeName" "$sourceCollectionName" "$targetScopeName" "$targetCollectionName"
	if ((!$? == $GET_BROKEN_MAP_NOT_FOUND)); then
		echo "Found entry when not supposed to"
		exit 1
	fi
}

# returns the count of remote cluster ref from source to target
function getRemoteCluster {
	local source=$1
	local target=$2
	local host=${CLUSTER_NAME_HOST_MAP[$source]:-"127.0.0.1"}
	local port=${CLUSTER_NAME_PORT_MAP[$source]:-}
	result=$(curl -GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://$host:$port/pools/default/remoteClusters | jq | grep name | grep -c $target)
	echo $result
}

# returns the output from /pools/default/remoteClusters
function getRemoteClusters {
	local source=$1
	local host=${CLUSTER_NAME_HOST_MAP[$source]:-"127.0.0.1"}
	local port=${CLUSTER_NAME_PORT_MAP[$source]:-}
	result=$(curl -GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://$host:$port/pools/default/remoteClusters)
	echo $result
}

function checkReplicationInfos {
	local srcClusterName=$1

	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$srcClusterName]:-}
	local sourceHost=${CLUSTER_NAME_HOST_MAP[$srcClusterName]:-"127.0.0.1"}

	echo "curl -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://${sourceHost}:${sourcePort}/pools/default/replicationInfos"
	curl -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://${sourceHost}:${sourcePort}/pools/default/replicationInfos
}

function changeRemoteClusterReferenceToSecure {
	local source=$1
	local target=$2
	local targetHost=${3:-"127.0.0.1"}
	if [[ -z "${source:-}" ]] || [[ -z "${target:-}" ]]; then
		echo "Invalid input"
		return 1
	fi
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$source]:-}
	local targetPort=${4:-${CLUSTER_NAME_PORT_MAP[$target]}}
	local targetSecurePort=${CLUSTER_NAME_SECURE_PORT_MAP[$target]:-$targetPort}
	local remoteClusterCert=${5:-}

	# Get the target cluster's root certificate if not provided
	if [[ -z "${remoteClusterCert:-}" ]]; then
		remoteClusterCert=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://$targetHost:$targetPort/pools/default/certificate)
	fi

	echo "Change remote cluster reference from $source to $target ($targetHost:$targetPort) to SECURE"
	echo "$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/pools/default/remoteClusters/$target -d name=$target -d hostname=$targetHost:$targetSecurePort -d username=$DEFAULT_ADMIN -d password=$DEFAULT_PW -d encryptionType=full -d demandEncryption=1 --data-urlencode \"certificate=${remoteClusterCert}\""
	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/pools/default/remoteClusters/$target -d name=$target -d hostname=$targetHost:$targetSecurePort -d username=$DEFAULT_ADMIN -d password=$DEFAULT_PW \
		-d encryptionType=full -d demandEncryption=1 --data-urlencode "certificate=${remoteClusterCert}"
}

function testIdleXdcrCPU {
	local goxdcrCPUsOut
	local oldIFS
	local retResult=0

	goxdcrCPUsOut=$(ps -e -o pid,pcpu,comm | grep goxdcr)
	oldIFS="$IFS"
	IFS=$'\n'

	local oneXDCRProcess
	local oneXDCRCPU
	for oneXDCRProcess in $(echo "$goxdcrCPUsOut"); do
		oneXDCRCPU=$(echo "$oneXDCRProcess" | awk '{print $2}')
		if (($(echo "$oneXDCRCPU > $GOXDCR_IDLE_CPU_THRESHOLD" | bc) == 1)); then
			echo "GOXDCR CPU process is using $oneXDCRCPU% and greater than idle threshold of $GOXDCR_IDLE_CPU_THRESHOLD"
			retResult=1
		else
			echo "GOXDCR CPU process is using $oneXDCRCPU% and under acceptable threshold of $GOXDCR_IDLE_CPU_THRESHOLD"
		fi
	done
	IFS="$oldIFS"

	return $retResult
}

function getXDCRPid {
	local clusterName="$1"
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	local pid
	pid=$(ps -ef | grep goxdcr | grep "=$sourcePort" | awk '{print $2}')
	local result=$?
	echo "$pid"
	return $result
}

function getXdcrRSS {
	local clusterName="$1"
	local pid

	pid=$(getXDCRPid $clusterName)
	if ((!$? == 0)); then
		return 1
	fi

	local rss
	local result
	rss=$(ps -xm -o rss,comm -p $pid | grep goxdcr | awk '{print $1}')
	result=$?
	echo "$rss"
	return $result
}

function monitorXdcrProcessMem {
	local clusterName=$1
	local numOfMinutes=$2
	local oldPid
	local pid
	local oldRss=0
	local origRss=0
	local rss
	local percentage
	local xdcrPort=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	oldPid=$(getXDCRPid $clusterName)

	local i
	for ((i = 0; $i < $numOfMinutes; i = (($i + 1)))); do
		pid=$(getXDCRPid $clusterName)
		if ((!$pid == $oldPid)); then
			echo "$clusterName XDCR process PID went from $oldPid to $pid. Might have exploded"
			return 1
		fi

		rss=$(getXdcrRSS $clusterName)
		if (($oldRss == 0)); then
			oldRss=$rss
			origRss=$rss
			echo "Start monitoring memory for node $clusterName... current RSS: $rss"
		elif (($rss == 0)); then
			echo "$clusterName got 0 rss??"
		else
			if (($rss > $oldRss)); then
				percentage=$(echo "scale=2; ($rss-$oldRss)/$oldRss * 100" | bc)
				echo "$clusterName XDCR size increased from $oldRss to $rss ($percentage %)"
				curl -s http://localhost:$xdcrPort/debug/pprof/heap >/tmp/heap_$xdcrPort.$i
			else
				percentage=$(echo "scale=2; ($oldRss-$rss)/$oldRss * 100" | bc)
				echo "$clusterName XDCR size decreased from $oldRss to $rss ($percentage %)"
			fi
			oldRss=$rss
		fi
		sleep 60
	done
	percentage=$(echo "scale=2; ($rss-$origRss)/$origRss * 100" | bc)
	echo "Done monitoring memory for node $clusterName. From $origRss to $rss ($percentage %)"
}

function getGoroutinesStack {
	local clusterName=$1
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	# check vagrant
	if [[ ! -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
		vagrantGetPprof "$clusterName" "goroutine"
		return $?
	fi

	$CURL -s http://localhost:$sourcePort/debug/pprof/goroutine?debug=1
}

function getGoHeap {
	local clusterName=$1
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	# check vagrant
	if [[ ! -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
		vagrantGetPprof "$clusterName" "heap"
		return $?
	fi

	$CURL -s http://localhost:$sourcePort/debug/pprof/heap?debug=1
}

function xdcrMemRss {
	local -A PORT_PID_MAP

	# skip if vagrant
	if [[ ! -z "${VAGRANT_VM_IP_MAP["C1"]:-}" ]]; then
		echo "Skipping xdcrMemRss for vagrant"
		return 0
	fi

	if (($(ps -ef | grep goxdcr | grep -cv grep) == 0)); then
		echo "No XDCR processes found"
		return 0
	fi

	local OLDIFS="$IFS"
	IFS=$'\n'
	local sourcePort
	local pid

	for processLine in $(ps -ef | grep goxdcr | grep sourceKVAdmin); do
		sourcePort=$(echo "$processLine" | awk '{print $9}' | cut -d= -f2)
		pid=$(echo "$processLine" | awk '{print $2}')
		PORT_PID_MAP["$sourcePort"]=$pid
	done
	IFS="$OLDIFS"

	for sourcePort in $(echo ${!PORT_PID_MAP[@]}); do
		pid=${PORT_PID_MAP[$sourcePort]}
		local RSS=$(ps -o rss= -p $pid)
		echo "XDCR port $sourcePort Pid $pid - RSS: $RSS"
	done
}

function dumpDebugInfoBeforeExit {
	local clusterName
	local testOutputDir

	xdcrMemRss
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		mkdir -p "testOutput"
		testOutputDir=$(realpath "testOutput")
		getGoroutinesStack "$clusterName" >${testOutputDir}/node${clusterName}_pprof.log
		getGoHeap "$clusterName" >${testOutputDir}/node${clusterName}_hprof.log
		getPrometheusStats "$clusterName" >${testOutputDir}/node${clusterName}_xdcrPrometheus.log
		getInternalNodeXdcrLog "$clusterName" >${testOutputDir}/node${clusterName}_xdcrLog.log
		getInternalNodeMemcachedLog "$clusterName" >${testOutputDir}/node${clusterName}_memcachedLog.log
		getInternalNodeNsServerInfoLog "$clusterName" >${testOutputDir}/node${clusterName}_nsServer_info.log
		getInternalNodeNsServerDebugLog "$clusterName" >${testOutputDir}/node${clusterName}_nsServer_debug.log
		getInternalNodeMetaKvLog "$clusterName" >${testOutputDir}/node${clusterName}_metakv.log
	done
}

function checkOpenSSL {
	if (($(openssl version | grep -c "LibreSSL 2.8.3") == 1)); then
		echo "Running this test requires brew version of openssl. Press brew install/upgrade openssl and link it to your bashProfile"
		exit 1
	fi
}

function setupCertificateAuthority {
	local clusterName="$1"
	local dependentNodeName
	local userName=${2:-}

	# Construct keys based on whether userName is set
	local caFileName="ca"
	local clusterMapKey="$clusterName"
	local CN="Couchbase Root CA"
	if [[ -n "$userName" ]]; then
		caFileName="${caFileName}_${userName}"
		clusterMapKey="${clusterName}_${userName}"
		CN="${CN}_${userName}"
	fi

	pushd $(pwd)
	cd /tmp/ || exit
	cd servercertfiles_$clusterName || exit

	# Create a private key for the cluster.
	openssl genrsa -out "./${caFileName}.key" 2048

	# Create the certificate (that is, the file that will contain the public key) for the cluster. The certificate is
	# intended to be self-signed, meaning that it will not be vouched for by any other authority. This means that it can
	# be created directly, based on the existing private key ca.key, without assistance from a third party.
	openssl req -new -x509 -days 3650 -sha256 -key "./${caFileName}.key" -out "./${caFileName}.pem" \
		-subj "/CN=${CN}" -addext "basicConstraints=CA:TRUE"
	#openssl req -new -x509 -days 3650 -sha256 -key ca.key -out ca.pem \
	# -subj "/CN=${CN}"

	# The lines below here will at least get some verification failure
	#openssl req -new -x509 -days 3650 -sha256 -key ca.key -out ca.pem \
	#  -subj "/C=UA/O=MyCompany/CN=MyCompanyRootCA"

	CLUSTER_ROOT_CERTIFICATE_MAP["$clusterMapKey"]=$(cat "${caFileName}.pem")
	CLUSTER_ROOT_CERTIFICATE_LOCATION["$clusterMapKey"]="$(PWD)/${caFileName}.pem"
	CLUSTER_ROOT_KEY_LOCATION["$clusterMapKey"]="$(PWD)/${caFileName}.key"

	# For dependent nodes, they should use the same CA
	for dependentNodeName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		if [[ "${CLUSTER_DEPENDENCY_MAP["$dependentNodeName"]}" == "$clusterName" ]]; then
			# This dependentNode will be using this CA setup
			local dependentClusterMapKey="$dependentNodeName"
			if [[ -n "$userName" ]]; then
				dependentClusterMapKey="${dependentNodeName}_${userName}"
			fi
			CLUSTER_ROOT_CERTIFICATE_MAP["$dependentClusterMapKey"]=$(cat "${caFileName}.pem")
			CLUSTER_ROOT_CERTIFICATE_LOCATION["$dependentClusterMapKey"]="$(PWD)/${caFileName}.pem"
			CLUSTER_ROOT_KEY_LOCATION["$dependentClusterMapKey"]="$(PWD)/${caFileName}.key"
		fi
	done

	popd
}

function setupCertsForTestingUsage {
	echo "setupCertsForTesting [-p \"client cert passphrase\"]"
}

# optional arguments:
# -p <client key passphrase>
function setupCertsForTesting {
	local OPTIND o p
	while getopts ":p:" o; do
		case "${o}" in
		p)
			p="${OPTARG}"
			;;
		*)
			setupCertsForTestingUsage
			;;
		esac
	done
	shift $((OPTIND - 1))

	local clientKeyPassphrase
	if [[ ! -z "${p:-}" ]]; then
		clientKeyPassphrase="$p"
	fi

	checkOpenSSL
	# Currently this test library exists under goproj/src/github.com/couchbase/goxdcr/tools/testScripts/
	# before below, store the ns_server absolute path
	local nsServerDir="$(findNsServerDir)"
	pushd $(pwd)
	cd $nsServerDir
	local nsServerDirAbsolute=$(pwd)
	echo "ns_server directory: $nsServerDirAbsolute"
	popd

	pushd $(pwd)

	local clusterName
	local depedentCheck
	local sanIP

	# First do cleanup + setup
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		cd /tmp/ || exit
		rm -rf servercertfiles_$clusterName
		mkdir servercertfiles_$clusterName || exit
		cd servercertfiles_$clusterName || exit
		mkdir -p {public,private,requests} || exit
	done

	cd /tmp/ || exit

	# First set up CA
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		# For now, skip if it is considered a dependent node. A dependent node will be using the CA created by the mother node
		if [[ -n "${CLUSTER_DEPENDENCY_MAP[$clusterName]:-}" ]]; then
			continue
		fi
		cd servercertfiles_$clusterName || exit
		setupCertificateAuthority "$clusterName"
		cd ..
	done

	cd /tmp/ || exit

	# Then perform actual node-based certs
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		cd /tmp/ || exit
		cd servercertfiles_$clusterName || exit

		# On the server to be certificate-protected, create working directories:

		local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
		local nodeDirIdx=$(echo "$port % 10" | bc)

		#Create a private key for the individual node.
		openssl genrsa -out private/couchbase.default.svc.key 2048

		# Create a certificate signing request for the node certificate.
		openssl req -new -key private/couchbase.default.svc.key \
			-out requests/couchbase.default.svc.csr -subj "/CN=Couchbase Server"

		# Define certificate extensions for the node.
		#				cat >server.ext <<EOF
		#[req]
		#distinguished_name = cn_only
		#x509_extensions = ca_ext
		#[ cn_only ]
		#commonName = Common Name (eg: your user, host, or server name)
		#commonName_max = 64
		#commonName_default = CA
		#[ca_ext]
		#basicConstraints = CA:TRUE
		#subjectKeyIdentifier = hash
		#authorityKeyIdentifier = keyid:always,issuer:always
		#keyUsage = cRLSign, keyCertSign
		#EOF

		cat >server.ext <<EOF
basicConstraints=CA:FALSE
subjectKeyIdentifier = hash
authorityKeyIdentifier = keyid,issuer:always
extendedKeyUsage=serverAuth
keyUsage = digitalSignature,keyEncipherment
EOF

		# Create a customized certificate extensions file, which adds per node constraints to the generic constraints already specified.
		cp ./server.ext ./server.ext.tmp

		unset sanIPs
		local -a sanIPs
		sanIPs[0]="127.0.0.1"
		if [[ ! -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
			sanIPs[${#sanIPs[@]}]="${VAGRANT_VM_IP_MAP["$clusterName"]}"
			if [[ -n "${VAGRANT_IP_EXTERNAL_MAP["$clusterName"]:-}" ]]; then
				sanIPs[${#sanIPs[@]}]="${VAGRANT_IP_EXTERNAL_MAP["$clusterName"]}"
			fi
			if [[ -n "${VAGRANT_LB_IP:-}" ]]; then
				sanIPs[${#sanIPs[@]}]="$VAGRANT_LB_IP"
			fi
		else
			sanIPs[${#sanIPs[@]}]="$(ipconfig getifaddr en0)"
		fi

		local counter=0
		for sanIP in $(echo ${sanIPs[@]}); do
			if (($counter == 0)); then
				echo -n "subjectAltName = IP:${sanIP}" \
					>>./server.ext.tmp
			else
				echo -n ", IP:${sanIP}" >>./server.ext.tmp
			fi
			counter=$(($counter + 1))
		done
		echo "" >>./server.ext.tmp

		# Create the node certificate, applying the certificate and digital signature of the appropriate authority, and the
		# customized extensions file for the node, to the materials in the signing request.
		openssl x509 -CA ${CLUSTER_ROOT_CERTIFICATE_LOCATION["$clusterName"]} -CAkey ${CLUSTER_ROOT_KEY_LOCATION["$clusterName"]} -CAcreateserial -days 365 -req \
			-in requests/couchbase.default.svc.csr \
			-out public/couchbase.default.svc.pem \
			-extfile server.ext.tmp

		# Rename the node certificate and node private key.
		local chainFileName="node${nodeDirIdx}_chain.pem"
		local pKeyFileName="node${nodeDirIdx}_pkey.key"
		cd ./public || exit
		mv couchbase.default.svc.pem $chainFileName
		cd ../private || exit
		mv couchbase.default.svc.key $pKeyFileName
		cd ..

		# Deploy the node certificate and node private key.
		local couchbaseDir="$nsServerDirAbsolute/data/n_${nodeDirIdx}/"
		mkdir -p $couchbaseDir/inbox/ || exit

		NODE_CERT_MAP["$clusterName"]="$PWD/public/$chainFileName"
		NODE_KEY_MAP["$clusterName"]="$PWD/private/$pKeyFileName"
		# TODO: figure out nodeCA map and see what's happening for vagrant
		NODE_CA_MAP["$clusterName"]="$PWD/ca.pem"

		if [[ -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
			cp ./public/$chainFileName $couchbaseDir/inbox/chain.pem
			cp ./private/$pKeyFileName $couchbaseDir/inbox/pkey.key

			# Upload the root certificate for the cluster. Use the following REST command:
			#curl -X POST --data-binary "@./ca.pem" \
			#	http://$DEFAULT_ADMIN:$DEFAULT_PW@127.0.0.1:$port/controller/uploadClusterCA
			curl -X POST --data-binary "@${CLUSTER_ROOT_CERTIFICATE_LOCATION["$clusterName"]}" \
				http://$DEFAULT_ADMIN:$DEFAULT_PW@127.0.0.1:$port/controller/uploadClusterCA

			# Reload the node certificate from disk, for the current node:
			curl -X POST \
				http://$DEFAULT_ADMIN:$DEFAULT_PW@127.0.0.1:$port/node/controller/reloadCertificate

		else
			echo "Running vagrant, skipping copy for now"
		fi

		# currently still in the servercertfiles_CX
		rm -rf clientcertfiles
		mkdir clientcertfiles
		cd clientcertfiles || exit

		# Create an extensions file for the use of all clients
		cat >client.ext <<EOF
basicConstraints = CA:FALSE
subjectKeyIdentifier = hash
authorityKeyIdentifier = keyid,issuer:always
extendedKeyUsage = clientAuth
keyUsage = digitalSignature
EOF

		cp ./client.ext ./client.ext.tmp

		echo "subjectAltName = email:john.smith@mail.com" \
			>>./client.ext.tmp

		# Create a client private key.
		if [[ -z "${clientKeyPassphrase:-}" ]]; then
			openssl genrsa -out ./travel-sample.key 2048
		else
			openssl genrsa -passout pass:"${clientKeyPassphrase}" -out ./travel-sample.key 2048
		fi

		# Generate the client-certificate signing-request.
		openssl req -new -key ./travel-sample.key -out ./travel-sample.csr -subj "/CN=Administrator"

		# Create the client certificate. In this example, the customized extensions file, client.ext.tmp, is used.
		#openssl x509 -CA ../ca.pem -CAkey ../ca.key \
		#	-CAcreateserial -days 365 -req -in ./travel-sample.csr \
		#	-out ./travel-sample.pem -extfile ./client.ext.tmp
		openssl x509 -CA ${CLUSTER_ROOT_CERTIFICATE_LOCATION[$clusterName]} \
			-CAkey ${CLUSTER_ROOT_KEY_LOCATION[$clusterName]} \
			-CAcreateserial -days 365 -req -in ./travel-sample.csr \
			-out ./travel-sample.pem -extfile ./client.ext.tmp

		local clientCertName="node${nodeDirIdx}_client.pem"
		local clientKeyName="node${nodeDirIdx}_client.key"

		mv travel-sample.pem $clientCertName
		mv travel-sample.key $clientKeyName

		CLIENT_CERT_MAP["$clusterName"]="$PWD/$clientCertName"
		CLIENT_KEY_MAP["$clusterName"]="$PWD/$clientKeyName"

		# Back to clientcertfiles
		#cd ..
		# Back to "root" directory before the server_certfiles...
		#cd ..
	done

	popd

	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		echo "NODE CERT for $clusterName: ${NODE_CERT_MAP[$clusterName]}"
		echo "NODE KEY for $clusterName: ${NODE_KEY_MAP[$clusterName]}"
		echo "NODE CA for $clusterName: ${NODE_CA_MAP[$clusterName]}"
		echo "NODE CLIENT CERT for $clusterName: ${CLIENT_CERT_MAP[$clusterName]}"
		echo "NODE CLIENT KEY for $clusterName: ${CLIENT_KEY_MAP[$clusterName]}"
	done

}

# Usage: pass the node log to this function
# Input: vb#
function validateVBTaskExistsInternnal {
	local vb=$1
	local input=$(cat)

	local lastVBsTaskInstance
	lastVBsTaskInstance=$(echo "$input" | grep "VBTaskMap:map" | tail -n 1 | tr ' ' $'\n' | grep "[[:alnum:]]:0x" | cut -d':' -f1)

	if (($(echo "$lastVBsTaskInstance" | grep -c "$vb") == 0)); then
		echo "Last instance of VB task does not contain VB $vb"
		return 1
	fi
}

function validateLastBackfillContainsVBTask {
	local logNodeName=$1
	local remClusterName=$2
	local vb=$3

	local remClusterUUID
	remClusterUUID=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local result=$?
	if ((!$result == 0)); then
		echo "Unable to parse UUID return code $result" >&2
		dumpDebugInfoBeforeExit
		exit 1
	fi

	local inputToInternal
	inputToInternal=$(getInternalNodeXdcrLog "$logNodeName")
	echo "$inputToInternal" | validateVBTaskExistsInternnal "$vb"
	if ((!$? == 0)); then
		echo "Unable to validate VB $vb exists in last backfill task instance for node $logNodeName cluster $remClusterName ($remClusterUUID)" >&2
		dumpDebugInfoBeforeExit
		exit 1
	fi
}

# Look at the logs to find one VB for backfill pipeline that is not 0
# Input:
# 1. clusterName to look at the log
# 2. Remote Cluster name
# 3. Source Bucket Name
# 4. Target Bucket Name
function getNon0StartingBackfillVB {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4
	local firstNon0VB

	local remClusterUUID
	remClusterUUID=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local result=$?
	if ((!$result == 0)); then
		echo "Unable to parse UUID return code $result" >&2
		return 1
	fi

	firstNon0VB=$(getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" "backfill" | getFirstNon0VB)
	result=$?
	if (($result == 0)); then
		echo "$firstNon0VB"
	fi
	return $result
}

# Test validation function that looks at pipeline resumes lifecycle
# and makes sure that for each VB XDCR is not rolling backwards
#
# Input:
# 1. clusterName to look at the log
# 2. Remote Cluster name
# 3. Source Bucket Name
# 4. Target Bucket Name
function validateCheckpointResumeSeqnos {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4

	local remClusterUUID
	remClusterUUID=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local result=$?
	if ((!$result == 0)); then
		echo "Unable to parse UUID return code $result"
		return 1
	fi

	echo "Parsing log for $logNodeName pipeline ${remClusterUUID}/${srcBucketName}/${tgtBucketName} for VB timestamps..."
	local vbsSeqnosOutput
	vbsSeqnosOutput=$(getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" | parseSetVBTimestamps)

	local OLDIFS="$IFS"
	local oneLine
	local atLeastOneFound
	IFS=$'\n'
	for oneLine in $(echo "$vbsSeqnosOutput"); do
		local vb
		local seqnos
		local -a seqnosArr
		# VB 1023: 865,4939,4939,5246,4939,5246,6354,5246,6354
		if [[ "$oneLine" =~ VB\ ([0-9]+): ]]; then
			vb=${BASH_REMATCH[1]}
			seqnos=$(echo "$oneLine" | cut -d: -f2 | xargs | tr ',' $'\n')
			local preVal
			local curVal
			preVal=""
			curVal=""
			for curVal in $(echo "$seqnos"); do
				if [[ -z "${preVal:-}" ]]; then
					# first
					preVal=$curVal
				else
					if (($curVal < $preVal)); then
						# Checkpoint resuming rolled backwards
						echo "Found at least one VB where checkpoint is resuming from an earlier point ($vb): $oneLine"
						IFS="$OLDIFS"
						exit 1
					fi
					preVal=$curVal
				fi
			done
			atLeastOneFound=1
		else
			echo "Unable to parse \"$oneLine\""
			IFS="$OLDIFS"
			exit 1
		fi
	done
	IFS="$OLDIFS"

	if [[ -z "${atLeastOneFound:-}" ]]; then
		echo "Unable to parse"
		getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" >/tmp/getSetVBTimestamp
	fi
}

# Test validation function that looks at backfill pipeline resumes lifecycle
# to make sure that at there are at least X VB's that have been checkpointed
#
# Input:
# 1. clusterName to look at the log
# 2. Remote Cluster name
# 3. Source Bucket Name
# 4. Target Bucket Name
function validateBackfillCkptTookPlaceForVBs {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4
	local minVBsToHaveCkpt=$5

	local totalVBsThatHaveCkpt
	totalVBsThatHaveCkpt=$(getNumOfBackfillCkptTookPlaceVB "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName")
	if (($totalVBsThatHaveCkpt < $minVBsToHaveCkpt)); then
		echo "For node $logNodeName requested to have at least $minVBsToHaveCkpt VBs to have checkpoint but only $totalVBsThatHaveCkpt have checkpoints"
		exit 1
	fi
}

function getNumOfBackfillCkptTookPlaceVB {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4

	local remClusterUUID
	remClusterUUID=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local result=$?
	if ((!$result == 0)); then
		echo "Unable to parse UUID return code $result" >&2
		getInternalNodeXdcrLog "$logNodeName" >/tmp/node${logNodeName}XdcrLog.log
		return 1
	fi

	local vbsSeqnosOutput
	vbsSeqnosOutput=$(getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" "backfill" | parseSetVBTimestamps)

	local OLDIFS="$IFS"
	local oneLine
	local atLeastOneFound
	local atLeastOneVBHasCkpt
	local -A vbHasCkptMap
	IFS=$'\n'
	for oneLine in $(echo "$vbsSeqnosOutput"); do
		local vb
		local seqnos
		local -a seqnosArr
		# VB 1023: 865,4939,4939,5246,4939,5246,6354,5246,6354
		if [[ "$oneLine" =~ VB\ ([0-9]+): ]]; then
			vb=${BASH_REMATCH[1]}
			seqnos=$(echo "$oneLine" | cut -d: -f2 | xargs | tr ',' $'\n')
			local preVal
			local curVal
			curVal=""
			for curVal in $(echo "$seqnos"); do
				if (($curVal > 0)); then
					vbHasCkptMap["$vb"]="true"
					atLeastOneVBHasCkpt="true"
				fi
			done
			atLeastOneFound=1
		else
			echo "Unable to parse \"$oneLine\""
			IFS="$OLDIFS"
			return 1
		fi
	done
	IFS="$OLDIFS"

	if [[ -z "${atLeastOneFound:-}" ]]; then
		echo "No checkpoint found, node $logNodeName, remCluster $remClusterName src $srcBucketName tgt $tgtBucketName stored to /tmp/getSetVBTimestamp" >&2
		getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" "backfill" >/tmp/getSetVBTimestamp_${logNodeName}.log
		getInternalNodeXdcrLog "$logNodeName" >/tmp/node${logNodeName}_xdcrLog.log
		return 1
	fi

	local totalVBsThatHaveCkpt
	if [[ -z "${atLeastOneVBHasCkpt:-}" ]]; then
		totalVBsThatHaveCkpt=0
	else
		totalVBsThatHaveCkpt="${#vbHasCkptMap[@]}"
	fi

	echo "$totalVBsThatHaveCkpt"
}

function getLastSetVBTimestampSeqno {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4
	local vbno=$5
	local backfill=${6:-}
	local output
	output=$(getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" "${backfill:-}" | grep "vb=$vbno" | parseSetVBTimestamps)

	local seqno
	seqno=$(echo "$output" | tr ',' ' ' | awk '{print $NF}')
	echo "$seqno"
}

# Ensure that VB tasks are progressing and that there are less tasks (less VBs) over time
function validateVBTasksProgress {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4

	local clusterUuid
	clusterUuid=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local retVal=$?
	if ((!$retVal == 0)); then
		echo "Unable to get clusterUUID with return code $retVal"
		return 1
	fi

	local vbTasksMsgs
	vbTasksMsgs=$(getInternalNodeXdcrLog "$logNodeName" | grep "backfill_${clusterUuid}/${srcBucketName}/${tgtBucketName}_ThroughSeqnoTracker bg scanner" | grep -v "running")

	local totalCount

	local OLDIFS="$IFS"
	IFS=$'\n'

	local prevLineCnt=0
	local curVBDoneCount
	local staticCounter=0
	local maxStaticCount=3
	for oneVBTasks in $(echo "$vbTasksMsgs"); do
		# This many number of VBs being supplied for tasks
		curVBDoneCount=$(echo "$oneVBTasks" | awk '{print $11}')
		if (($prevLineCnt == 0)); then
			prevLineCnt=$curVBDoneCount
		elif (($curVBDoneCount == $prevLineCnt)); then
			staticCounter=$(($staticCounter + 1))
			if (($staticCounter == $maxStaticCount)); then
				echo "VB task has remained the same for $maxStaticCount times"
				IFS="$OLDIFS"
				dumpDebugInfoBeforeExit
				exit 1
			fi
		fi
	done
	IFS="$OLDIFS"
}

# Validates that the result is greater than 0
function validatePrometheusStatsNon0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	local prometheusStatsName=$4
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$node]:-}
	local prometheusOut
	prometheusOut=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/_prometheusMetrics)

	local count
	count=$(echo "$prometheusOut" | grep pipelineType | grep Main | grep $prometheusStatsName |
		grep "sourceBucketName=\"${sourceBucket}\"" | grep "targetBucketName=\"${targetBucket}\"" | awk '{print $NF}')

	if (($count == 0)); then
		echo "Stat $prometheusStatsName shows 0"
		dumpDebugInfoBeforeExit
		exit 1
	fi
}

function validatePrometheusSourceNodesCnt {
	local node=$1
	local expectedCnt=$2
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$node]:-}
	local prometheusOut
	local idleSleepCnt=0
	prometheusOut=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/_prometheusMetrics)

	local count
	count=$(echo "$prometheusOut" | grep "xdcr_number_of_source_nodes_total" | grep -v "HELP" | grep -v "TYPE" |
		awk '{print $NF}')

	while (($idleSleepCnt < 3)); do
		if [[ -z "${count:-}" ]]; then
			echo "Heartbeat not found yet"
			idleSleepCnt=$(($idleSleepCnt + 1))
			sleep 15
			prometheusOut=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/_prometheusMetrics)
			count=$(echo "$prometheusOut" | grep "xdcr_number_of_source_nodes_total" | grep -v "HELP" | grep -v "TYPE" |
				awk '{print $NF}')
		else
			break
		fi
	done

	if [[ -z "${count:-}" ]]; then
		echo "Stat xdcr_number_of_source_nodes_total not found"
		dumpDebugInfoBeforeExit
		exit 1
	fi

	if (($count != expectedCnt)); then
		echo "Stat xdcr_number_of_source_nodes_total shows $count when expecting $expectedCnt"
		dumpDebugInfoBeforeExit
		exit 1
	fi
}

function validatePrometheusSourceRunningReplCnt {
	local node=$1
	local expectedCnt=$2
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$node]:-}
	local prometheusOut
	local idleSleepCnt=0
	prometheusOut=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/_prometheusMetrics)

	local count
	count=$(echo "$prometheusOut" | grep "xdcr_number_of_source_replications_total" | grep -v "HELP" | grep -v "TYPE" |
		grep "Running" | awk '{print $NF}')
	while (($idleSleepCnt < 5)); do
		if [[ -z "${count:-}" ]]; then
			echo "Heartbeat not found yet"
			idleSleepCnt=$(($idleSleepCnt + 1))
			sleep 15
			prometheusOut=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/_prometheusMetrics)
			count=$(echo "$prometheusOut" | grep "xdcr_number_of_source_replications_total" | grep -v "HELP" | grep -v "TYPE" |
				grep "Running" | awk '{print $NF}')
		else
			break
		fi
	done

	if [[ -z "${count:-}" ]]; then
		echo "Stat xdcr_number_of_source_replications_total not found"
		exit 1
	fi

	if (($count != expectedCnt)); then
		echo "Stat xdcr_number_of_source_replications_total for running shows $count when expecting $expectedCnt"
		exit 1
	fi
}

# Validates that the result is 0
function validatePrometheusStatsIs0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	local prometheusStatsName=$4
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$node]:-}
	local prometheusOut
	local cmd

	prometheusOut=$(getPrometheusStats "$node")
	local count
	count=$(echo "$prometheusOut" | grep pipelineType | grep Main | grep $prometheusStatsName |
		grep "sourceBucketName=\"${sourceBucket}\"" | grep "targetBucketName=\"${targetBucket}\"" | awk '{print $NF}')

	# Strip out non-numerics since vssh prints out newlines
	count=$(echo "$count" | sed 's/[^0-9]//g')

	if (($count > 0)); then
		echo "Node $node source $sourceBucket target $targetBucket Stat $prometheusStatsName shows $count"
		dumpDebugInfoBeforeExit
		exit 1
	fi
}

function getPrometheusStat {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	local prometheusStatsName=$4
	local pipelineType=${5:-Main}
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$node]:-}
	local prometheusOut
	local cmd

	prometheusOut=$(getPrometheusStats "$node")
	local count
	count=$(echo "$prometheusOut" | grep pipelineType | grep "$pipelineType" | grep $prometheusStatsName |
		grep "sourceBucketName=\"${sourceBucket}\"" | grep "targetBucketName=\"${targetBucket}\"" | awk '{print $NF}')

	# Strip out non-numerics since vssh prints out newlines
	count=$(echo "$count" | sed 's/[^0-9]//g')

	echo $count
}

function validatePrometheusStatsRRNon0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	validatePrometheusStatsNon0 "$node" "$sourceBucket" "$targetBucket" "xdcr_guardrail_resident_ratio_total"
}

function validatePrometheusStatsSystemEventsNon0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	validatePrometheusStatsNon0 "$node" "$sourceBucket" "$targetBucket" "xdcr_system_events_received_from_dcp_total"
}

function validatePrometheusStatsSeqAdvNon0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	validatePrometheusStatsNon0 "$node" "$sourceBucket" "$targetBucket" "xdcr_seqno_adv_received_from_dcp_total"
}

function validateDatapoolFailIs0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	validatePrometheusStatsIs0 "$node" "$sourceBucket" "$targetBucket" "xdcr_datapool_failed_gets_total"
}

function validateBinaryFilteredIs0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	validatePrometheusStatsIs0 "$node" "$sourceBucket" "$targetBucket" "xdcr_binary_filtered_total"
}

function validatePrometheusStatsCasPoisonNon0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3

	validatePrometheusStatsNon0 "$node" "$sourceBucket" "$targetBucket" "xdcr_docs_cas_poisoned_total"
}

function validatePrometheusStatsDocsFilteredNon0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3

	validatePrometheusStatsNon0 "$node" "$sourceBucket" "$targetBucket" "xdcr_docs_filtered_total"
}

function validatePrometheusStatsCLogOtherErrors0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3

	validatePrometheusStatsIs0 "$node" "$sourceBucket" "$targetBucket" "xdcr_clog_other_errors_total"
}

# use cbc-pillowfight to create a large bucket
function runCbcPillowFight {
	local cluster=$1
	local bucket=$2
	local numDocs=$3
	local scope=$4
	local collection=$5

	if [[ -z "${cluster:-}" ]] || [[ -z "${bucket:-}" ]] || [[ -z "${numDocs:-}" ]]; then
		echo "Error: Expected to pass cluster, bucket and numDocs"
		return 1
	fi

	if [[ -z "${scope:-}" ]]; then
		scope="_default"
	fi
	if [[ -z "${collection:-}" ]]; then
		collection="_default"
	fi

	local port=${CLUSTER_NAME_PORT_MAP[$cluster]}
	if [[ -z "${port:-}" ]]; then
		echo "Error: Invalid cluster - $cluster"
		return 1
	fi

	local cbcPillowfight
	cbcPillowfight=$(findFileTraverseUp "./install/bin" "cbc-pillowfight")
	if [[ -z "${cbcPillowfight:-}" ]]; then
		echo "Error: cannot find cbc-pillowfight"
		return 1
	fi

	$cbcPillowfight -U http://localhost:$port/$bucket --collection $scope.$collection -M 2000000 -m 2000000 -I $numDocs --json --populate-only -u $DEFAULT_ADMIN -P $DEFAULT_PW -t 5

	return 0
}

# The cbepctl tool is used to control vBucket states, configuration, and memory and disk persistence behavior.
function runCbepctl {
	local cluster=$1
	local bucket=$2
	local paramType=$3
	local param=$4
	local val=$5
	local kvPort

	if [[ -z "${cluster:-}" ]] || [[ -z "${bucket:-}" ]] || [[ -z "${paramType:-}" ]] || [[ -z "${param:-}" ]] || [[ -z "${param:-}" ]]; then
		echo "Error: Expected to pass cluster, bucket, paramType, param and val"
		return 1
	fi

	kvPort=${CLUSTER_NAME_KV_PORT_MAP[$cluster]}
	if [[ -z "${kvPort:-}" ]]; then
		echo "kvPort for $cluster is not set in CLUSTER_NAME_KV_PORT_MAP"
		return 1
	fi

	local cbepctl
	cbepctl=$(findFileTraverseUp "./install/bin" "cbepctl")
	if [[ -z "${cbepctl:-}" ]]; then
		echo "Error: cannot locate cbepctl"
		return 1
	fi

	$cbepctl localhost:$kvPort -u $DEFAULT_ADMIN -p $DEFAULT_PW -b $bucket set $paramType $param $val

	return 0
}

function setCrossClusterVersioningForBucket {
	local cluster=$1
	local bucketName=$2
	local setting="enableCrossClusterVersioning"
	local value="true"
	local output

	echo "setBucket $cluster $bucketName $setting $value"

	if [[ -z "${VAGRANT_KV_EXTERNAL_MAP[$cluster]:-}" ]]; then
		# not vagrant
		output=$(setBucket $cluster $bucketName $setting $value)
	else
		output=$(vagrantSetBucket $cluster $bucketName $setting $value)
	fi

	echo $output
	while [[ ! -z "${output:-}" ]] && [[ ! "$output" =~ [Cc]ross\ [Cc]luster\ [Vv]ersioning\ [Ii]s\ [Aa]lready\ [Ee]nabled ]]; do
		echo "retrying..."
		sleep 2
		if [[ -z "${VAGRANT_KV_EXTERNAL_MAP[$cluster]:-}" ]]; then
			# not vagrant
			output=$(setBucket $cluster $bucketName $setting $value)
		else
			output=$(vagrantSetBucket $cluster $bucketName $setting $value)
		fi
		echo $output
	done
}

function setBucket {
	local cluster=$1
	local bucketName=$2
	local setting=$3
	local value=$4

	local port=${CLUSTER_NAME_PORT_MAP[$cluster]:-}
	output=$($CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/pools/default/buckets/$bucketName -d $setting=$value)
	echo $output
}

function enableMobileImportSimIfPresent {
	if [[ -z ${mobileImportSimBin:-} ]]; then
		return
	fi

	clusterName=$1
	bucketName=$2
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	echo "Enabling mobile import simulator on $bucketName of 127.0.0.1:$port"

	$mobileImportSimBin -username $DEFAULT_ADMIN -password $DEFAULT_PW -bucketname $bucketName -hostAddr 127.0.0.1:$port -debugMode 1 >/tmp/importSim-$clusterName-$bucketName.log &

	echo "Sleeping 3 seconds for simulator to start"
	sleep 3
}

function grepForAbnormalities {
	grepForPanics
	if (($? != 0)); then
		exit 1
	fi

	grepForErrs
	if (($? != 0)); then
		exit 1
	fi

	grepForEINVAL
	if (($? != 0)); then
		exit 1
	fi

	grepForMultiError
	if (($? != 0)); then
		exit 1
	fi

	grepForDecodingError
	if (($? != 0)); then
		exit 1
	fi

	grepForUnknownResponse
	if (($? != 0)); then
		exit 1
	fi

	grepForFaultyCLogTrackers
	if (($? != 0)); then
		exit 1
	fi

	grepForNonMonotonicThroughSeqno
	if (($? != 0)); then
		exit 1
	fi

	grepForUnusualOSOSessionEnds
	if (($? != 0)); then
		exit 1
	fi
}

function grepForLastMappingDocUpdateInMetaKvLogs {
	clusterName=$1
	pattern=$2
	updateRegex="Updating data.*backfillMappings"

	logs=$(getInternalNodeMetaKvLog "$clusterName")
	if ((!$? == 0)); then
		echo "Unable to get metakv log for validation"
		exit 1
	fi

	# 2 lines comprise of one update
	lastUpdate=$(echo "$logs" | grep -A 1 "$updateRegex" | tail -n 2)
	cnt=$(echo "$lastUpdate" | grep -c "$pattern")
	if (($cnt == 0)); then
		now=$(date)
		echo "0 occurances found of $pattern in lastUpdate of metakv.log at $now"
		exit 1
	fi

	echo "$pattern found in lastUpdate of metakv.log"
	return
}

# note that we need to take care of rev if the persistence store is metaKV (and not simple store)
function updateNsServerSimpleStore {
	clusterName=$1
	key=$2
	val=$3
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	$CURL -s -u $DEFAULT_ADMIN:$DEFAULT_PW localhost:$port/_metakv/$key -X PUT -d value="$val"
	if (($? == 0)); then
		echo "Updated simple store $key to $val"
		return
	fi

	echo "simple store update failed"
	exit 1
}

# clog stats that require monitoring
declare -A requiredClogStats=(["xdcr_clog_src_docs_written_total"]=0 ["xdcr_clog_tgt_docs_written_total"]=0 ["xdcr_clog_crd_docs_written_total"]=0 ["xdcr_clog_hibernated_count_total"]=0 ["xdcr_clog_docs_filtered_total"]=0 ["xdcr_true_conflicts_detected_total"]=0 ["xdcr_subdoc_cmd_docs_skipped_total"]=0 ["xdcr_get_docs_cas_changed_total"]=0)

function getClogStatsBefore {
	local clusterName=$1
	local sourceBucketName=$2
	local targetBucketName=$3
	local replicationKey="${sourceBucketName}_${targetBucketName}"

	echo "Getting clog stats for cluster $clusterName bucket $sourceBucketName -> $targetBucketName"

	# Dynamically create and access the associative array
	eval "declare -gA clogStatsBefore_${replicationKey}"

	for statKey in "${!requiredClogStats[@]}"; do
		# Fetch the value from Prometheus
		newVal=$(getReplicationSpecificStatFromPrometheus "$clusterName" "$sourceBucketName" "$targetBucketName" "$statKey")

		eval "oldVal=\${clogStatsBefore_${replicationKey}[$statKey]:-0}"
		sum=$((oldVal + newVal))

		# Update the array
		eval "clogStatsBefore_${replicationKey}[$statKey]=$sum"

		echo "BEFORE: logging $statKey with $sum"
	done
}

function getClogStatsAfter {
	local clusterName=$1
	local sourceBucketName=$2
	local targetBucketName=$3
	local replicationKey="${sourceBucketName}_${targetBucketName}"

	echo "Getting clog stats for cluster $clusterName bucket $sourceBucketName -> $targetBucketName"

	# Dynamically create and access the associative array
	eval "declare -gA clogStatsAfter_${replicationKey}"

	for statKey in "${!requiredClogStats[@]}"; do
		# Fetch the value from Prometheus
		newVal=$(getReplicationSpecificStatFromPrometheus "$clusterName" "$sourceBucketName" "$targetBucketName" "$statKey")

		eval "oldVal=\${clogStatsAfter_${replicationKey}[$statKey]:-0}"
		sum=$((oldVal + newVal))

		# Update the array
		eval "clogStatsAfter_${replicationKey}[$statKey]=$sum"

		echo "AFTER: logging $statKey with $sum"
	done
}

function verifyClogStats {
	local sourceBucketName=$1
	local targetBucketName=$2
	local replicationKey="${sourceBucketName}_${targetBucketName}"

	echo "Verifying clog stats for replication: $sourceBucketName -> $targetBucketName"

	declare -n beforeStats="clogStatsBefore_${replicationKey}"
	declare -n afterStats="clogStatsAfter_${replicationKey}"

	for statKey in "${!beforeStats[@]}"; do
		beforeVal=${beforeStats[$statKey]:-0}
		afterVal=${afterStats[$statKey]:-0}

		if ((afterVal < beforeVal)); then
			echo "ERROR: $statKey decreased! Before: $beforeVal, After: $afterVal"
			exit 1
		fi
	done

	echo "All clog stats are correct for replication $sourceBucketName -> $targetBucketName."
	return 0
}

function postStageCredToRemoteReference {
	local source=$1
	local target=$2
	local username=$3
	local password=$4
	if [[ -z "${source:-}" ]] || [[ -z "${target:-}" ]]; then
		echo "Invalid input"
		return 1
	fi
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$source]:-}
	local targetPort=${CLUSTER_NAME_PORT_MAP[$target]:-}
	local sourceHost=${CLUSTER_NAME_HOST_MAP[$source]:-"127.0.0.1"}

	echo "Staging creds $username and $password"
	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://$sourceHost:$sourcePort/pools/default/remoteClusters/$target -d stage=true -d username=$username -d password=$password
}

function createCertsForUser {
	local clusterName=$1
	local userName=${2:-}

	local clusterMapKey="$clusterName"
	if [[ -n "$userName" ]]; then
		clusterMapKey="${clusterName}_${userName}"
	fi

	checkOpenSSL
	# Currently this test library exists under goproj/src/github.com/couchbase/goxdcr/tools/testScripts/
	# before below, store the ns_server absolute path
	local nsServerDir="$(findNsServerDir)"
	pushd $(pwd)
	cd $nsServerDir
	local nsServerDirAbsolute=$(pwd)
	echo "ns_server directory: $nsServerDirAbsolute"
	popd

	pushd $(pwd)

	cd /tmp/ || exit
	cd servercertfiles_$clusterName || exit
	cd clientcertfiles || exit

	# Create a client private key.
	openssl genrsa -out "./${userName}.key" 2048

	# Generate the client-certificate signing-request.
	openssl req -new -key "./${userName}.key" -out "./${userName}.csr" -subj "/CN=${userName}"

	# Create the client certificate. In this example, the customized extensions file, client.ext.tmp, is used.

	openssl x509 -CA ${CLUSTER_ROOT_CERTIFICATE_LOCATION[$clusterMapKey]} \
		-CAkey ${CLUSTER_ROOT_KEY_LOCATION[$clusterMapKey]} \
		-CAcreateserial -days 365 -req -in "./${userName}.csr" \
		-out "./${userName}.pem" -extfile ./client.ext.tmp

	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	local nodeDirIdx=$(echo "$port % 10" | bc)

	local clientCertName="node${nodeDirIdx}_${userName}.pem"
	local clientKeyName="node${nodeDirIdx}_${userName}.key"

	mv "./${userName}.pem" $clientCertName
	mv "./${userName}.key" $clientKeyName

	CLIENT_CERT_MAP["$clusterMapKey"]="$PWD/$clientCertName"
	CLIENT_KEY_MAP["$clusterMapKey"]="$PWD/$clientKeyName"

	popd
}

function testForMobileImportSim {
	if [[ -z ${mobileImportSimBin:-} ]]; then
		echo "mobile import binary needed"
		exit 1
	fi
}

# HELP xdcr_pipeline_status The pipeline status for a specific pipeline, where it could be paused, running or, error.
# TYPE xdcr_pipeline_status gauge
#   xdcr_pipeline_status {targetClusterUUID="a8b73b82ec06ae15944919b0706c3556", sourceBucketName="B1", targetBucketName="B2", pipelineType="Main", status="Paused"} 0
#   xdcr_pipeline_status {targetClusterUUID="a8b73b82ec06ae15944919b0706c3556", sourceBucketName="B1", targetBucketName="B2", pipelineType="Main", status="Running"} 0
#   xdcr_pipeline_status {targetClusterUUID="a8b73b82ec06ae15944919b0706c3556", sourceBucketName="B1", targetBucketName="B2", pipelineType="Main", status="Error"} 1
#   xdcr_pipeline_status {targetClusterUUID="a8b73b82ec06ae15944919b0706c3556", sourceBucketName="B1", targetBucketName="B2", pipelineType="Backfill", status="Paused"} 1
#   xdcr_pipeline_status {targetClusterUUID="a8b73b82ec06ae15944919b0706c3556", sourceBucketName="B1", targetBucketName="B2", pipelineType="Backfill", status="Running"} 0
#   xdcr_pipeline_status {targetClusterUUID="a8b73b82ec06ae15944919b0706c3556", sourceBucketName="B1", targetBucketName="B2", pipelineType="Backfill", status="Error"} 0
function validatePrometheusPipelineStatusIs1Internal {
	local sourceBucket=$1
	local targetBucket=$2
	local pipelineType=$3
	local statusType=$4
	local prometheusOut="$5"

	local count
	count=$(echo "$prometheusOut" | grep "xdcr_pipeline_status" | grep "pipelineType=\"$pipelineType\"" | grep "status=\"$statusType\"" |
		grep "sourceBucketName=\"${sourceBucket}\"" | grep "targetBucketName=\"${targetBucket}\"" | awk '{print $NF}')

	if (($count == 0)); then
		echo "Pipeline status $pipelineType $statusType shows 0"
		echo "Full prometheus output:"
		echo "$prometheusOut"
		exit 1
	fi
}

function validatePrometheusPipelineStatusIs1 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	local pipelineType=$4
	local statusType=$5
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$node]:-}
	local prometheusOut
	prometheusOut=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/_prometheusMetrics)

	if [[ -z "${prometheusOut:-}" ]]; then
		prometheusOut=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/_prometheusMetrics)
		if [[ -z "${prometheusOut:-}" ]]; then
			echo "Warning Unable to get prometheus stats"
			echo "Command is $CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/_prometheusMetrics"
		fi
	fi

	validatePrometheusPipelineStatusIs1Internal "$sourceBucket" "$targetBucket" "$pipelineType" "$statusType" "$prometheusOut"
}

# Runs pprof periodically
# Input:
# 1. node - node name
# 2. captureCnt - number of captures to take
# 3. sleepTime - time to sleep between captures
# 4. type - pprof type (heap, cpu, etc.)
# 5. outputDir - directory to save the pprof files
function runPeriodicPprof {
	local node=$1
	local captureCnt=$2
	local sleepTime=$3
	local type=$4
	local outputDir=$5
	local port=${CLUSTER_NAME_XDCR_PORT_MAP[$node]:-}

	if [[ -z "${port:-}" ]]; then
		echo "Error: port for node $node is not set in CLUSTER_NAME_XDCR_PORT_MAP"
		exit 1
	fi

	if [[ -z "${outputDir:-}" ]]; then
		echo "Error: output directory is not set"
		exit 1
	fi

	mkdir -p "$outputDir"
	for ((i = 1; i <= captureCnt; i++)); do
		sleep "$sleepTime"
		echo "Capturing pprof $type for node $node, capture $i of $captureCnt"
		local outputFile="$outputDir/${node}_${type}_$(date +%Y%m%d_%H%M%S).pprof"

		# Run pprof command
		$CURL -X GET http://127.0.0.1:$port/debug/pprof/$type >"$outputFile"

		if (($? != 0)); then
			echo "Error capturing pprof for node $node, capture $i"
			exit 1
		fi
		echo "Captured pprof $type for node $node, capture $i of $captureCnt to $outputFile"
	done
}

function validateCkptResume {
	local dependentNodeName=${1:-}
	local tempLogs
	tempLogs=$(getInternalNodeXdcrLog "$dependentNodeName")
	# CKPT_RESUME_FOUND="checkpoint documents for"
	ckptFoundWith0Count=$(echo "$tempLogs" | grep -v "Backfill" | grep "$CKPT_RESUME_FOUND" | grep -c " 0 ")
	ckptFoundTotalCount=$(echo "$tempLogs" | grep -v "Backfill" | grep -c "$CKPT_RESUME_FOUND")
	if (($ckptFoundWith0Count == $ckptFoundTotalCount)); then
		if (($ckptFoundTotalCount == 0)); then
			echo "$dependentNodeName shows no resume message"
			return 1
		else
			echo "$dependentNodeName unable to find upserted checkpoints"
			dumpDebugInfoBeforeExit
			exit 1
		fi
	fi
}

function validateCkptResumeForDependentNodes {
	local dependentNodeName
	local retry
	local lastResult
	for dependentNodeName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		validateCkptResume "$dependentNodeName"
		lastResult=$?
		retry=0
		while ((!$? == 0 && $retry < 5)); do
			echo "Trying again $retry out of 5..."
			sleep 10
			validateCkptResume "$dependentNodeName"
			lastResult=$?
			retry=$(($retry + 1))
		done
	done

	return $lastResult
}

function vagrantGetInternalNodeLog {
	local clusterName=$1
	local logFileName=$2
	local logFile="$VAGRANT_LOG_DIR/$logFileName"
	local idx

	idx="$(getClusterIdx "$clusterName")"
	${VSSH[$idx]} "sudo cat $logFile"
}

function vagrantGetPprof {
	local clusterName=$1
	local pprofType=$2
	local idx
	idx="$(getClusterIdx "$clusterName")"

	${VSSH[$idx]} "curl -s http://localhost:9998/debug/pprof/$pprofType?debug=1"
}

function setupCNGCertificateAuthority {
	local cngNodeName="$1"
	local dependentCngNodeName
	local userName=${2:-}

	# Construct keys based on whether userName is set
	local caFileName="cng_ca"
	local cngMapKey="$cngNodeName"
	local CN="Couchbase CNG Root CA"
	if [[ -n "$userName" ]]; then
		caFileName="${caFileName}_${userName}"
		cngMapKey="${cngNodeName}_${userName}"
		CN="${CN}_${userName}"
	fi

	pushd $CNG_PATH

	# Create a private key for the cluster (CNG)
	openssl genrsa -out "./${caFileName}.key" 2048

	# Create the self-signed certificate with CNG specific CN
	openssl req -new -x509 -days 3650 -sha256 -key "./${caFileName}.key" -out "./${caFileName}.pem" \
		-subj "/CN=${CN}" -addext "basicConstraints=CA:TRUE"

	CNG_ROOT_CERTIFICATE_MAP["$cngMapKey"]=$(cat "${caFileName}.pem")
	CNG_ROOT_CERTIFICATE_LOCATION["$cngMapKey"]="$(PWD)/${caFileName}.pem"
	CNG_ROOT_KEY_LOCATION["$cngMapKey"]="$(PWD)/${caFileName}.key"

	# Propagate to dependent nodes
	for dependentCngNodeName in $(echo ${!CNG_DEPENDENCY_MAP[@]}); do
		if [[ "${CNG_DEPENDENCY_MAP["$dependentCngNodeName"]}" == "$cngNodeName" ]]; then
			local dependentCngNodeMapKey="$dependentCngNodeName"
			if [[ -n "$userName" ]]; then
				dependentCngNodeMapKey="${dependentCngNodeName}_${userName}"
			fi
			CNG_ROOT_CERTIFICATE_MAP["$dependentCngNodeMapKey"]=$(cat "${caFileName}.pem")
			CNG_ROOT_CERTIFICATE_LOCATION["$dependentCngNodeMapKey"]="$(PWD)/${caFileName}.pem"
			CNG_ROOT_KEY_LOCATION["$dependentCngNodeMapKey"]="$(PWD)/${caFileName}.key"
		fi
	done

	popd
}

# setupCNGNodeCertificates <cngNodeName> [userName]
# Generates a node key/cert pair signed by the CNG Root CA for the given CNG node.
# CN: "CNG Node Cert"
# SAN: 127.0.0.1
function setupCNGNodeCertificates {
	local cngNodeName="$1"
	local userName="${2:-}"
	local cngMapKey="$cngNodeName"
	if [[ -n "$userName" ]]; then
		cngMapKey="${cngNodeName}_${userName}"
	fi

	if [[ -z "${CNG_ROOT_CERTIFICATE_LOCATION[$cngMapKey]:-}" ]] || [[ -z "${CNG_ROOT_KEY_LOCATION[$cngMapKey]:-}" ]]; then
		echo "ERRO: CNG root CA not initialized for $cngMapKey. Run setupCNGCertificateAuthority first." >&2
		return 1
	fi

	# If a node cert and key already exist, skip regeneration
	if [[ -n "${CNG_NODE_CERT_LOCATION_MAP[$cngMapKey]:-}" ]] &&
		[[ -n "${CNG_NODE_KEY_LOCATION_MAP[$cngMapKey]:-}" ]] &&
		[[ -f "${CNG_NODE_CERT_LOCATION_MAP[$cngMapKey]}" ]] &&
		[[ -f "${CNG_NODE_KEY_LOCATION_MAP[$cngMapKey]}" ]]; then
		echo "INFO: CNG node certificate already exists for $cngMapKey: ${CNG_NODE_CERT_LOCATION_MAP[$cngMapKey]}"
		return 0
	fi

	local workDir="$CNG_PATH/${cngNodeName}"
	mkdir -p "$workDir" || return 1
	cd "$workDir" || return 1
	mkdir -p public private requests || return 1

	# Generate key
	openssl genrsa -out private/cng_node.key 2048 >/dev/null 2>&1 || {
		echo "ERRO: Failed generating node key"
		return 1
	}

	# CSR with fixed CN
	openssl req -new -key private/cng_node.key -out requests/cng_node.csr -subj "/CN=CNG Node Cert" >/dev/null 2>&1 || {
		echo "ERRO: Failed generating node CSR"
		return 1
	}

	# Extensions file with SAN 127.0.0.1 only
	cat >cng_node.ext <<EOF
basicConstraints=CA:FALSE
subjectKeyIdentifier = hash
authorityKeyIdentifier = keyid,issuer:always
extendedKeyUsage=serverAuth
keyUsage = digitalSignature,keyEncipherment
subjectAltName = IP:127.0.0.1
EOF

	openssl x509 \
		-CA "${CNG_ROOT_CERTIFICATE_LOCATION[$cngMapKey]}" \
		-CAkey "${CNG_ROOT_KEY_LOCATION[$cngMapKey]}" \
		-CAcreateserial -days 365 -req \
		-in requests/cng_node.csr \
		-out public/cng_node.pem \
		-extfile cng_node.ext >/dev/null 2>&1 || {
		echo "ERRO: Failed signing CNG node certificate"
		return 1
	}

	CNG_NODE_CERT_LOCATION_MAP["$cngMapKey"]="$workDir/public/cng_node.pem"
	CNG_NODE_KEY_LOCATION_MAP["$cngMapKey"]="$workDir/private/cng_node.key"

	echo "INFO: Created CNG node certificate for $cngMapKey: ${CNG_NODE_CERT_LOCATION_MAP[$cngMapKey]}"
	return 0
}

# setupCNGCerts <cngNodeName> [userName]
# creates CA (if not already created) and generates a node certificate.
function setupCNGCerts {
	local cngNodeName="$1"
	local userName="${2:-}"
	local cngMapKey="$cngNodeName"
	if [[ -n "$userName" ]]; then
		cngMapKey="${cngNodeName}_${userName}"
	fi

	# Prepare CA working directory (mirrors setupCNGCertificateAuthority expectation)
	local caDir="$CNG_PATH"
	mkdir -p "$caDir" || return 1

	# If CA not yet in maps, create it
	if [[ -z "${CNG_ROOT_CERTIFICATE_LOCATION[$cngMapKey]:-}" ]] || [[ -z "${CNG_ROOT_KEY_LOCATION[$cngMapKey]:-}" ]]; then
		pushd $CNG_PATH
		setupCNGCertificateAuthority "$cngNodeName" "$userName" || {
			echo "ERRO: Failed creating CNG root CA" >&2
			popd >/dev/null
			return 1
		}
		popd
	else
		echo "INFO: CNG root CA already exists for $cngMapKey"
	fi

	# Generate node certificate
	setupCNGNodeCertificates "$cngNodeName" "$userName" || {
		echo "ERRO: Failed creating CNG node certificate" >&2
		return 1
	}

	echo "INFO: Completed CNG cert setup for $cngMapKey"
	return 0
}
