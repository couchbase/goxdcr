# Copyright 2019-Present Couchbase, Inc.
#
# Use of this software is governed by the Business Source License included in
# the file licenses/BSL-Couchbase.txt.  As of the Change Date specified in that
# file, in accordance with the Business Source License, use of this software
# will be governed by the Apache License, Version 2.0, included in the file
# licenses/APL2.txt.

# CONSTANTS
BROKEN_MSG="Found following destination collection(s) missing (and will not get replicated to)"
REPAIR_MSG="Following collection mappings are now repaired and replicating"
BACKFILL_MSG="These collections need to backfill"
BACKFILL_APPEND_MSG="These collections need to append backfill"
VBTASKS_DONE_MSG="has finished processing one task for all requested VBs"
TIMEDOUT_TYPE1_MSG="Executing Action timed out"
TIMEDOUT_TYPE2_MSG="Executing Action2 timed out"
OSO_MODE_MSG="with OSO mode requested"
OSO_BACKFILL_COUNT="oso_received=10000"
DCP_CONVERT_ERR_MSG="Error converting VBTask to DCP Nozzle Task"
BROKENEVENT_TYPE=3
BACKFILL_PIPELINE_TORNDOWN_MSG="Background check task finished"
GOXDCR_IDLE_CPU_THRESHOLD=10
RECEIVE_P2P_REQ_MSG="Received peer-to-peer push requests"
RECEIVE_P2P_REQ_DONE_MSG="Done handling peer-to-peer push requests from"
TS_PREFIX="ts.Seqno"
PIPELINE_SHUTDOWN_DONE_MSG="status is finished shutting down"
P2P_DESERIALIZATION_ERR_MSG="has payloadCompressed but no payload after deserialization"
P2P_UNABLE_TO_RESPOND_MSG="Unable to respond to caller"
CKPT_MAPPING_NOT_FOUND_MSG="Error when getting brokenMapping for"
P2P_BACKFILL_PUSH_RECEIVED_MSG="received peer node push backfill replication"
UNABLE_TO_GET_HIGH_SEQNO_MSG="Unable to find any collection ID for getHighSeqno"
P2P_PULL_ERR_MSG="Unable to respond to caller given type"
BACKFILL_START_MSG="Starting BackfillPipeline"
TOPOLOGY_RESTART_MSG="Topology change detected. Estimated time of pipeline restart"
DCP_ROLLBACK_MSG="Received rollback from DCP stream"
P2P_PULL_MANIFEST_ERR="Unable to retrieve peer manifests for new spec"
XMEM_REPAIR_CONNECTION="Repairing connection"
BACKFILL_PIPELINE_START="Starting BackfillPipeline"
BACKFILL_KILLED="background waiting backfill streams to all be replicated timed out"

# These should be imported after clusterRunProvision script

function checkItemCnt {
	local cluster=$1
	local bucket=$2
	local expectedCnt=$3
	local i

	local previousItemCnt=0
	local maxCnt=8
	for ((i = 0; $i < $maxCnt; i = $(($i + 1)))); do
		echo "Checking item count $(($i + 1)) / $maxCnt"
		itemCount=$(getBucketItemCount "$cluster" "$bucket")
		if (($itemCount == $expectedCnt)); then
			echo "Item count for cluster $cluster bucket $bucket: $itemCount"
			return 0
		else
			if (($itemCount != $previousItemCnt)); then
				previousItemCnt=$itemCount
				i=$(($i - 1))
				echo "ERROR: Cluster $cluster bucket $bucket only has $itemCount items. Expect $expectedCnt. Items are increasing..."
			else
				echo "ERROR: Cluster $cluster bucket $bucket only has $itemCount items"
			fi
		fi
		echo "Sleeping 10 seconds and retrying..."
		sleep 10
	done
	read -p "Press any key once done investigating"
	dumpDebugInfoBeforeExit
	exit 1
}

# Assumes running test script from this directory
function getNsServerDir {
	# i.e. Running from "/Users/neil.huang/source/couchbase/goproj/src/github.com/couchbase/goxdcr/tools/testScripts"
	local srcTreeName=$(pwd | cut -d/ -f6-)
	# /Users/neil.huang/source/couchbase/
	local couchbaseDir=$(pwd | sed "s|$srcTreeName||g")
	echo "${couchbaseDir}ns_server"
	return 0
}

function grepForPanics {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"
	for dir in $(ls $logsDir); do
		count=$(grep -c panic ${logsDir}/${dir}/goxdcr.log)
		if (($count > 0)); then
			echo "WARNING Found panics in ${logsDir}/${dir}"
			exit 1
		fi
	done
	return 0
}

function grepForInvalidCommand {
	local ns_serverDir=$(getNsServerDir)
	local logsDir="${ns_serverDir}/logs"

	for dir in $(ls $logsDir); do
		counts=$(grep -crhn "Invalid format specified" ${logsDir}/${dir})
		for count in $(echo "$counts"); do
			if (($count > 0)); then
				echo "WARNING Found invalid format in ${logsDir}/${dir}"
				exit 1
			fi
		done
	done
	return 0
}

function getDataReplicated {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	echo $(getStats "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket" "data_replicated")
}

function getChangesLeft {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	echo $(getStats "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket" "changes_left")
	if (($? != 0)); then
		echo "Failed to get stats"
		return 1
	fi
}

function getDocsProcessed {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4

	echo $(getStats "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket" "docs_processed")
}

function waitForChangesLeft0 {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local changesLeft
	local i

	for ((i = 0; $i < 5; i = $(($i + 1)))); do
		changesLeft=$(getChangesLeft "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket")
		if (($? != 0)); then
			echo "Failed to get changes_left"
			dumpDebugInfoBeforeExit
			exit 1
		fi
		if [[ -z "${changesLeft:-}" ]]; then
			echo "Changes left is empty. Trying again..."
			sleep 10
			continue
		elif [[ "$changesLeft" == "null" ]]; then
			echo "Changes left is null. Trying again..."
			sleep 10
			continue
		elif (($changesLeft > 0)); then
			echo "Changes left $changesLeft is not 0 yet..."
		elif (($changesLeft == 0)); then
			break
		else
			echo "Changes left unknown value: $changesLeft"
		fi
		echo "Sleeping 10 seconds and retrying..."
		sleep 10
	done
}

function checkNonNegativeChangesLeft {
	local srcCluster=$1
	validateLogWithInstance "$srcCluster" "changes_left=-" 0
}

function checkChangesLeftInternal {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local i

	local lastChangesLeft=0

	for ((i = 0; $i < $CHECK_CHANGES_LEFT_MAX; i = $(($i + 1)))); do
		changesLeft=$(getChangesLeft "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket")
		if [[ -z "${changesLeft:-}" ]] || [[ "$changesLeft" == "null" ]]; then
			changesLeft=999999
		fi
		if (($changesLeft == 0)); then
			echo "Node $srcCluster changes_left is 0"
			checkNonNegativeChangesLeft "$srcCluster"
			return 0
		else
			if (($changesLeft == $lastChangesLeft)); then
				echo "Node $srcCluster Changes left is not 0. It is $changesLeft"
			else
				lastChangesLeft=$changesLeft
				i=$(($i - 1))
				echo "Node $srcCluster Changes left is not 0. It is $changesLeft... it is decreasing"
			fi
			sleep 10
		fi
	done
	dumpDebugInfoBeforeExit
	exit 1
}

function checkUnidirectionalChangesLeft {
	checkChangesLeftInternal "C1" "B1" "C2" "B2"
}

function checkBidirectionalChangesLeft {
	checkChangesLeftInternal "C1" "B1" "C2" "B2"
	checkChangesLeftInternal "C2" "B2" "C1" "B1"
}

function checkDataReplicatedIsZero {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local oldDataReplicated=$5
	local i

	for ((i = 0; $i < 3; i = $(($i + 1)))); do
		dataReplicated=$(getDataReplicated "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket")
		if (($dataReplicated > 0)); then
			echo "Data replicated $dataReplicated is not 0 yet..."
			if (($dataReplicated != $oldDataReplicated)); then
				echo "Error: Data replicated is different from previous replicated $oldDataReplicated"
				break
			fi
		else
			return 0
		fi
		echo "Sleeping 10 seconds and retrying..."
		sleep 10
	done
	exit 1
}

function checkDocsProcessed {
	local srcCluster=$1
	local srcBucket=$2
	local targetCluster=$3
	local targetBucket=$4
	local docsProcessedCheck=$5
	local i

	for ((i = 0; $i < 5; i = $(($i + 1)))); do
		docsProcessed=$(getDocsProcessed "$srcCluster" "$srcBucket" "$targetCluster" "$targetBucket")
		if (($docsProcessed != $docsProcessedCheck)); then
			echo "DocsProcessed: $docsProcessed. Waiting for it to be $docsProcessedCheck..."
		else
			return 0
		fi
		echo "Sleeping 10 seconds and retrying..."
		sleep 10
	done
	dumpDebugInfoBeforeExit
	exit 1
}

function getSpecificInternalSettings {
	local clusterName=$1
	local key=$2

	echo $(listInternalSettings "$clusterName" | jq ".$key")
}

function killGoXdcr {
	local clusterName=$1
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}

	if [[ -z "$sourcePort" ]]; then
		echo "Unable to kill goxdcr as source port is not found"
	fi

	echo "Killing GoXDCR for $clusterName with port $sourcePort..."
	ps -ef | grep goxdcr | grep $sourcePort | awk '{print $2}' | xargs kill
}

function killMemcached {
	local nodePrefix=$1

	ps -ef | grep memcached | grep -v grep | grep -v beam | grep "$nodePrefix" | awk '{print $2}' | xargs kill -9
}

# Input:
# 1 - cluster name
# 2 - String to look for
# 3 - Number of occurrences
# 4 - Max number of occurrences
function validateLogWithInstance {
	local clusterName=$1
	local grepStr="$2"
	local instanceCnt=$3
	local maxInstanceCnt=${4:-}

	local logs=$(getClusterLogs "$clusterName")
	if ! (($? == 0)); then
		echo "Unable to get log for validation"
		return 1
	fi

	count=$(echo "$logs" | grep -c "$grepStr")
	if (($count != $instanceCnt)); then
		if [[ ! -z "$maxInstanceCnt" ]] && (($count > $maxInstanceCnt)); then
			echo "Error - requested count for $grepStr is $instanceCnt or < $maxInstanceCnt, but found $count"
			dumpDebugInfoBeforeExit
			echo "Logs: $logs" >/tmp/testOutput.log
			echo "Console logs saved as /tmp/testOutput.log"
			exit 1
		elif [[ ! -z "$maxInstanceCnt" ]]; then
			echo "Warning - requested count for $grepStr is $instanceCnt or < $maxInstanceCnt, found $count"
		else
			echo "Error - requested count for $grepStr is $instanceCnt, but found $count"
			dumpDebugInfoBeforeExit
			echo "Logs: $logs" >/tmp/testOutput.log
			echo "Console logs saved as /tmp/testOutput.log"
			exit 1
		fi
	else
		echo "Found exactly $instanceCnt of \"$grepStr\""
	fi
}

declare -i ORIG_TARGET_MAN_PULL_INTERVAL

function setCustomManifestRefreshInterval {
	local cluster="$1"

	for ((i = 0; i < 2; i = $(($i + 1)))); do
		ORIG_TARGET_MAN_PULL_INTERVAL=$(getSpecificInternalSettings "$cluster" "ManifestRefreshTgtInterval")
		tempTargetManifestPullInterval="5"

		echo "Temporarily updating targetManifestPull from $ORIG_TARGET_MAN_PULL_INTERVAL to $tempTargetManifestPullInterval"
		setInternalSettings "$cluster" "ManifestRefreshTgtInterval=$tempTargetManifestPullInterval"

		echo "Sleeping 10 seconds for XDCR to reboot before checking..."
		sleep 10
		chkTargetManifestPullInterval=$(getSpecificInternalSettings "$cluster" "ManifestRefreshTgtInterval")
		if (($chkTargetManifestPullInterval == $tempTargetManifestPullInterval)); then
			return 0
		else
			echo "Error - unable to update pull interval - stuck at $chkTargetManifestPullInterval. Trying again..."
		fi
	done
	exit 1
}

function resetCustomManifestRefreshInterval {
	local cluster="$1"
	echo "Cleaning up internal settings"
	setInternalSettings "C1" "ManifestRefreshTgtInterval=$ORIG_TARGET_MAN_PULL_INTERVAL"
}

function getInternalNsServerLogDir {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	local lastDigit=$(echo "${port: -1}")
	local logNodeDir="n_${lastDigit}"

	# Currently this test library exists under goproj/src/github.com/couchbase/goxdcr/tools/testScripts/
	local nsServerLogDir="../../../../../../../ns_server/logs/"

	echo "${nsServerLogDir}/${logNodeDir}/"
}

function getInternalNodeMemcachedLog {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	local logfileDir=$(getInternalNsServerLogDir "$clusterName")

	local memcachedLog
	for memcachedLog in $(ls $logfileDir | grep memcached); do
		cat ${logfileDir}/${memcachedLog}
	done
}

function getInternalNodeXdcrLog {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	local logfileDir=$(getInternalNsServerLogDir "$clusterName")

	local goxdcrLogFile=${logfileDir}/goxdcr.log
	if ! [[ -f "$goxdcrLogFile" ]]; then
		echo "Unable to find file $goxdcrLogFile"
		return 1
	fi

	cat $goxdcrLogFile
}

# Used only if the log needs to be clean for parsing purposes
function clearInternalNodeXdcrLog {
	local clusterName=$1
	local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
	if [[ -z "$port" ]]; then
		echo "Invalid clustername $clusterName"
		return 1
	fi

	local logfileDir=$(getInternalNsServerLogDir "$clusterName")

	local goxdcrLogFile=${logfileDir}/goxdcr.log
	if ! [[ -f "$goxdcrLogFile" ]]; then
		echo "Unable to find file $goxdcrLogFile"
		return 1
	fi

	echo "" >$goxdcrLogFile
}

function waitForOneReplicationToBeDeleted {
	local clusterName=$1
	local srcBucketName=$2
	local tgtBucketName=$3
	local currentInstanceCnt=0

	logs=$(getInternalNodeXdcrLog "$clusterName")
	if ((!$? == 0)); then
		echo "Unable to get log for validation"
		exit 1
	fi

	#	2021-11-03T17:44:45.353-07:00 INFO GOXDCR.PipelineMgr: Replication ebf93073d83a1951c6454753536a6eb5/B1/B2's status is finished shutting down
	currentInstanceCnt=$(echo "$logs" | grep "$PIPELINE_SHUTDOWN_DONE_MSG" | grep -c "$srcBucketName\/$tgtBucketName")
	waitForInternalLogInstance "$clusterName" "$PIPELINE_SHUTDOWN_DONE_MSG" "$(($currentInstanceCnt + 1))" 2 "$srcBucketName\/$tgtBucketName"

	if ((!$? == 0)); then
		echo "Timed out waiting for message $PIPELINE_SHUTDOWN_DONE_MSG with buckets "$srcBucketName/$tgtBucketName" to increase from $currentInstanceCnt by 1"
		dumpDebugInfoBeforeExit
		exit 1
	fi
}

# 1 - cluster name
# 2 - String to look for
# 3 - Minimum Number of occurrences to wait for
# 4 - Number of minutes to wait for
function waitForInternalLogInstance {
	local clusterName=$1
	local grepStr="$2"
	local instanceCnt=$3
	local minToWait=$4
	local optionalGrepStr=${5:-}
	local minElapsed=0
	local i=0

	while (($minElapsed < $minToWait)); do
		logs=$(getInternalNodeXdcrLog "$clusterName")
		if ((!$? == 0)); then
			echo "Unable to get log for validation"
			exit 1
		fi

		if [[ -z "$optionalGrepStr" ]]; then
			count=$(echo "$logs" | grep -c "$grepStr")
			if (($count >= $instanceCnt)); then
				echo "Found $instanceCnt instances of the string: $grepStr"
				return
			fi
		else
			count=$(echo "$logs" | grep "$grepStr" | grep -c "$optionalGrepStr")
			if (($count >= $instanceCnt)); then
				echo "Found $instanceCnt instances of the string: $grepStr with $optionalGrepStr"
				return
			fi
		fi

		sleep 10
		i=$(($i + 1))
		if (($i == 6)); then
			minElapsed=$(($minElapsed + 1))
			i=0
		fi
	done

	return 1
}

# 1 - cluster name
# 2 - String to look for
# 3 - Number of occurrences
# 4 - Max number of occurrences
function validateInternalLogWithInstance {
	local clusterName=$1
	local grepStr="$2"
	local instanceCnt=$3
	local maxInstanceCnt=${4:-}

	logs=$(getInternalNodeXdcrLog "$clusterName")
	if ! (($? == 0)); then
		echo "Unable to get log for validation"
		exit 1
	fi

	count=$(echo "$logs" | grep -c "$grepStr")
	if (($count != $instanceCnt)); then
		if [[ ! -z "$maxInstanceCnt" ]] && (($count > $maxInstanceCnt)); then
			echo "Error - requested count for $grepStr is $instanceCnt or <= $maxInstanceCnt, but found $count"
			dumpDebugInfoBeforeExit
			exit 1
		elif [[ ! -z "$maxInstanceCnt" ]] && (($count < $instanceCnt)); then
			echo "Error - requested count for $grepStr is $instanceCnt or <= $maxInstanceCnt, but found $count"
			dumpDebugInfoBeforeExit
			exit 1
		elif [[ ! -z "$maxInstanceCnt" ]]; then
			echo "Warning - requested count for $grepStr is $instanceCnt or <= $maxInstanceCnt, found $count"
		else
			echo "Error - requested count for $grepStr is $instanceCnt, but found $count"
			dumpDebugInfoBeforeExit
			exit 1
		fi
	else
		echo "Found exactly $instanceCnt of \"$grepStr\""
	fi
}

function validateXDCRCheckpoints {
	local cluster=$1

	checkpointOutput=$(getXDCRCheckpoints $cluster)
	if ! (($? == 0)); then
		echo "Unable to get checkpoint"
		dumpDebugInfoBeforeExit
		exit 1
	fi

	# validate
	echo "$checkpointOutput" | jq type >/dev/null
	if ! (($? == 0)); then
		echo "$checkpointOutput" >/tmp/checkpoint.error
		echo "Erroneous checkpoint output to /tmp/checkpoint.error"
		exit 1
	fi
}

function killAllBgJobs {
	jobs -l | awk '{print $2}' | xargs kill
}

function xdcrDifferParseOpts {
	local optsIn=$1

	if [[ "$optsIn" == "compareBody" ]]; then
		echo "-b"
	fi

	if [[ "$optsIn" == "retry" ]]; then
		echo "-e 2"
	fi
}

function runXdcrDiffer {
	local srcCluster=$1
	local srcPort=${CLUSTER_NAME_PORT_MAP[$srcCluster]:-}
	local srcBucket=$2
	local tgtCluster=$3
	local tgtBucket=$4
	local extraOpts1=${5:-}
	local extraOpts2=${6:-}
	local opts1Flag=""
	local opts2Flag=""

	local compareBody

	if [[ ! -z "${extraOpts1:-}" ]]; then
		opts1Flag="$(xdcrDifferParseOpts "$extraOpts1")"
	fi
	if [[ ! -z "${extraOpts2:-}" ]]; then
		opts2Flag="$(xdcrDifferParseOpts "$extraOpts2")"
	fi

	pushd $(pwd)

	cd $xdcrDifferDir
	$differSh -u $DEFAULT_ADMIN -p $DEFAULT_PW -h "127.0.0.1:$srcPort" -r $tgtCluster -s $srcBucket -t $tgtBucket -c $opts1Flag $opts2Flag
	retVal=$?

	popd
	return $retVal
}

function differGetTotalNumber {
	local input="$1"
	local collectionIDs
	local collectionID
	local sum=0

	collectionIDs=$(echo "$input" | jq 'keys' | jq .[])
	for collectionID in $(echo "$collectionIDs"); do
		local keys
		local numDocsForThisCollection
		keys=$(echo "$input" | jq ".$collectionID")
		numDocsForThisCollection=$(echo "$keys" | jq length)
		sum=$(($sum + $numDocsForThisCollection))
	done

	echo "$sum"
}

function validateDifferResults {
	local expectedMismatchCnt=$1
	local expectedMissingSrcCnt=$2
	local expectedMissingTgtCnt=$3
	local expectedDeletedSrcCnt=${4:-}
	local expectedDeletedTgtCnt=${5:-}
	local numOfMismatch
	local numOfMissingSrc
	local numOfMissingTgt
	local numOfDeletedSrc
	local numOfDeletedTgt
	local resultOutput
	local retVal=0
	local mismatchOutput
	local missingFromSourceOutput
	local missingFromTargetOutput
	local deletedFromSourceOutput
	local deletedFromTargetOutput

	if [[ ! -f "$mutationDiffResults" ]]; then
		echo "Error: Unable to find mutation results file: $mutationDiffResults"
		return 1
	fi

	resultOutput=$(cat $mutationDiffResults)
	mismatchOutput=$(echo "$resultOutput" | jq '.Mismatch')
	missingFromSourceOutput=$(echo "$resultOutput" | jq '.MissingFromSource')
	missingFromTargetOutput=$(echo "$resultOutput" | jq '.MissingFromTarget')

	numOfMismatch=$(differGetTotalNumber "$mismatchOutput")
	numOfMissingSrc=$(differGetTotalNumber "$missingFromSourceOutput")
	numOfMissingTgt=$(differGetTotalNumber "$missingFromTargetOutput")

	if (($numOfMismatch != $expectedMismatchCnt)); then
		echo "Expected $expectedMismatchCnt mismatch(es), but found $numOfMismatch"
		retVal=1
	fi

	if (($numOfMissingSrc != $expectedMissingSrcCnt)); then
		echo "Expected $expectedMissingSrcCnt missing from source, but found $numOfMissingSrc"
		retVal=1
	fi

	if (($numOfMissingTgt != $expectedMissingTgtCnt)); then
		echo "Expected $expectedMissingTgtCnt missing from target, but found $numOfMissingTgt"
		retVal=1
	fi

	if [ ! -z "$expectedDeletedSrcCnt" ]; then
		deletedFromSourceOutput=$(echo "$resultOutput" | jq '.DeletedFromSource')
		numOfDeletedSrc=$(differGetTotalNumber "$deletedFromSourceOutput")
		if (($numOfDeletedSrc != $expectedDeletedSrcCnt)); then
			echo "Expected $expectedDeletedSrcCnt deleted from source, but found $numOfDeletedSrc"
			retVal=1
		fi
	fi

	if [ ! -z "$expectedDeletedTgtCnt" ]; then
		deletedFromTargetOutput=$(echo "$resultOutput" | jq '.DeletedFromTarget')
		numOfDeletedTgt=$(differGetTotalNumber "$deletedFromTargetOutput")
		if (($numOfDeletedTgt != $expectedDeletedTgtCnt)); then
			echo "Expected $expectedDeletedTgtCnt deleted from target, but found $numOfDeletedTgt"
			retVal=1
		fi
	fi

	if (($retVal == 1)); then
		echo "$resultOutput" | jq
		echo ""
	fi

	return $retVal
}

function checkDifferLogItemCount {
	local srcOrTgt=$1
	local itemCnt=$2
	local filteredCnt=$3
	local logFile="${xdcrDifferDir}/xdcrDiffer.log"
	local expected="$srcOrTgt bucket item count including tombstones is $itemCnt (excluding $filteredCnt filtered mutations)"

	found=$(grep -c "$expected" $logFile)
	if (($found == 0)); then
		echo "Did not find the line: \"$expected\" from the file $logFile"
		exit 1
	fi
	echo "Found the line: $expected"
}

function checkInternalSetting {
	local clusterName=$1
	local settingKey=$2
	local expectedVal=$3
	local checkInt

	checkInt=$(getInternalSetting "$clusterName" "$settingKey")
	if (($checkInt != $expectedVal)); then
		echo "$settingKey is not set to $expectedVal. It is $checkInt"
		exit 1
	fi
}

# TODO - right now assumes only one outgoing pipeline per cluster
function validateBrokenMapExists {
	local errList
	local cluster=$1

	errList=$(getErrorListForMainPipeline $cluster)
	if ((!$? == 0)); then
		echo "Issue getting error list"
		exit 1
	fi

	if (($(echo "$errList" | jq 'length') == 0)); then
		echo "See no error list"
		exit 1
	fi
}

function checkNoErrorInErrorList {
	local cluster="$1"
	validateNumberOfEvents "$cluster" 0
}

function validateNumberOfEvents {
	local errList
	local cluster=$1
	local count=$2

	waitForNumberOfEvents "$cluster" "$count" 0
	if (($? > 0)); then
		exit 1
	fi
}

function waitForNumberOfEvents {
	local errList
	local cluster=$1
	local count=$2
	local minToWaitFor=$3

	errList=$(getErrorListForMainPipeline $cluster)
	if ((!$? == 0)); then
		echo "Issue getting error list"
		exit 1
	fi

	local curMin=0
	local actualCount=$(echo "$errList" | jq 'length')
	if (($actualCount != $count)); then
		echo "Expecting $count in errorsList but found $actualCount"
		if (($minToWaitFor == 0)) || (($curMin > $minToWaitFor)); then
			return 1
		else
			curMin=$(($curMin + 1))
			echo "Waiting one minute and trying again"
			sleep 60
		fi
	fi
}

function validateBrokenMapDoesNotExist {
	local cluster=$1
	checkNoErrorInErrorList $cluster
}

# Ensures that a specified linkage is broken
function validateBrokenMapEntry {
	local cluster=$1
	local sourceScopeName=$2
	local sourceCollectionName=$3
	local targetScopeName=$4
	local targetCollectionName=$5

	getBrokenMapEntryId "$cluster" "$sourceScopeName" "$sourceCollectionName" "$targetScopeName" "$targetCollectionName"
	local entryId=$?
	if (($entryId == $GET_BROKEN_MAP_NOT_FOUND)); then
		exit 1
	fi
	echo "Got entry ID: $entryId"
}

function validateBrokenMapEntryDNE {
	local cluster=$1
	local sourceScopeName=$2
	local sourceCollectionName=$3
	local targetScopeName=$4
	local targetCollectionName=$5

	getBrokenMapEntryId "$cluster" "$sourceScopeName" "$sourceCollectionName" "$targetScopeName" "$targetCollectionName"
	if ((!$? == $GET_BROKEN_MAP_NOT_FOUND)); then
		echo "Found entry when not supposed to"
		exit 1
	fi
}

# returns the count of remote cluster ref from source to target
function getRemoteCluster {
	local source=$1
	local target=$2
	local host=${CLUSTER_NAME_HOST_MAP[$source]:-"127.0.0.1"}
	local port=${CLUSTER_NAME_PORT_MAP[$source]:-}
	result=$(curl -GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://$host:$port/pools/default/remoteClusters | jq | grep name | grep -c $target)
	echo $result
}

# returns the output from /pools/default/remoteClusters
function getRemoteClusters {
	local source=$1
	local host=${CLUSTER_NAME_HOST_MAP[$source]:-"127.0.0.1"}
	local port=${CLUSTER_NAME_PORT_MAP[$source]:-}
	result=$(curl -GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://$host:$port/pools/default/remoteClusters)
	echo $result
}

function checkReplicationInfos {
	local srcClusterName=$1

	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$srcClusterName]:-}
	local sourceHost=${CLUSTER_NAME_HOST_MAP[$srcClusterName]:-"127.0.0.1"}

	echo "curl -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://${sourceHost}:${sourcePort}/pools/default/replicationInfos"
	curl -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://${sourceHost}:${sourcePort}/pools/default/replicationInfos
}

function changeRemoteClusterReferenceToSecure {
	local source=$1
	local target=$2
	local targetHost=${3:-"127.0.0.1"}
	if [[ -z "${source:-}" ]] || [[ -z "${target:-}" ]]; then
		echo "Invalid input"
		return 1
	fi
	local sourcePort=${CLUSTER_NAME_PORT_MAP[$source]:-}
	local targetPort=${4:-${CLUSTER_NAME_PORT_MAP[$target]}}
	local targetSecurePort=${CLUSTER_NAME_SECURE_PORT_MAP[$target]:-$targetPort}
	local remoteClusterCert=${5:-}

	# Get the target cluster's root certificate if not provided
	if [[ -z "${remoteClusterCert:-}" ]]; then
		remoteClusterCert=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://$targetHost:$targetPort/pools/default/certificate)
	fi

	echo "Change remote cluster reference from $source to $target ($targetHost:$targetPort) to SECURE"
	echo "$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/pools/default/remoteClusters/$target -d name=$target -d hostname=$targetHost:$targetSecurePort -d username=$DEFAULT_ADMIN -d password=$DEFAULT_PW -d encryptionType=full -d demandEncryption=1 --data-urlencode \"certificate=${remoteClusterCert}\""
	$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/pools/default/remoteClusters/$target -d name=$target -d hostname=$targetHost:$targetSecurePort -d username=$DEFAULT_ADMIN -d password=$DEFAULT_PW \
		-d encryptionType=full -d demandEncryption=1 --data-urlencode "certificate=${remoteClusterCert}"
}

function testIdleXdcrCPU {
	local goxdcrCPUsOut
	local oldIFS
	local retResult=0

	goxdcrCPUsOut=$(ps -e -o pid,pcpu,comm | grep goxdcr)
	oldIFS="$IFS"
	IFS=$'\n'

	local oneXDCRProcess
	local oneXDCRCPU
	for oneXDCRProcess in $(echo "$goxdcrCPUsOut"); do
		oneXDCRCPU=$(echo "$oneXDCRProcess" | awk '{print $2}')
		if (($(echo "$oneXDCRCPU > $GOXDCR_IDLE_CPU_THRESHOLD" | bc) == 1)); then
			echo "GOXDCR CPU process is using $oneXDCRCPU% and greater than idle threshold of $GOXDCR_IDLE_CPU_THRESHOLD"
			retResult=1
		else
			echo "GOXDCR CPU process is using $oneXDCRCPU% and under acceptable threshold of $GOXDCR_IDLE_CPU_THRESHOLD"
		fi
	done
	IFS="$oldIFS"

	return $retResult
}

function getXDCRPid {
	local clusterName="$1"
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	local pid
	pid=$(ps -ef | grep goxdcr | grep "=$sourcePort" | awk '{print $2}')
	local result=$?
	echo "$pid"
	return $result
}

function getXdcrRSS {
	local clusterName="$1"
	local pid

	pid=$(getXDCRPid $clusterName)
	if ((!$? == 0)); then
		return 1
	fi

	local rss
	local result
	rss=$(ps -xm -o rss,comm -p $pid | grep goxdcr | awk '{print $1}')
	result=$?
	echo "$rss"
	return $result
}

function monitorXdcrProcessMem {
	local clusterName=$1
	local numOfMinutes=$2
	local oldPid
	local pid
	local oldRss=0
	local origRss=0
	local rss
	local percentage
	local xdcrPort=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	oldPid=$(getXDCRPid $clusterName)

	local i
	for ((i = 0; $i < $numOfMinutes; i = (($i + 1)))); do
		pid=$(getXDCRPid $clusterName)
		if ((!$pid == $oldPid)); then
			echo "$clusterName XDCR process PID went from $oldPid to $pid. Might have exploded"
			return 1
		fi

		rss=$(getXdcrRSS $clusterName)
		if (($oldRss == 0)); then
			oldRss=$rss
			origRss=$rss
			echo "Start monitoring memory for node $clusterName... current RSS: $rss"
		elif (($rss == 0)); then
			echo "$clusterName got 0 rss??"
		else
			if (($rss > $oldRss)); then
				percentage=$(echo "scale=2; ($rss-$oldRss)/$oldRss * 100" | bc)
				echo "$clusterName XDCR size increased from $oldRss to $rss ($percentage %)"
				curl -s http://localhost:$xdcrPort/debug/pprof/heap >/tmp/heap_$xdcrPort.$i
			else
				percentage=$(echo "scale=2; ($oldRss-$rss)/$oldRss * 100" | bc)
				echo "$clusterName XDCR size decreased from $oldRss to $rss ($percentage %)"
			fi
			oldRss=$rss
		fi
		sleep 60
	done
	percentage=$(echo "scale=2; ($rss-$origRss)/$origRss * 100" | bc)
	echo "Done monitoring memory for node $clusterName. From $origRss to $rss ($percentage %)"
}

function getGoroutinesStack {
	local clusterName=$1
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	echo "Goroutines for cluster $clusterName..."
	$CURL http://localhost:$sourcePort/debug/pprof/goroutine?debug=1
}

function getGoHeap {
	local clusterName=$1
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$clusterName]:-}

	echo "Go heap for cluster $clusterName..."
	$CURL http://localhost:$sourcePort/debug/pprof/heap?debug=1
}

function xdcrMemRss {
	local -A PORT_PID_MAP

	if (($(ps -ef | grep goxdcr | grep -cv grep) == 0)); then
		echo "No XDCR processes found"
		return 0
	fi

	local OLDIFS="$IFS"
	IFS=$'\n'
	local sourcePort
	local pid

	for processLine in $(ps -ef | grep goxdcr | grep sourceKVAdmin); do
		sourcePort=$(echo "$processLine" | awk '{print $9}' | cut -d= -f2)
		pid=$(echo "$processLine" | awk '{print $2}')
		PORT_PID_MAP["$sourcePort"]=$pid
	done
	IFS="$OLDIFS"

	for sourcePort in $(echo ${!PORT_PID_MAP[@]}); do
		pid=${PORT_PID_MAP[$sourcePort]}
		local RSS=$(ps -o rss= -p $pid)
		echo "XDCR port $sourcePort Pid $pid - RSS: $RSS"
	done
}

function dumpDebugInfoBeforeExit {
	local clusterName

	xdcrMemRss
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		getGoroutinesStack "$clusterName" >/tmp/$clusterName.pprof.log
		getGoHeap "$clusterName" >/tmp/$clusterName.hprof.log
	done
}

function checkOpenSSL {
	if (($(openssl version | grep -c "LibreSSL 2.8.3") == 1)); then
		echo "Running this test requires brew version of openssl. Press brew install/upgrade openssl and link it to your bashProfile"
		exit 1
	fi
}

function findNsServerDir {
	local i=0
	local outStr=""
	pushd "$PWD" >/dev/null

	while [[ "$PWD" != / ]] && [[ ! -d "ns_server" ]]; do
		i=$(($i + 1))
		cd ..
	done

	local j
	for ((j = 0; $j < $i; j = $(($j + 1)))); do
		outStr="${outStr}../"
	done
	outStr="${outStr}ns_server"
	popd >/dev/null

	echo "$outStr"
}

function setupCertificateAuthority {
	local clusterName="$1"
	local dependentNodeName

	# Create a private key for the cluster.
	openssl genrsa -out ca.key 2048

	# Create the certificate (that is, the file that will contain the public key) for the cluster. The certificate is
	# intended to be self-signed, meaning that it will not be vouched for by any other authority. This means that it can
	# be created directly, based on the existing private key ca.key, without assistance from a third party.
	openssl req -new -x509 -days 3650 -sha256 -key ca.key -out ca.pem \
		-subj "/CN=Couchbase Root CA"
	#openssl req -new -x509 -days 3650 -sha256 -key ca.key -out ca.pem \
	# -subj "/CN=Couchbase Server"

	# The lines below here will at least get some verification failure
	#openssl req -new -x509 -days 3650 -sha256 -key ca.key -out ca.pem \
	#  -subj "/C=UA/O=MyCompany/CN=MyCompanyRootCA"

	CLUSTER_ROOT_CERTIFICATE_MAP["$clusterName"]=$(cat "ca.pem")
	CLUSTER_ROOT_CERTIFICATE_LOCATION["$clusterName"]="$(PWD)/ca.pem"
	CLUSTER_ROOT_KEY_LOCATION["$clusterName"]="$(PWD)/ca.key"

	# For dependent nodes, they should use the same CA
	for dependentNodeName in $(echo ${!CLUSTER_DEPENDENCY_MAP[@]}); do
		if [[ "${CLUSTER_DEPENDENCY_MAP["$dependentNodeName"]}" == "$clusterName" ]]; then
			# This dependentNode will be using this CA setup
			CLUSTER_ROOT_CERTIFICATE_MAP["$dependentNodeName"]=$(cat "ca.pem")
			CLUSTER_ROOT_CERTIFICATE_LOCATION["$dependentNodeName"]="$(PWD)/ca.pem"
			CLUSTER_ROOT_KEY_LOCATION["$dependentNodeName"]="$(PWD)/ca.key"
		fi
	done
}

function setupCertsForTesting {
	checkOpenSSL
	# Currently this test library exists under goproj/src/github.com/couchbase/goxdcr/tools/testScripts/
	# before below, store the ns_server absolute path
	local nsServerDir="$(findNsServerDir)"
	pushd $(pwd)
	cd $nsServerDir
	local nsServerDirAbsolute=$(pwd)
	echo "ns_server directory: $nsServerDirAbsolute"
	popd

	pushd $(pwd)

	local clusterName
	local depedentCheck
	local sanIP

	# First do cleanup + setup
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		cd /tmp/ || exit
		rm -rf servercertfiles_$clusterName
		mkdir servercertfiles_$clusterName || exit
		cd servercertfiles_$clusterName || exit
		mkdir -p {public,private,requests} || exit
	done

	cd /tmp/ || exit

	# First set up CA
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		# For now, skip if it is considered a dependent node. A dependent node will be using the CA created by the mother node
		if [[ -n "${CLUSTER_DEPENDENCY_MAP[$clusterName]:-}" ]]; then
			continue
		fi
		cd servercertfiles_$clusterName || exit
		setupCertificateAuthority "$clusterName"
		cd ..
	done

	cd /tmp/ || exit

	# Then perform actual node-based certs
	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		cd /tmp/ || exit
		cd servercertfiles_$clusterName || exit

		# On the server to be certificate-protected, create working directories:

		local port=${CLUSTER_NAME_PORT_MAP[$clusterName]:-}
		local nodeDirIdx=$(echo "$port % 10" | bc)

		#Create a private key for the individual node.
		openssl genrsa -out private/couchbase.default.svc.key 2048

		# Create a certificate signing request for the node certificate.
		openssl req -new -key private/couchbase.default.svc.key \
			-out requests/couchbase.default.svc.csr -subj "/CN=Couchbase Server"

		# Define certificate extensions for the node.
		#				cat >server.ext <<EOF
		#[req]
		#distinguished_name = cn_only
		#x509_extensions = ca_ext
		#[ cn_only ]
		#commonName = Common Name (eg: your user, host, or server name)
		#commonName_max = 64
		#commonName_default = CA
		#[ca_ext]
		#basicConstraints = CA:TRUE
		#subjectKeyIdentifier = hash
		#authorityKeyIdentifier = keyid:always,issuer:always
		#keyUsage = cRLSign, keyCertSign
		#EOF

		cat >server.ext <<EOF
basicConstraints=CA:FALSE
subjectKeyIdentifier = hash
authorityKeyIdentifier = keyid,issuer:always
extendedKeyUsage=serverAuth
keyUsage = digitalSignature,keyEncipherment
EOF

		# Create a customized certificate extensions file, which adds per node constraints to the generic constraints already specified.
		cp ./server.ext ./server.ext.tmp

		unset sanIPs
		local -a sanIPs
		sanIPs[0]="127.0.0.1"
		if [[ ! -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
			sanIPs[${#sanIPs[@]}]="${VAGRANT_VM_IP_MAP["$clusterName"]}"
			if [[ -n "${VAGRANT_IP_EXTERNAL_MAP["$clusterName"]:-}" ]]; then
				sanIPs[${#sanIPs[@]}]="${VAGRANT_IP_EXTERNAL_MAP["$clusterName"]}"
			fi
			if [[ -n "${VAGRANT_LB_IP:-}" ]]; then
				sanIPs[${#sanIPs[@]}]="$VAGRANT_LB_IP"
			fi
		else
			sanIPs[${#sanIPs[@]}]="$(ipconfig getifaddr en0)"
		fi

		local counter=0
		for sanIP in $(echo ${sanIPs[@]}); do
			if (($counter == 0)); then
				echo -n "subjectAltName = IP:${sanIP}" \
					>>./server.ext.tmp
			else
				echo -n ", IP:${sanIP}" >>./server.ext.tmp
			fi
			counter=$(($counter + 1))
		done
		echo "" >>./server.ext.tmp

		# Create the node certificate, applying the certificate and digital signature of the appropriate authority, and the
		# customized extensions file for the node, to the materials in the signing request.
		openssl x509 -CA ${CLUSTER_ROOT_CERTIFICATE_LOCATION["$clusterName"]} -CAkey ${CLUSTER_ROOT_KEY_LOCATION["$clusterName"]} -CAcreateserial -days 365 -req \
			-in requests/couchbase.default.svc.csr \
			-out public/couchbase.default.svc.pem \
			-extfile server.ext.tmp

		# Rename the node certificate and node private key.
		local chainFileName="node${nodeDirIdx}_chain.pem"
		local pKeyFileName="node${nodeDirIdx}_pkey.key"
		cd ./public || exit
		mv couchbase.default.svc.pem $chainFileName
		cd ../private || exit
		mv couchbase.default.svc.key $pKeyFileName
		cd ..

		# Deploy the node certificate and node private key.
		local couchbaseDir="$nsServerDirAbsolute/data/n_${nodeDirIdx}/"
		mkdir -p $couchbaseDir/inbox/ || exit

		NODE_CERT_MAP["$clusterName"]="$PWD/public/$chainFileName"
		NODE_KEY_MAP["$clusterName"]="$PWD/private/$pKeyFileName"
		# TODO: figure out nodeCA map and see what's happening for vagrant
		NODE_CA_MAP["$clusterName"]="$PWD/ca.pem"

		if [[ -z "${VAGRANT_VM_IP_MAP["$clusterName"]:-}" ]]; then
			cp ./public/$chainFileName $couchbaseDir/inbox/chain.pem
			cp ./private/$pKeyFileName $couchbaseDir/inbox/pkey.key

			# Upload the root certificate for the cluster. Use the following REST command:
			#curl -X POST --data-binary "@./ca.pem" \
			#	http://$DEFAULT_ADMIN:$DEFAULT_PW@127.0.0.1:$port/controller/uploadClusterCA
			curl -X POST --data-binary "@${CLUSTER_ROOT_CERTIFICATE_LOCATION["$clusterName"]}" \
				http://$DEFAULT_ADMIN:$DEFAULT_PW@127.0.0.1:$port/controller/uploadClusterCA

			# Reload the node certificate from disk, for the current node:
			curl -X POST \
				http://$DEFAULT_ADMIN:$DEFAULT_PW@127.0.0.1:$port/node/controller/reloadCertificate
		else
			echo "Running vagrant, skipping copy for now"
		fi

		# currently still in the servercertfiles_CX
		rm -rf clientcertfiles
		mkdir clientcertfiles
		cd clientcertfiles || exit

		# Create an extensions file for the use of all clients
		cat >client.ext <<EOF
basicConstraints = CA:FALSE
subjectKeyIdentifier = hash
authorityKeyIdentifier = keyid,issuer:always
extendedKeyUsage = clientAuth
keyUsage = digitalSignature
EOF

		cp ./client.ext ./client.ext.tmp

		echo "subjectAltName = email:john.smith@mail.com" \
			>>./client.ext.tmp

		# Create a client private key.
		openssl genrsa -out ./travel-sample.key 2048

		# Generate the client-certificate signing-request.
		openssl req -new -key ./travel-sample.key -out ./travel-sample.csr -subj "/CN=Administrator"

		# Create the client certificate. In this example, the customized extensions file, client.ext.tmp, is used.
		#openssl x509 -CA ../ca.pem -CAkey ../ca.key \
		#	-CAcreateserial -days 365 -req -in ./travel-sample.csr \
		#	-out ./travel-sample.pem -extfile ./client.ext.tmp
		openssl x509 -CA ${CLUSTER_ROOT_CERTIFICATE_LOCATION[$clusterName]} \
			-CAkey ${CLUSTER_ROOT_KEY_LOCATION[$clusterName]} \
			-CAcreateserial -days 365 -req -in ./travel-sample.csr \
			-out ./travel-sample.pem -extfile ./client.ext.tmp

		local clientCertName="node${nodeDirIdx}_client.pem"
		local clientKeyName="node${nodeDirIdx}_client.key"

		mv travel-sample.pem $clientCertName
		mv travel-sample.key $clientKeyName

		CLIENT_CERT_MAP["$clusterName"]="$PWD/$clientCertName"
		CLIENT_KEY_MAP["$clusterName"]="$PWD/$clientKeyName"

		# Back to clientcertfiles
		#cd ..
		# Back to "root" directory before the server_certfiles...
		#cd ..
	done

	popd

	for clusterName in $(echo ${!CLUSTER_NAME_PORT_MAP[@]}); do
		echo "NODE CERT for $clusterName: ${NODE_CERT_MAP[$clusterName]}"
		echo "NODE KEY for $clusterName: ${NODE_KEY_MAP[$clusterName]}"
		echo "NODE CA for $clusterName: ${NODE_CA_MAP[$clusterName]}"
		echo "NODE CLIENT CERT for $clusterName: ${CLIENT_CERT_MAP[$clusterName]}"
		echo "NODE CLIENT KEY for $clusterName: ${CLIENT_KEY_MAP[$clusterName]}"
	done

}

# Usage: pass the node log to this function
# Input: vb#
function validateVBTaskExistsInternnal {
	local vb=$1
	local input=$(cat)

	local lastVBsTaskInstance
	lastVBsTaskInstance=$(echo "$input" | grep "VBTaskMap:map" | tail -n 1 | tr ' ' $'\n' | grep "[[:alnum:]]:0x" | cut -d':' -f1)

	if (($(echo "$lastVBsTaskInstance" | grep -c "$vb") == 0)); then
		echo "Last instance of VB task does not contain VB $vb"
		return 1
	fi
}

function validateLastBackfillContainsVBTask {
	local logNodeName=$1
	local remClusterName=$2
	local vb=$3

	local remClusterUUID
	remClusterUUID=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local result=$?
	if ((!$result == 0)); then
		echo "Unable to parse UUID return code $result"
		return 1
	fi

	local inputToInternal
	inputToInternal=$(getInternalNodeXdcrLog "$logNodeName")
	echo "$inputToInternal" | validateVBTaskExistsInternnal "$vb"
	if ((!$? == 0)); then
		exit 1
	fi
}

# Look at the logs to find one VB for backfill pipeline that is not 0
# Input:
# 1. clusterName to look at the log
# 2. Remote Cluster name
# 3. Source Bucket Name
# 4. Target Bucket Name
function getNon0StartingBackfillVB {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4
	local firstNon0VB

	local remClusterUUID
	remClusterUUID=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local result=$?
	if ((!$result == 0)); then
		echo "Unable to parse UUID return code $result"
		return 1
	fi

	firstNon0VB=$(getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" "backfill" | getFirstNon0VB)
	result=$?
	if (($result == 0)); then
		echo "$firstNon0VB"
	fi
	return $result
}

# Test validation function that looks at pipeline resumes lifecycle
# and makes sure that for each VB XDCR is not rolling backwards
#
# Input:
# 1. clusterName to look at the log
# 2. Remote Cluster name
# 3. Source Bucket Name
# 4. Target Bucket Name
function validateCheckpointResumeSeqnos {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4

	local remClusterUUID
	remClusterUUID=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local result=$?
	if ((!$result == 0)); then
		echo "Unable to parse UUID return code $result"
		return 1
	fi

	echo "Parsing log for $logNodeName pipeline ${remClusterUUID}/${srcBucketName}/${tgtBucketName} for VB timestamps..."
	local vbsSeqnosOutput
	vbsSeqnosOutput=$(getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" | parseSetVBTimestamps)

	local OLDIFS="$IFS"
	local oneLine
	local atLeastOneFound
	IFS=$'\n'
	for oneLine in $(echo "$vbsSeqnosOutput"); do
		local vb
		local seqnos
		local -a seqnosArr
		# VB 1023: 865,4939,4939,5246,4939,5246,6354,5246,6354
		if [[ "$oneLine" =~ VB\ ([0-9]+): ]]; then
			vb=${BASH_REMATCH[1]}
			seqnos=$(echo "$oneLine" | cut -d: -f2 | xargs | tr ',' $'\n')
			local preVal
			local curVal
			preVal=""
			curVal=""
			for curVal in $(echo "$seqnos"); do
				if [[ -z "${preVal:-}" ]]; then
					# first
					preVal=$curVal
				else
					if (($curVal < $preVal)); then
						# Checkpoint resuming rolled backwards
						echo "Found at least one VB where checkpoint is resuming from an earlier point ($vb): $oneLine"
						IFS="$OLDIFS"
						exit 1
					fi
					preVal=$curVal
				fi
			done
			atLeastOneFound=1
		else
			echo "Unable to parse \"$oneLine\""
			IFS="$OLDIFS"
			exit 1
		fi
	done
	IFS="$OLDIFS"

	if [[ -z "${atLeastOneFound:-}" ]]; then
		echo "Unable to parse"
		getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" >/tmp/getSetVBTimestamp
	fi
}

# Test validation function that looks at backfill pipeline resumes lifecycle
# to make sure that at there are at least X VB's that have been checkpointed
#
# Input:
# 1. clusterName to look at the log
# 2. Remote Cluster name
# 3. Source Bucket Name
# 4. Target Bucket Name
function validateBackfillCkptTookPlaceForVBs {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4
	local minVBsToHaveCkpt=$5

	local totalVBsThatHaveCkpt
	totalVBsThatHaveCkpt=$(getNumOfBackfillCkptTookPlaceVB "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName")
	if (($totalVBsThatHaveCkpt < $minVBsToHaveCkpt)); then
		echo "For node $logNodeName requested to have at least $minVBsToHaveCkpt VBs to have checkpoint but only $totalVBsThatHaveCkpt have checkpoints"
		exit 1
	fi
}

function getNumOfBackfillCkptTookPlaceVB {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4

	local remClusterUUID
	remClusterUUID=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local result=$?
	if ((!$result == 0)); then
		echo "Unable to parse UUID return code $result"
		return 1
	fi

	local vbsSeqnosOutput
	vbsSeqnosOutput=$(getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" "backfill" | parseSetVBTimestamps)

	local OLDIFS="$IFS"
	local oneLine
	local atLeastOneFound
	local atLeastOneVBHasCkpt
	local -A vbHasCkptMap
	IFS=$'\n'
	for oneLine in $(echo "$vbsSeqnosOutput"); do
		local vb
		local seqnos
		local -a seqnosArr
		# VB 1023: 865,4939,4939,5246,4939,5246,6354,5246,6354
		if [[ "$oneLine" =~ VB\ ([0-9]+): ]]; then
			vb=${BASH_REMATCH[1]}
			seqnos=$(echo "$oneLine" | cut -d: -f2 | xargs | tr ',' $'\n')
			local preVal
			local curVal
			curVal=""
			for curVal in $(echo "$seqnos"); do
				if (($curVal > 0)); then
					vbHasCkptMap["$vb"]="true"
					atLeastOneVBHasCkpt="true"
				fi
			done
			atLeastOneFound=1
		else
			echo "Unable to parse \"$oneLine\""
			IFS="$OLDIFS"
			exit 1
		fi
	done
	IFS="$OLDIFS"

	if [[ -z "${atLeastOneFound:-}" ]]; then
		echo "Unable to parse"
		getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" >/tmp/getSetVBTimestamp
		return 1
	fi

	local totalVBsThatHaveCkpt
	if [[ -z "${atLeastOneVBHasCkpt:-}" ]]; then
		totalVBsThatHaveCkpt=0
	else
		totalVBsThatHaveCkpt="${#vbHasCkptMap[@]}"
	fi

	echo "$totalVBsThatHaveCkpt"
}

function getLastSetVBTimestampSeqno {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4
	local vbno=$5
	local backfill=${6:-}
	local output
	output=$(getSetVBTimestampMsgsFromLogs "$logNodeName" "$remClusterName" "$srcBucketName" "$tgtBucketName" "${backfill:-}" | grep "vb=$vbno" | parseSetVBTimestamps)

	local seqno
	seqno=$(echo "$output" | tr ',' ' ' | awk '{print $NF}')
	echo "$seqno"
}

# Ensure that VB tasks are progressing and that there are less tasks (less VBs) over time
function validateVBTasksProgress {
	local logNodeName=$1
	local remClusterName=$2
	local srcBucketName=$3
	local tgtBucketName=$4

	local clusterUuid
	clusterUuid=$(getClusterUuidUsingNameFromLogs "$logNodeName" "$remClusterName")
	local retVal=$?
	if ((!$retVal == 0)); then
		echo "Unable to get clusterUUID with return code $retVal"
		return 1
	fi

	local vbTasksMsgs
	vbTasksMsgs=$(getInternalNodeXdcrLog "$logNodeName" | grep "backfill_${clusterUuid}/${srcBucketName}/${tgtBucketName}_ThroughSeqnoTracker bg scanner" | grep -v "running")

	local totalCount

	local OLDIFS="$IFS"
	IFS=$'\n'

	local prevLineCnt=0
	local curVBDoneCount
	local staticCounter=0
	local maxStaticCount=3
	for oneVBTasks in $(echo "$vbTasksMsgs"); do
		# This many number of VBs being supplied for tasks
		curVBDoneCount=$(echo "$oneVBTasks" | awk '{print $11}')
		if (($prevLineCnt == 0)); then
			prevLineCnt=$curVBDoneCount
		elif (($curVBDoneCount == $prevLineCnt)); then
			staticCounter=$(($staticCounter + 1))
			if (($staticCounter == $maxStaticCount)); then
				echo "VB task has remained the same for $maxStaticCount times"
				IFS="$OLDIFS"
				exit 1
			fi
		fi
	done
	IFS="$OLDIFS"
}

# Validates that the result is greater than 0
function validatePrometheusStatsRRNon0 {
	local node=$1
	local sourceBucket=$2
	local targetBucket=$3
	local sourcePort=${CLUSTER_NAME_XDCR_PORT_MAP[$node]:-}
	local prometheusOut
	prometheusOut=$($CURL -X GET -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$sourcePort/_prometheusMetrics)

	local count
	count=$(echo "$prometheusOut" | grep pipelineType | grep Main | grep xdcr_guardrail_resident_ratio_total |
		grep "sourceBucketName=\"${sourceBucket}\"" | grep "targetBucketName=\"${targetBucket}\"" | awk '{print $NF}')

	if (($count == 0)); then
		echo "Guardrail resident ratio shows 0"
		exit 1
	fi
}

# use cbc-pillowfight to create a large bucket
function runCbcPillowFight {
	local cluster=$1
	local bucket=$2
	local numDocs=$3
	local scope=$4
	local collection=$5

	if [[ -z "${cluster:-}" ]] || [[ -z "${bucket:-}" ]] || [[ -z "${numDocs:-}" ]]; then
		echo "Error: Expected to pass cluster, bucket and numDocs"
		return 1
	fi

	if [[ -z "${scope:-}" ]]; then
		scope="_default"
	fi
	if [[ -z "${collection:-}" ]]; then
		collection="_default"
	fi

	local port=${CLUSTER_NAME_PORT_MAP[$cluster]}
	if [[ -z "${port:-}" ]]; then
		echo "Error: Invalid cluster - $cluster"
		return 1
	fi

	local cbcPillowfight
	cbcPillowfight=$(locate cbc-pillowfight | grep install | grep bin | head -n 1)
	if [[ -z "${cbcPillowfight:-}" ]]; then
		cbcPillowfight=$(mdfind cbc-pillowfight | grep install | grep bin | head -n 1)
	fi
	if [[ -z "${cbcPillowfight:-}" ]]; then
		echo "Error: cannot locate cbc-pillowfight"
		return 1
	fi

	$cbcPillowfight -U http://localhost:$port/$bucket --collection $scope.$collection -M 2000000 -m 2000000 -I $numDocs --json --populate-only -u $DEFAULT_ADMIN -P $DEFAULT_PW -t 5

	return 0
}

# The cbepctl tool is used to control vBucket states, configuration, and memory and disk persistence behavior.
function runCbepctl {
	local cluster=$1
	local bucket=$2
	local paramType=$3
	local param=$4
	local val=$5
	local kvPort

	if [[ -z "${cluster:-}" ]] || [[ -z "${bucket:-}" ]] || [[ -z "${paramType:-}" ]] || [[ -z "${param:-}" ]] || [[ -z "${param:-}" ]]; then
		echo "Error: Expected to pass cluster, bucket, paramType, param and val"
		return 1
	fi

	kvPort=${CLUSTER_NAME_KV_PORT_MAP[$cluster]}
	if [[ -z "${kvPort:-}" ]]; then
		echo "kvPort for $cluster is not set in CLUSTER_NAME_KV_PORT_MAP"
		return 1
	fi

	local cbepctl
	cbepctl=$(locate cbepctl | grep install | grep bin | head -n 1)
	if [[ -z "${cbepctl:-}" ]]; then
		cbepctl=$(mdfind cbepctl | grep install | grep bin | head -n 1)
	fi
	if [[ -z "${cbepctl:-}" ]]; then
		echo "Error: cannot locate cbepctl"
		return 1
	fi

	$cbepctl localhost:$kvPort -u $DEFAULT_ADMIN -p $DEFAULT_PW -b $bucket set $paramType $param $val

	return 0
}

function setBucket {
	local cluster=$1
	local bucketName=$2
	local setting=$3
	local value=$4

	local port=${CLUSTER_NAME_PORT_MAP[$cluster]:-}
	echo "$CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/pools/default/buckets/$bucketName -d $setting=$value"
	output=$($CURL -X POST -u $DEFAULT_ADMIN:$DEFAULT_PW http://127.0.0.1:$port/pools/default/buckets/$bucketName -d $setting=$value)
	echo $output
}
